{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules from keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# creates a generic neural network architecture\n",
    "model = Sequential()\n",
    "\n",
    "# hidden layer takes a pre-processed frame as input, and has 200 units\n",
    "model.add(Dense(units=200,input_dim=80*80, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(units=1, activation='sigmoid', kernel_initializer='RandomNormal'))\n",
    "\n",
    "# compile the model using traditional Machine Learning losses and optimizers\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: gym\n",
      "Version: 0.16.0\n",
      "Summary: The OpenAI Gym: A toolkit for developing and comparing your reinforcement learning agents.\n",
      "Home-page: https://github.com/openai/gym\n",
      "Author: OpenAI\n",
      "Author-email: gym@openai.com\n",
      "License: UNKNOWN\n",
      "Location: /Users/hannesengelbrecht/Library/Python/2.7/lib/python/site-packages\n",
      "Requires: cloudpickle, six, pyglet, scipy, numpy, enum34\n",
      "Required-by: \n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip show gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: numpy\n",
      "Version: 1.16.6\n",
      "Summary: NumPy is the fundamental package for array computing with Python.\n",
      "Home-page: https://www.numpy.org\n",
      "Author: Travis E. Oliphant et al.\n",
      "Author-email: None\n",
      "License: BSD\n",
      "Location: /Users/hannesengelbrecht/Library/Python/2.7/lib/python/site-packages\n",
      "Requires: \n",
      "Required-by: opencv-python, matplotlib, h5py, gym, atari-py\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip show numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/usr/local/lib/python3.7/site-packages')\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "# gym initialization\n",
    "env = gym.make(\"Pong-v0\")\n",
    "observation = env.reset()\n",
    "prev_input = None\n",
    "\n",
    "# Macros\n",
    "UP_ACTION = 2\n",
    "DOWN_ACTION = 3\n",
    "\n",
    "# Hyperparameters\n",
    "gamma = 0.99\n",
    "\n",
    "# initialization of variables used in the main loop\n",
    "x_train, y_train, rewards = [],[],[]\n",
    "reward_sum = 0\n",
    "episode_nb = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing used by Karpathy (cf. https://gist.github.com/karpathy/a4166c7fe253700972fcbc77e4ea32c5)\n",
    "def prepro(I):\n",
    "    \"\"\"prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector\"\"\"\n",
    "    I = I[35:195] # crop\n",
    "    I = I[::2,::2,0] # downsample by factor of 2\n",
    "    I[I == 144] = 0 # erase background (background type 1)\n",
    "    I[I == 109] = 0 # erase background (background type 2)\n",
    "    I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "    return I.astype(np.float).ravel()\n",
    "\n",
    "# reward discount used by Karpathy (cf. https://gist.github.com/karpathy/a4166c7fe253700972fcbc77e4ea32c5)\n",
    "def discount_rewards(r, gamma):\n",
    "    \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
    "    r = np.array(r)\n",
    "    discounted_r = np.zeros_like(r)\n",
    "    running_add = 0\n",
    "    # we go from last reward to first one so we don't have to do exponentiations\n",
    "    for t in reversed(range(0, r.size)):\n",
    "        if r[t] != 0: running_add = 0 # if the game ended (in Pong), reset the reward sum\n",
    "        running_add = running_add * gamma + r[t] # the point here is to use Horner's method to compute those rewards efficiently\n",
    "        discounted_r[t] = running_add\n",
    "    discounted_r -= np.mean(discounted_r) #normalizing the result\n",
    "    discounted_r /= np.std(discounted_r) #idem\n",
    "    return discounted_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At the end of episode 0 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1885/1885 [==============================] - 1s 368us/step - loss: -0.0017 - accuracy: 0.4966\n",
      "At the end of episode 1 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1090/1090 [==============================] - 0s 336us/step - loss: -0.0016 - accuracy: 0.5761\n",
      "At the end of episode 2 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1393/1393 [==============================] - 0s 306us/step - loss: -0.0187 - accuracy: 0.5901\n",
      "At the end of episode 3 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1355/1355 [==============================] - 0s 320us/step - loss: -0.0143 - accuracy: 0.6494\n",
      "At the end of episode 4 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1338/1338 [==============================] - 0s 310us/step - loss: 0.0080 - accuracy: 0.6487\n",
      "At the end of episode 5 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1479/1479 [==============================] - 0s 318us/step - loss: 7.0916e-04 - accuracy: 0.6430\n",
      "At the end of episode 6 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1094/1094 [==============================] - 1s 468us/step - loss: 0.0046 - accuracy: 0.6280\n",
      "At the end of episode 7 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1175/1175 [==============================] - 0s 409us/step - loss: -0.0066 - accuracy: 0.6613\n",
      "At the end of episode 8 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1165/1165 [==============================] - 0s 347us/step - loss: -0.0280 - accuracy: 0.7116\n",
      "At the end of episode 9 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1120/1120 [==============================] - 1s 463us/step - loss: 0.0208 - accuracy: 0.6982\n",
      "At the end of episode 10 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1109/1109 [==============================] - 0s 379us/step - loss: -0.0168 - accuracy: 0.7286\n",
      "At the end of episode 11 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1243/1243 [==============================] - 0s 354us/step - loss: 0.0049 - accuracy: 0.7570\n",
      "At the end of episode 12 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1104/1104 [==============================] - 0s 391us/step - loss: 0.0150 - accuracy: 0.7409\n",
      "At the end of episode 13 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1108/1108 [==============================] - 0s 428us/step - loss: -0.0310 - accuracy: 0.7653 0s - loss: -0.0267 - accuracy: 0.75\n",
      "At the end of episode 14 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1100/1100 [==============================] - 0s 432us/step - loss: 0.0059 - accuracy: 0.7791\n",
      "At the end of episode 15 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1090/1090 [==============================] - 1s 465us/step - loss: -0.0034 - accuracy: 0.7936\n",
      "At the end of episode 16 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1101/1101 [==============================] - 0s 309us/step - loss: -0.0059 - accuracy: 0.7929\n",
      "At the end of episode 17 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1107/1107 [==============================] - 0s 410us/step - loss: -0.0242 - accuracy: 0.8139\n",
      "At the end of episode 18 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1105/1105 [==============================] - 0s 293us/step - loss: 0.0262 - accuracy: 0.8009\n",
      "At the end of episode 19 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1177/1177 [==============================] - 0s 293us/step - loss: -0.0061 - accuracy: 0.8012\n",
      "At the end of episode 20 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1100/1100 [==============================] - 0s 306us/step - loss: -0.0088 - accuracy: 0.7845\n",
      "At the end of episode 21 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1359/1359 [==============================] - 0s 352us/step - loss: -0.0276 - accuracy: 0.7910\n",
      "At the end of episode 22 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1097/1097 [==============================] - 0s 313us/step - loss: -0.0074 - accuracy: 0.8113\n",
      "At the end of episode 23 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1194/1194 [==============================] - 0s 303us/step - loss: 0.0080 - accuracy: 0.8258\n",
      "At the end of episode 24 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1107/1107 [==============================] - 0s 428us/step - loss: -0.0074 - accuracy: 0.7958\n",
      "At the end of episode 25 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1083/1083 [==============================] - 0s 311us/step - loss: 0.0148 - accuracy: 0.8190\n",
      "At the end of episode 26 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1109/1109 [==============================] - 0s 298us/step - loss: 0.0230 - accuracy: 0.7935\n",
      "At the end of episode 27 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1503/1503 [==============================] - 0s 304us/step - loss: -0.0241 - accuracy: 0.8031\n",
      "At the end of episode 28 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1224/1224 [==============================] - 0s 323us/step - loss: -0.0078 - accuracy: 0.8047\n",
      "At the end of episode 29 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1097/1097 [==============================] - 0s 324us/step - loss: 0.0224 - accuracy: 0.8086\n",
      "At the end of episode 30 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1144/1144 [==============================] - 0s 418us/step - loss: 0.0239 - accuracy: 0.8042\n",
      "At the end of episode 31 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1100/1100 [==============================] - 0s 361us/step - loss: -0.0097 - accuracy: 0.8255\n",
      "At the end of episode 32 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1194/1194 [==============================] - 0s 351us/step - loss: -0.0165 - accuracy: 0.8224\n",
      "At the end of episode 33 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1088/1088 [==============================] - 0s 295us/step - loss: 3.0814e-04 - accuracy: 0.8107\n",
      "At the end of episode 34 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1114/1114 [==============================] - 0s 371us/step - loss: -0.0125 - accuracy: 0.8321\n",
      "At the end of episode 35 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1179/1179 [==============================] - 1s 435us/step - loss: -0.0191 - accuracy: 0.8346\n",
      "At the end of episode 36 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1197/1197 [==============================] - 0s 364us/step - loss: -0.0090 - accuracy: 0.8296\n",
      "At the end of episode 37 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1124/1124 [==============================] - 1s 488us/step - loss: -0.0108 - accuracy: 0.8345\n",
      "At the end of episode 38 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1292/1292 [==============================] - 0s 304us/step - loss: -0.0113 - accuracy: 0.8452\n",
      "At the end of episode 39 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1340/1340 [==============================] - 0s 287us/step - loss: -0.0066 - accuracy: 0.8388\n",
      "At the end of episode 40 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1260/1260 [==============================] - 0s 295us/step - loss: 0.0231 - accuracy: 0.8349\n",
      "At the end of episode 41 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1100/1100 [==============================] - 0s 328us/step - loss: -0.0029 - accuracy: 0.8345\n",
      "At the end of episode 42 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1424/1424 [==============================] - 1s 510us/step - loss: 0.0148 - accuracy: 0.8385\n",
      "At the end of episode 43 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1599/1599 [==============================] - 1s 313us/step - loss: 0.0221 - accuracy: 0.8293\n",
      "At the end of episode 44 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1018/1018 [==============================] - 0s 444us/step - loss: 0.0020 - accuracy: 0.7957\n",
      "At the end of episode 45 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 1s 446us/step - loss: -0.0020 - accuracy: 0.7908\n",
      "At the end of episode 46 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1401/1401 [==============================] - 0s 276us/step - loss: 0.0340 - accuracy: 0.8258\n",
      "At the end of episode 47 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1479/1479 [==============================] - 0s 279us/step - loss: -0.0134 - accuracy: 0.8039\n",
      "At the end of episode 48 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1511/1511 [==============================] - 0s 298us/step - loss: -0.0039 - accuracy: 0.8193\n",
      "At the end of episode 49 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1414/1414 [==============================] - 0s 314us/step - loss: 0.0200 - accuracy: 0.8409\n",
      "At the end of episode 50 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1524/1524 [==============================] - 0s 317us/step - loss: 0.0304 - accuracy: 0.8406\n",
      "At the end of episode 51 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1253/1253 [==============================] - 0s 289us/step - loss: 0.0059 - accuracy: 0.8117\n",
      "At the end of episode 52 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1565/1565 [==============================] - 0s 272us/step - loss: -0.0115 - accuracy: 0.8300\n",
      "At the end of episode 53 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1726/1726 [==============================] - 1s 299us/step - loss: 0.0186 - accuracy: 0.8355\n",
      "At the end of episode 54 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1320/1320 [==============================] - 0s 290us/step - loss: -0.0056 - accuracy: 0.8280\n",
      "At the end of episode 55 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1421/1421 [==============================] - 0s 333us/step - loss: -0.0095 - accuracy: 0.7868\n",
      "At the end of episode 56 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1548/1548 [==============================] - 0s 283us/step - loss: 0.0347 - accuracy: 0.8275\n",
      "At the end of episode 57 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1408/1408 [==============================] - 0s 313us/step - loss: 0.0444 - accuracy: 0.8395\n",
      "At the end of episode 58 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1173/1173 [==============================] - 0s 351us/step - loss: 0.0100 - accuracy: 0.8193\n",
      "At the end of episode 59 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1103/1103 [==============================] - 1s 482us/step - loss: 0.0335 - accuracy: 0.8277\n",
      "At the end of episode 60 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1310/1310 [==============================] - 0s 318us/step - loss: 0.0118 - accuracy: 0.8305\n",
      "At the end of episode 61 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1577/1577 [==============================] - 0s 291us/step - loss: -0.0025 - accuracy: 0.8383\n",
      "At the end of episode 62 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2159/2159 [==============================] - 1s 499us/step - loss: -0.0088 - accuracy: 0.8231\n",
      "At the end of episode 63 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1628/1628 [==============================] - 1s 348us/step - loss: 0.0093 - accuracy: 0.8366\n",
      "At the end of episode 64 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1273/1273 [==============================] - 0s 318us/step - loss: -0.0029 - accuracy: 0.8272\n",
      "At the end of episode 65 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1185/1185 [==============================] - 0s 303us/step - loss: 0.0043 - accuracy: 0.8219\n",
      "At the end of episode 66 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1330/1330 [==============================] - 0s 345us/step - loss: 3.5659e-04 - accuracy: 0.8301\n",
      "At the end of episode 67 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1353/1353 [==============================] - 0s 300us/step - loss: 0.0076 - accuracy: 0.8514\n",
      "At the end of episode 68 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1234/1234 [==============================] - 0s 327us/step - loss: -0.0013 - accuracy: 0.8476\n",
      "At the end of episode 69 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1220/1220 [==============================] - 0s 321us/step - loss: 0.0370 - accuracy: 0.8385\n",
      "At the end of episode 70 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1264/1264 [==============================] - 1s 409us/step - loss: -0.0025 - accuracy: 0.8608\n",
      "At the end of episode 71 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1112/1112 [==============================] - 0s 298us/step - loss: 0.0170 - accuracy: 0.8291\n",
      "At the end of episode 72 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1089/1089 [==============================] - 0s 288us/step - loss: -0.0272 - accuracy: 0.8430\n",
      "At the end of episode 73 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1112/1112 [==============================] - 0s 289us/step - loss: 0.0220 - accuracy: 0.8534\n",
      "At the end of episode 74 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1088/1088 [==============================] - 0s 303us/step - loss: -0.0129 - accuracy: 0.8676\n",
      "At the end of episode 75 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1187/1187 [==============================] - 1s 539us/step - loss: 0.0036 - accuracy: 0.8703\n",
      "At the end of episode 76 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1254/1254 [==============================] - 1s 414us/step - loss: -0.0126 - accuracy: 0.8581\n",
      "At the end of episode 77 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1332/1332 [==============================] - 1s 472us/step - loss: 0.0099 - accuracy: 0.8851\n",
      "At the end of episode 78 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1596/1596 [==============================] - 1s 317us/step - loss: -0.0085 - accuracy: 0.8640\n",
      "At the end of episode 79 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1348/1348 [==============================] - 0s 322us/step - loss: -0.0219 - accuracy: 0.8783\n",
      "At the end of episode 80 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1102/1102 [==============================] - 0s 316us/step - loss: -0.0045 - accuracy: 0.8838\n",
      "At the end of episode 81 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1108/1108 [==============================] - 0s 307us/step - loss: 0.0141 - accuracy: 0.8782\n",
      "At the end of episode 82 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1349/1349 [==============================] - 0s 316us/step - loss: 0.0157 - accuracy: 0.8643\n",
      "At the end of episode 83 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1103/1103 [==============================] - 0s 333us/step - loss: 0.0028 - accuracy: 0.8794\n",
      "At the end of episode 84 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1260/1260 [==============================] - 0s 353us/step - loss: 0.0181 - accuracy: 0.8571\n",
      "At the end of episode 85 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1553/1553 [==============================] - 1s 326us/step - loss: 0.0099 - accuracy: 0.8757\n",
      "At the end of episode 86 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1511/1511 [==============================] - 0s 310us/step - loss: -4.6887e-04 - accuracy: 0.8782\n",
      "At the end of episode 87 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1413/1413 [==============================] - 0s 349us/step - loss: 0.0097 - accuracy: 0.8903\n",
      "At the end of episode 88 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1106/1106 [==============================] - 0s 316us/step - loss: 0.0376 - accuracy: 0.8834\n",
      "At the end of episode 89 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1313/1313 [==============================] - 0s 326us/step - loss: 0.0253 - accuracy: 0.8880\n",
      "At the end of episode 90 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1476/1476 [==============================] - 0s 301us/step - loss: 0.0192 - accuracy: 0.8801\n",
      "At the end of episode 91 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1904/1904 [==============================] - 1s 312us/step - loss: 0.0089 - accuracy: 0.8787\n",
      "At the end of episode 92 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1499/1499 [==============================] - 0s 331us/step - loss: 0.0154 - accuracy: 0.8926\n",
      "At the end of episode 93 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1671/1671 [==============================] - 1s 316us/step - loss: -0.0050 - accuracy: 0.8731\n",
      "At the end of episode 94 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1621/1621 [==============================] - 1s 325us/step - loss: 0.0226 - accuracy: 0.8803\n",
      "At the end of episode 95 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1344/1344 [==============================] - 1s 376us/step - loss: 0.0280 - accuracy: 0.8720\n",
      "At the end of episode 96 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1666/1666 [==============================] - 1s 302us/step - loss: -0.0038 - accuracy: 0.8896\n",
      "At the end of episode 97 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1611/1611 [==============================] - 1s 312us/step - loss: 0.0381 - accuracy: 0.8721\n",
      "At the end of episode 98 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1712/1712 [==============================] - 1s 319us/step - loss: 0.0010 - accuracy: 0.8832\n",
      "At the end of episode 99 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1386/1386 [==============================] - 0s 328us/step - loss: -0.0183 - accuracy: 0.8838\n",
      "At the end of episode 100 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1827/1827 [==============================] - 1s 311us/step - loss: 0.0149 - accuracy: 0.8878\n",
      "At the end of episode 101 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1384/1384 [==============================] - 0s 317us/step - loss: 0.0135 - accuracy: 0.8851\n",
      "At the end of episode 102 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1822/1822 [==============================] - 1s 352us/step - loss: 0.0100 - accuracy: 0.8793\n",
      "At the end of episode 103 the total reward was : -19.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1678/1678 [==============================] - 1s 415us/step - loss: 0.0037 - accuracy: 0.8814\n",
      "At the end of episode 104 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1515/1515 [==============================] - 1s 340us/step - loss: -0.0153 - accuracy: 0.8772\n",
      "At the end of episode 105 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1702/1702 [==============================] - 1s 341us/step - loss: 0.0097 - accuracy: 0.9001\n",
      "At the end of episode 106 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1583/1583 [==============================] - 1s 319us/step - loss: -0.0034 - accuracy: 0.8800\n",
      "At the end of episode 107 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1468/1468 [==============================] - 1s 417us/step - loss: 0.0153 - accuracy: 0.8842\n",
      "At the end of episode 108 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1888/1888 [==============================] - 1s 440us/step - loss: -0.0043 - accuracy: 0.9094\n",
      "At the end of episode 109 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1585/1585 [==============================] - 1s 560us/step - loss: 0.0034 - accuracy: 0.8845\n",
      "At the end of episode 110 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1598/1598 [==============================] - 1s 315us/step - loss: 0.0262 - accuracy: 0.8930\n",
      "At the end of episode 111 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1260/1260 [==============================] - 0s 370us/step - loss: 0.0342 - accuracy: 0.8730\n",
      "At the end of episode 112 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1773/1773 [==============================] - 1s 299us/step - loss: 0.0190 - accuracy: 0.8883\n",
      "At the end of episode 113 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1265/1265 [==============================] - 0s 300us/step - loss: 0.0067 - accuracy: 0.8877\n",
      "At the end of episode 114 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1972/1972 [==============================] - 1s 310us/step - loss: 0.0347 - accuracy: 0.8702\n",
      "At the end of episode 115 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1494/1494 [==============================] - 0s 309us/step - loss: -0.0153 - accuracy: 0.8869\n",
      "At the end of episode 116 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1304/1304 [==============================] - 0s 360us/step - loss: 0.0085 - accuracy: 0.8834\n",
      "At the end of episode 117 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1337/1337 [==============================] - 0s 315us/step - loss: 0.0173 - accuracy: 0.8915\n",
      "At the end of episode 118 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1561/1561 [==============================] - 0s 318us/step - loss: 0.0132 - accuracy: 0.8751\n",
      "At the end of episode 119 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1343/1343 [==============================] - 0s 318us/step - loss: 0.0314 - accuracy: 0.8712\n",
      "At the end of episode 120 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1729/1729 [==============================] - 1s 318us/step - loss: -0.0109 - accuracy: 0.8936\n",
      "At the end of episode 121 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "1782/1782 [==============================] - 1s 304us/step - loss: 0.0105 - accuracy: 0.8967\n",
      "At the end of episode 122 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "1932/1932 [==============================] - 1s 309us/step - loss: -0.0083 - accuracy: 0.8970\n",
      "At the end of episode 123 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1460/1460 [==============================] - 0s 321us/step - loss: -0.0069 - accuracy: 0.9014\n",
      "At the end of episode 124 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1805/1805 [==============================] - 1s 304us/step - loss: 0.0049 - accuracy: 0.9058\n",
      "At the end of episode 125 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1807/1807 [==============================] - 1s 300us/step - loss: -0.0023 - accuracy: 0.9009\n",
      "At the end of episode 126 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1793/1793 [==============================] - 1s 304us/step - loss: 0.0022 - accuracy: 0.8918\n",
      "At the end of episode 127 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1183/1183 [==============================] - 0s 318us/step - loss: 0.0136 - accuracy: 0.8918\n",
      "At the end of episode 128 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1259/1259 [==============================] - 0s 325us/step - loss: -0.0258 - accuracy: 0.8912\n",
      "At the end of episode 129 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1524/1524 [==============================] - 0s 317us/step - loss: -0.0058 - accuracy: 0.8825\n",
      "At the end of episode 130 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1097/1097 [==============================] - 0s 321us/step - loss: 0.0260 - accuracy: 0.8933\n",
      "At the end of episode 131 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1260/1260 [==============================] - 0s 308us/step - loss: -0.0181 - accuracy: 0.8992\n",
      "At the end of episode 132 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1476/1476 [==============================] - 0s 317us/step - loss: -8.6423e-04 - accuracy: 0.8977\n",
      "At the end of episode 133 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1475/1475 [==============================] - 0s 321us/step - loss: -0.0187 - accuracy: 0.8875\n",
      "At the end of episode 134 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1090/1090 [==============================] - 0s 318us/step - loss: 0.0148 - accuracy: 0.9147\n",
      "At the end of episode 135 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1554/1554 [==============================] - 0s 320us/step - loss: 0.0028 - accuracy: 0.9035\n",
      "At the end of episode 136 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1489/1489 [==============================] - 0s 314us/step - loss: -0.0093 - accuracy: 0.9066\n",
      "At the end of episode 137 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1796/1796 [==============================] - 1s 300us/step - loss: -0.0026 - accuracy: 0.9109\n",
      "At the end of episode 138 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1104/1104 [==============================] - 0s 306us/step - loss: 0.0330 - accuracy: 0.9004\n",
      "At the end of episode 139 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1031/1031 [==============================] - 0s 335us/step - loss: 0.0026 - accuracy: 0.9001\n",
      "At the end of episode 140 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1169/1169 [==============================] - 0s 355us/step - loss: 0.0159 - accuracy: 0.8905\n",
      "At the end of episode 141 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1011/1011 [==============================] - 0s 323us/step - loss: 0.0204 - accuracy: 0.8991\n",
      "At the end of episode 142 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1520/1520 [==============================] - 0s 306us/step - loss: 0.0035 - accuracy: 0.8816\n",
      "At the end of episode 143 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1016/1016 [==============================] - 0s 302us/step - loss: -0.0196 - accuracy: 0.8711\n",
      "At the end of episode 144 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1005/1005 [==============================] - 0s 291us/step - loss: 0.0202 - accuracy: 0.8905\n",
      "At the end of episode 145 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1123/1123 [==============================] - 0s 300us/step - loss: 0.0015 - accuracy: 0.8825\n",
      "At the end of episode 146 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1017/1017 [==============================] - 0s 295us/step - loss: -0.0169 - accuracy: 0.8997\n",
      "At the end of episode 147 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1037/1037 [==============================] - 0s 297us/step - loss: -0.0137 - accuracy: 0.8968\n",
      "At the end of episode 148 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1034/1034 [==============================] - 0s 292us/step - loss: -0.0054 - accuracy: 0.8975\n",
      "At the end of episode 149 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1025/1025 [==============================] - 0s 303us/step - loss: 0.0215 - accuracy: 0.8937\n",
      "At the end of episode 150 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1015/1015 [==============================] - 0s 300us/step - loss: 0.0257 - accuracy: 0.8887\n",
      "At the end of episode 151 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1028/1028 [==============================] - 0s 291us/step - loss: 0.0338 - accuracy: 0.8823\n",
      "At the end of episode 152 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1193/1193 [==============================] - 0s 296us/step - loss: -0.0236 - accuracy: 0.8894\n",
      "At the end of episode 153 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1019/1019 [==============================] - 0s 341us/step - loss: 0.0018 - accuracy: 0.8960\n",
      "At the end of episode 154 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1187/1187 [==============================] - 0s 296us/step - loss: -0.0215 - accuracy: 0.8955\n",
      "At the end of episode 155 the total reward was : -19.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1617/1617 [==============================] - 0s 293us/step - loss: 0.0011 - accuracy: 0.9041\n",
      "At the end of episode 156 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1032/1032 [==============================] - 0s 292us/step - loss: 0.0223 - accuracy: 0.9070\n",
      "At the end of episode 157 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1096/1096 [==============================] - 0s 301us/step - loss: 0.0023 - accuracy: 0.9033\n",
      "At the end of episode 158 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1695/1695 [==============================] - 0s 278us/step - loss: 0.0125 - accuracy: 0.9156\n",
      "At the end of episode 159 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1191/1191 [==============================] - 0s 300us/step - loss: 0.0086 - accuracy: 0.9118\n",
      "At the end of episode 160 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1027/1027 [==============================] - 0s 298us/step - loss: 0.0391 - accuracy: 0.8880\n",
      "At the end of episode 161 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1119/1119 [==============================] - 0s 297us/step - loss: 0.0092 - accuracy: 0.9080\n",
      "At the end of episode 162 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1016/1016 [==============================] - 0s 288us/step - loss: -0.0187 - accuracy: 0.8917\n",
      "At the end of episode 163 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1021/1021 [==============================] - 0s 300us/step - loss: -0.0063 - accuracy: 0.8923\n",
      "At the end of episode 164 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1020/1020 [==============================] - 0s 285us/step - loss: 0.0119 - accuracy: 0.9049\n",
      "At the end of episode 165 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1230/1230 [==============================] - 0s 299us/step - loss: 0.0269 - accuracy: 0.8911\n",
      "At the end of episode 166 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1026/1026 [==============================] - 0s 292us/step - loss: -0.0070 - accuracy: 0.8957\n",
      "At the end of episode 167 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1016/1016 [==============================] - 0s 286us/step - loss: 0.0128 - accuracy: 0.8868\n",
      "At the end of episode 168 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1014/1014 [==============================] - 0s 280us/step - loss: 0.0056 - accuracy: 0.9063\n",
      "At the end of episode 169 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1019/1019 [==============================] - 0s 305us/step - loss: 0.0381 - accuracy: 0.8881\n",
      "At the end of episode 170 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1009/1009 [==============================] - 0s 344us/step - loss: -0.0087 - accuracy: 0.8940\n",
      "At the end of episode 171 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1029/1029 [==============================] - 0s 335us/step - loss: 0.0104 - accuracy: 0.8805\n",
      "At the end of episode 172 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1008/1008 [==============================] - 0s 281us/step - loss: -0.0096 - accuracy: 0.8919\n",
      "At the end of episode 173 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1100/1100 [==============================] - 0s 281us/step - loss: 0.0198 - accuracy: 0.9045\n",
      "At the end of episode 174 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1024/1024 [==============================] - 0s 277us/step - loss: 0.0186 - accuracy: 0.8926\n",
      "At the end of episode 175 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1014/1014 [==============================] - 0s 291us/step - loss: 0.0022 - accuracy: 0.8994\n",
      "At the end of episode 176 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1025/1025 [==============================] - 0s 286us/step - loss: 0.0173 - accuracy: 0.9024\n",
      "At the end of episode 177 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1008/1008 [==============================] - 0s 289us/step - loss: 0.0234 - accuracy: 0.9058\n",
      "At the end of episode 178 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1005/1005 [==============================] - 0s 271us/step - loss: 0.0104 - accuracy: 0.9075\n",
      "At the end of episode 179 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1099/1099 [==============================] - 0s 295us/step - loss: 0.0041 - accuracy: 0.9081\n",
      "At the end of episode 180 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1011/1011 [==============================] - 0s 285us/step - loss: 0.0039 - accuracy: 0.9001\n",
      "At the end of episode 181 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1170/1170 [==============================] - 0s 284us/step - loss: -0.0076 - accuracy: 0.8991\n",
      "At the end of episode 182 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1515/1515 [==============================] - 0s 282us/step - loss: 0.0239 - accuracy: 0.8964\n",
      "At the end of episode 183 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1314/1314 [==============================] - 0s 286us/step - loss: 0.0152 - accuracy: 0.9140\n",
      "At the end of episode 184 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1181/1181 [==============================] - 0s 287us/step - loss: 0.0179 - accuracy: 0.9111\n",
      "At the end of episode 185 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1543/1543 [==============================] - 0s 279us/step - loss: 0.0240 - accuracy: 0.9093\n",
      "At the end of episode 186 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1263/1263 [==============================] - 0s 287us/step - loss: 0.0116 - accuracy: 0.9105\n",
      "At the end of episode 187 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2075/2075 [==============================] - 1s 272us/step - loss: -0.0052 - accuracy: 0.9002\n",
      "At the end of episode 188 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1907/1907 [==============================] - 1s 272us/step - loss: -0.0015 - accuracy: 0.9046\n",
      "At the end of episode 189 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2014/2014 [==============================] - 1s 281us/step - loss: 0.0037 - accuracy: 0.9161\n",
      "At the end of episode 190 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2035/2035 [==============================] - 1s 279us/step - loss: -0.0025 - accuracy: 0.9130\n",
      "At the end of episode 191 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1351/1351 [==============================] - 0s 292us/step - loss: 0.0032 - accuracy: 0.9215\n",
      "At the end of episode 192 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1303/1303 [==============================] - 0s 282us/step - loss: -5.4234e-04 - accuracy: 0.9133\n",
      "At the end of episode 193 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1442/1442 [==============================] - 0s 288us/step - loss: 0.0038 - accuracy: 0.8994\n",
      "At the end of episode 194 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1450/1450 [==============================] - 0s 306us/step - loss: 0.0309 - accuracy: 0.9028\n",
      "At the end of episode 195 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1431/1431 [==============================] - 0s 283us/step - loss: -0.0028 - accuracy: 0.9357\n",
      "At the end of episode 196 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1317/1317 [==============================] - 0s 280us/step - loss: -0.0139 - accuracy: 0.9256\n",
      "At the end of episode 197 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1620/1620 [==============================] - 0s 278us/step - loss: 0.0142 - accuracy: 0.9333\n",
      "At the end of episode 198 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2087/2087 [==============================] - 1s 274us/step - loss: 0.0162 - accuracy: 0.9300\n",
      "At the end of episode 199 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1353/1353 [==============================] - 0s 288us/step - loss: 0.0048 - accuracy: 0.9069\n",
      "At the end of episode 200 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1304/1304 [==============================] - 0s 287us/step - loss: 0.0182 - accuracy: 0.9172\n",
      "At the end of episode 201 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1171/1171 [==============================] - 0s 291us/step - loss: 0.0252 - accuracy: 0.9026\n",
      "At the end of episode 202 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1669/1669 [==============================] - 0s 278us/step - loss: 0.0227 - accuracy: 0.9239\n",
      "At the end of episode 203 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1266/1266 [==============================] - 0s 284us/step - loss: 0.0082 - accuracy: 0.9179\n",
      "At the end of episode 204 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 0s 285us/step - loss: 0.0148 - accuracy: 0.9197\n",
      "At the end of episode 205 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1347/1347 [==============================] - 0s 288us/step - loss: 0.0174 - accuracy: 0.8946\n",
      "At the end of episode 206 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1090/1090 [==============================] - 0s 300us/step - loss: 0.0339 - accuracy: 0.9055\n",
      "At the end of episode 207 the total reward was : -21.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1672/1672 [==============================] - 0s 283us/step - loss: 0.0031 - accuracy: 0.9079\n",
      "At the end of episode 208 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1382/1382 [==============================] - 0s 283us/step - loss: 0.0259 - accuracy: 0.8980\n",
      "At the end of episode 209 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1539/1539 [==============================] - 0s 288us/step - loss: 0.0185 - accuracy: 0.9084\n",
      "At the end of episode 210 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2311/2311 [==============================] - 1s 276us/step - loss: -0.0031 - accuracy: 0.9195\n",
      "At the end of episode 211 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1222/1222 [==============================] - 0s 294us/step - loss: 0.0276 - accuracy: 0.9059\n",
      "At the end of episode 212 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1944/1944 [==============================] - 1s 283us/step - loss: 0.0162 - accuracy: 0.9033\n",
      "At the end of episode 213 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2195/2195 [==============================] - 1s 283us/step - loss: 0.0083 - accuracy: 0.9043\n",
      "At the end of episode 214 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1758/1758 [==============================] - 0s 276us/step - loss: -0.0100 - accuracy: 0.9198\n",
      "At the end of episode 215 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1851/1851 [==============================] - 1s 285us/step - loss: -0.0082 - accuracy: 0.9195\n",
      "At the end of episode 216 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1875/1875 [==============================] - 1s 275us/step - loss: -0.0067 - accuracy: 0.9216\n",
      "At the end of episode 217 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1591/1591 [==============================] - 0s 266us/step - loss: 0.0183 - accuracy: 0.9145\n",
      "At the end of episode 218 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1660/1660 [==============================] - 0s 276us/step - loss: 0.0200 - accuracy: 0.9199\n",
      "At the end of episode 219 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1909/1909 [==============================] - 1s 278us/step - loss: -0.0031 - accuracy: 0.9068\n",
      "At the end of episode 220 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2071/2071 [==============================] - 1s 285us/step - loss: 0.0099 - accuracy: 0.9107\n",
      "At the end of episode 221 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2436/2436 [==============================] - 1s 280us/step - loss: 0.0122 - accuracy: 0.9232\n",
      "At the end of episode 222 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2022/2022 [==============================] - 1s 284us/step - loss: -0.0017 - accuracy: 0.9174\n",
      "At the end of episode 223 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1598/1598 [==============================] - 0s 296us/step - loss: 0.0114 - accuracy: 0.9161\n",
      "At the end of episode 224 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2238/2238 [==============================] - 1s 301us/step - loss: 0.0012 - accuracy: 0.9191\n",
      "At the end of episode 225 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1475/1475 [==============================] - 0s 312us/step - loss: 0.0186 - accuracy: 0.8976\n",
      "At the end of episode 226 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2082/2082 [==============================] - 1s 277us/step - loss: 0.0011 - accuracy: 0.9304\n",
      "At the end of episode 227 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1759/1759 [==============================] - 0s 277us/step - loss: 0.0169 - accuracy: 0.9306\n",
      "At the end of episode 228 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1632/1632 [==============================] - 0s 280us/step - loss: 0.0062 - accuracy: 0.9289\n",
      "At the end of episode 229 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1715/1715 [==============================] - 1s 417us/step - loss: 0.0066 - accuracy: 0.9219\n",
      "At the end of episode 230 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1936/1936 [==============================] - 1s 301us/step - loss: 0.0069 - accuracy: 0.9277\n",
      "At the end of episode 231 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2312/2312 [==============================] - 1s 323us/step - loss: -0.0160 - accuracy: 0.9291\n",
      "At the end of episode 232 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1747/1747 [==============================] - 1s 312us/step - loss: -0.0165 - accuracy: 0.9193\n",
      "At the end of episode 233 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1619/1619 [==============================] - 0s 282us/step - loss: 0.0128 - accuracy: 0.9364\n",
      "At the end of episode 234 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1839/1839 [==============================] - 1s 299us/step - loss: -0.0024 - accuracy: 0.9347\n",
      "At the end of episode 235 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1553/1553 [==============================] - 0s 288us/step - loss: -0.0063 - accuracy: 0.9208\n",
      "At the end of episode 236 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1466/1466 [==============================] - 1s 343us/step - loss: 0.0147 - accuracy: 0.9236\n",
      "At the end of episode 237 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1400/1400 [==============================] - 0s 338us/step - loss: 0.0047 - accuracy: 0.9286\n",
      "At the end of episode 238 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1336/1336 [==============================] - 0s 289us/step - loss: 0.0047 - accuracy: 0.9207\n",
      "At the end of episode 239 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1497/1497 [==============================] - 0s 289us/step - loss: -0.0036 - accuracy: 0.9265\n",
      "At the end of episode 240 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 1s 283us/step - loss: 0.0197 - accuracy: 0.9144\n",
      "At the end of episode 241 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1632/1632 [==============================] - 0s 301us/step - loss: 0.0082 - accuracy: 0.9350\n",
      "At the end of episode 242 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1594/1594 [==============================] - 0s 278us/step - loss: 0.0099 - accuracy: 0.9241\n",
      "At the end of episode 243 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 1s 299us/step - loss: 0.0214 - accuracy: 0.9196\n",
      "At the end of episode 244 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1351/1351 [==============================] - 0s 297us/step - loss: 0.0022 - accuracy: 0.9260\n",
      "At the end of episode 245 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1618/1618 [==============================] - 0s 298us/step - loss: -0.0229 - accuracy: 0.9258\n",
      "At the end of episode 246 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2257/2257 [==============================] - 1s 296us/step - loss: -0.0154 - accuracy: 0.9233\n",
      "At the end of episode 247 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2191/2191 [==============================] - 1s 283us/step - loss: 0.0102 - accuracy: 0.9238\n",
      "At the end of episode 248 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2117/2117 [==============================] - 1s 283us/step - loss: -0.0097 - accuracy: 0.9249\n",
      "At the end of episode 249 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1685/1685 [==============================] - 0s 293us/step - loss: -0.0035 - accuracy: 0.9270\n",
      "At the end of episode 250 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1746/1746 [==============================] - 1s 297us/step - loss: 0.0023 - accuracy: 0.9233\n",
      "At the end of episode 251 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2215/2215 [==============================] - 1s 296us/step - loss: -0.0014 - accuracy: 0.9237\n",
      "At the end of episode 252 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2220/2220 [==============================] - 1s 283us/step - loss: -0.0073 - accuracy: 0.9176\n",
      "At the end of episode 253 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1800/1800 [==============================] - 1s 294us/step - loss: -0.0029 - accuracy: 0.9378\n",
      "At the end of episode 254 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1662/1662 [==============================] - 0s 285us/step - loss: 0.0140 - accuracy: 0.9362\n",
      "At the end of episode 255 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2298/2298 [==============================] - 1s 279us/step - loss: -0.0105 - accuracy: 0.9269\n",
      "At the end of episode 256 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1493/1493 [==============================] - 0s 282us/step - loss: 0.0213 - accuracy: 0.9344\n",
      "At the end of episode 257 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2262/2262 [==============================] - 1s 281us/step - loss: -0.0041 - accuracy: 0.9355\n",
      "At the end of episode 258 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2520/2520 [==============================] - 1s 296us/step - loss: -0.0104 - accuracy: 0.9317\n",
      "At the end of episode 259 the total reward was : -15.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2108/2108 [==============================] - 1s 317us/step - loss: -0.0082 - accuracy: 0.9274\n",
      "At the end of episode 260 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1821/1821 [==============================] - 1s 277us/step - loss: -0.0122 - accuracy: 0.9341\n",
      "At the end of episode 261 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2046/2046 [==============================] - 1s 297us/step - loss: -0.0116 - accuracy: 0.9413\n",
      "At the end of episode 262 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2383/2383 [==============================] - 1s 282us/step - loss: -0.0187 - accuracy: 0.9358\n",
      "At the end of episode 263 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2286/2286 [==============================] - 1s 282us/step - loss: 0.0065 - accuracy: 0.9501\n",
      "At the end of episode 264 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1967/1967 [==============================] - 1s 285us/step - loss: 0.0066 - accuracy: 0.9471\n",
      "At the end of episode 265 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1833/1833 [==============================] - 1s 296us/step - loss: -0.0085 - accuracy: 0.9427\n",
      "At the end of episode 266 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2138/2138 [==============================] - 1s 291us/step - loss: -0.0025 - accuracy: 0.9453\n",
      "At the end of episode 267 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2682/2682 [==============================] - 1s 276us/step - loss: 0.0040 - accuracy: 0.9485\n",
      "At the end of episode 268 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1666/1666 [==============================] - 0s 295us/step - loss: -0.0099 - accuracy: 0.9232\n",
      "At the end of episode 269 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1749/1749 [==============================] - 1s 298us/step - loss: 0.0078 - accuracy: 0.9451\n",
      "At the end of episode 270 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2296/2296 [==============================] - 1s 282us/step - loss: -0.0059 - accuracy: 0.9425\n",
      "At the end of episode 271 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1259/1259 [==============================] - 0s 298us/step - loss: 0.0231 - accuracy: 0.9365\n",
      "At the end of episode 272 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1571/1571 [==============================] - 0s 291us/step - loss: 0.0092 - accuracy: 0.9504\n",
      "At the end of episode 273 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2080/2080 [==============================] - 1s 277us/step - loss: 0.0076 - accuracy: 0.9466\n",
      "At the end of episode 274 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1686/1686 [==============================] - 0s 289us/step - loss: -0.0069 - accuracy: 0.9318\n",
      "At the end of episode 275 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1840/1840 [==============================] - 1s 302us/step - loss: 1.7995e-04 - accuracy: 0.9473\n",
      "At the end of episode 276 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2290/2290 [==============================] - 1s 281us/step - loss: -0.0051 - accuracy: 0.9358\n",
      "At the end of episode 277 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1986/1986 [==============================] - 1s 281us/step - loss: 0.0094 - accuracy: 0.9436\n",
      "At the end of episode 278 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2642/2642 [==============================] - 1s 281us/step - loss: 0.0027 - accuracy: 0.9296\n",
      "At the end of episode 279 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1594/1594 [==============================] - 0s 298us/step - loss: 0.0045 - accuracy: 0.9398\n",
      "At the end of episode 280 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1886/1886 [==============================] - 1s 290us/step - loss: 0.0167 - accuracy: 0.9411\n",
      "At the end of episode 281 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1892/1892 [==============================] - 1s 297us/step - loss: -0.0153 - accuracy: 0.9466\n",
      "At the end of episode 282 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2019/2019 [==============================] - 1s 293us/step - loss: 0.0091 - accuracy: 0.9470\n",
      "At the end of episode 283 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2104/2104 [==============================] - 1s 298us/step - loss: 0.0013 - accuracy: 0.9463\n",
      "At the end of episode 284 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2032/2032 [==============================] - 1s 288us/step - loss: 0.0085 - accuracy: 0.9552\n",
      "At the end of episode 285 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2285/2285 [==============================] - 1s 289us/step - loss: 5.3300e-04 - accuracy: 0.9484\n",
      "At the end of episode 286 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1928/1928 [==============================] - 1s 305us/step - loss: 0.0076 - accuracy: 0.9435\n",
      "At the end of episode 287 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2132/2132 [==============================] - 1s 299us/step - loss: -0.0041 - accuracy: 0.9493\n",
      "At the end of episode 288 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2377/2377 [==============================] - 1s 287us/step - loss: -0.0023 - accuracy: 0.9483\n",
      "At the end of episode 289 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1782/1782 [==============================] - 1s 297us/step - loss: 0.0012 - accuracy: 0.9450\n",
      "At the end of episode 290 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2184/2184 [==============================] - 1s 299us/step - loss: 0.0125 - accuracy: 0.9432\n",
      "At the end of episode 291 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1713/1713 [==============================] - 1s 292us/step - loss: 0.0032 - accuracy: 0.9545\n",
      "At the end of episode 292 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2137/2137 [==============================] - 1s 282us/step - loss: -0.0011 - accuracy: 0.9518\n",
      "At the end of episode 293 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2335/2335 [==============================] - 1s 308us/step - loss: 0.0062 - accuracy: 0.9512\n",
      "At the end of episode 294 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1964/1964 [==============================] - 1s 281us/step - loss: 0.0072 - accuracy: 0.9516\n",
      "At the end of episode 295 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1769/1769 [==============================] - 1s 299us/step - loss: -0.0076 - accuracy: 0.9486\n",
      "At the end of episode 296 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2369/2369 [==============================] - 1s 297us/step - loss: -0.0018 - accuracy: 0.9409\n",
      "At the end of episode 297 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1618/1618 [==============================] - 0s 291us/step - loss: 0.0193 - accuracy: 0.9345\n",
      "At the end of episode 298 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1549/1549 [==============================] - 0s 299us/step - loss: 0.0225 - accuracy: 0.9458\n",
      "At the end of episode 299 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2377/2377 [==============================] - 1s 287us/step - loss: -0.0058 - accuracy: 0.9411\n",
      "At the end of episode 300 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2204/2204 [==============================] - 1s 280us/step - loss: 0.0135 - accuracy: 0.9560\n",
      "At the end of episode 301 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 1s 275us/step - loss: 8.5342e-04 - accuracy: 0.9508\n",
      "At the end of episode 302 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2284/2284 [==============================] - 1s 292us/step - loss: 6.0325e-04 - accuracy: 0.9470\n",
      "At the end of episode 303 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1686/1686 [==============================] - 0s 296us/step - loss: -0.0069 - accuracy: 0.9508\n",
      "At the end of episode 304 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1900/1900 [==============================] - 1s 279us/step - loss: -0.0039 - accuracy: 0.9553\n",
      "At the end of episode 305 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2834/2834 [==============================] - 1s 279us/step - loss: 0.0143 - accuracy: 0.9591\n",
      "At the end of episode 306 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1980/1980 [==============================] - 1s 288us/step - loss: 0.0224 - accuracy: 0.9530\n",
      "At the end of episode 307 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2175/2175 [==============================] - 1s 278us/step - loss: -3.0029e-04 - accuracy: 0.9614\n",
      "At the end of episode 308 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2121/2121 [==============================] - 1s 280us/step - loss: 0.0184 - accuracy: 0.9505\n",
      "At the end of episode 309 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1893/1893 [==============================] - 1s 294us/step - loss: 0.0112 - accuracy: 0.9519\n",
      "At the end of episode 310 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 1s 289us/step - loss: -0.0065 - accuracy: 0.9587\n",
      "At the end of episode 311 the total reward was : -20.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1970/1970 [==============================] - 1s 324us/step - loss: -0.0106 - accuracy: 0.9574\n",
      "At the end of episode 312 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 1s 287us/step - loss: -0.0027 - accuracy: 0.9492\n",
      "At the end of episode 313 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1830/1830 [==============================] - 1s 292us/step - loss: -0.0124 - accuracy: 0.9508\n",
      "At the end of episode 314 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2520/2520 [==============================] - 1s 292us/step - loss: -0.0111 - accuracy: 0.9571\n",
      "At the end of episode 315 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2131/2131 [==============================] - 1s 298us/step - loss: -0.0022 - accuracy: 0.9611\n",
      "At the end of episode 316 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1743/1743 [==============================] - 1s 295us/step - loss: 0.0019 - accuracy: 0.9530\n",
      "At the end of episode 317 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1916/1916 [==============================] - 1s 303us/step - loss: 0.0016 - accuracy: 0.9588\n",
      "At the end of episode 318 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1845/1845 [==============================] - 1s 280us/step - loss: 0.0086 - accuracy: 0.9588\n",
      "At the end of episode 319 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1495/1495 [==============================] - 0s 288us/step - loss: 0.0214 - accuracy: 0.9478\n",
      "At the end of episode 320 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 1s 278us/step - loss: 0.0106 - accuracy: 0.9612\n",
      "At the end of episode 321 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 1s 275us/step - loss: -0.0077 - accuracy: 0.9533\n",
      "At the end of episode 322 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1973/1973 [==============================] - 1s 292us/step - loss: 0.0011 - accuracy: 0.9574\n",
      "At the end of episode 323 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2470/2470 [==============================] - 1s 307us/step - loss: 0.0025 - accuracy: 0.9522\n",
      "At the end of episode 324 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1260/1260 [==============================] - 0s 293us/step - loss: -0.0028 - accuracy: 0.9468\n",
      "At the end of episode 325 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1807/1807 [==============================] - 1s 295us/step - loss: -0.0033 - accuracy: 0.9563\n",
      "At the end of episode 326 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2100/2100 [==============================] - 1s 281us/step - loss: 0.0090 - accuracy: 0.9533\n",
      "At the end of episode 327 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2736/2736 [==============================] - 1s 303us/step - loss: 0.0042 - accuracy: 0.9466\n",
      "At the end of episode 328 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1325/1325 [==============================] - 0s 288us/step - loss: 0.0095 - accuracy: 0.9668\n",
      "At the end of episode 329 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2104/2104 [==============================] - 1s 294us/step - loss: 0.0123 - accuracy: 0.9567\n",
      "At the end of episode 330 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2197/2197 [==============================] - 1s 288us/step - loss: -1.5767e-04 - accuracy: 0.9467\n",
      "At the end of episode 331 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2374/2374 [==============================] - 1s 291us/step - loss: -2.9681e-04 - accuracy: 0.9579\n",
      "At the end of episode 332 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2490/2490 [==============================] - 1s 292us/step - loss: 0.0096 - accuracy: 0.9586\n",
      "At the end of episode 333 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2785/2785 [==============================] - 1s 288us/step - loss: 0.0075 - accuracy: 0.9483\n",
      "At the end of episode 334 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2062/2062 [==============================] - 1s 290us/step - loss: -1.5209e-04 - accuracy: 0.9403\n",
      "At the end of episode 335 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1424/1424 [==============================] - 0s 292us/step - loss: -0.0025 - accuracy: 0.9494\n",
      "At the end of episode 336 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2920/2920 [==============================] - 1s 286us/step - loss: -0.0111 - accuracy: 0.9387\n",
      "At the end of episode 337 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2251/2251 [==============================] - 1s 286us/step - loss: 0.0027 - accuracy: 0.9445\n",
      "At the end of episode 338 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2650/2650 [==============================] - 1s 274us/step - loss: -0.0105 - accuracy: 0.9464\n",
      "At the end of episode 339 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2182/2182 [==============================] - 1s 295us/step - loss: -0.0033 - accuracy: 0.9528\n",
      "At the end of episode 340 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1994/1994 [==============================] - 1s 278us/step - loss: -0.0124 - accuracy: 0.9468\n",
      "At the end of episode 341 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2086/2086 [==============================] - 1s 294us/step - loss: 0.0017 - accuracy: 0.9338\n",
      "At the end of episode 342 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1748/1748 [==============================] - 1s 287us/step - loss: -0.0150 - accuracy: 0.9434\n",
      "At the end of episode 343 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1105/1105 [==============================] - 0s 293us/step - loss: -0.0044 - accuracy: 0.9421\n",
      "At the end of episode 344 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1502/1502 [==============================] - 0s 297us/step - loss: -0.0044 - accuracy: 0.9521\n",
      "At the end of episode 345 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2079/2079 [==============================] - 1s 292us/step - loss: 0.0077 - accuracy: 0.9447\n",
      "At the end of episode 346 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "1916/1916 [==============================] - 1s 299us/step - loss: 0.0018 - accuracy: 0.9462\n",
      "At the end of episode 347 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1266/1266 [==============================] - 0s 302us/step - loss: 0.0069 - accuracy: 0.9439\n",
      "At the end of episode 348 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1818/1818 [==============================] - 1s 284us/step - loss: -0.0031 - accuracy: 0.9439\n",
      "At the end of episode 349 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2185/2185 [==============================] - 1s 288us/step - loss: -0.0100 - accuracy: 0.9478\n",
      "At the end of episode 350 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1816/1816 [==============================] - 1s 296us/step - loss: -0.0246 - accuracy: 0.9383\n",
      "At the end of episode 351 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2584/2584 [==============================] - 1s 282us/step - loss: 0.0071 - accuracy: 0.9613\n",
      "At the end of episode 352 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1878/1878 [==============================] - 1s 285us/step - loss: -0.0053 - accuracy: 0.9617\n",
      "At the end of episode 353 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2203/2203 [==============================] - 1s 291us/step - loss: -0.0017 - accuracy: 0.9483\n",
      "At the end of episode 354 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1802/1802 [==============================] - 1s 280us/step - loss: -0.0038 - accuracy: 0.9528\n",
      "At the end of episode 355 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2079/2079 [==============================] - 1s 289us/step - loss: 0.0015 - accuracy: 0.9577\n",
      "At the end of episode 356 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1912/1912 [==============================] - 1s 281us/step - loss: 0.0119 - accuracy: 0.9503\n",
      "At the end of episode 357 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2574/2574 [==============================] - 1s 296us/step - loss: 0.0015 - accuracy: 0.9604\n",
      "At the end of episode 358 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2716/2716 [==============================] - 1s 314us/step - loss: 0.0078 - accuracy: 0.9580\n",
      "At the end of episode 359 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2654/2654 [==============================] - 1s 291us/step - loss: 0.0021 - accuracy: 0.9435\n",
      "At the end of episode 360 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2338/2338 [==============================] - 1s 290us/step - loss: -0.0034 - accuracy: 0.9538\n",
      "At the end of episode 361 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2366/2366 [==============================] - 1s 300us/step - loss: -0.0140 - accuracy: 0.9493\n",
      "At the end of episode 362 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1673/1673 [==============================] - 0s 290us/step - loss: -0.0088 - accuracy: 0.9570\n",
      "At the end of episode 363 the total reward was : -19.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1841/1841 [==============================] - 1s 298us/step - loss: -0.0011 - accuracy: 0.9544\n",
      "At the end of episode 364 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2012/2012 [==============================] - 1s 278us/step - loss: 0.0069 - accuracy: 0.9558\n",
      "At the end of episode 365 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2711/2711 [==============================] - 1s 278us/step - loss: -0.0032 - accuracy: 0.9506\n",
      "At the end of episode 366 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1561/1561 [==============================] - 0s 292us/step - loss: -0.0069 - accuracy: 0.9635\n",
      "At the end of episode 367 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 1s 286us/step - loss: 0.0082 - accuracy: 0.9571\n",
      "At the end of episode 368 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2267/2267 [==============================] - 1s 289us/step - loss: 0.0056 - accuracy: 0.9656\n",
      "At the end of episode 369 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1980/1980 [==============================] - 1s 299us/step - loss: 0.0145 - accuracy: 0.9571\n",
      "At the end of episode 370 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1791/1791 [==============================] - 1s 282us/step - loss: 0.0042 - accuracy: 0.9576\n",
      "At the end of episode 371 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2745/2745 [==============================] - 1s 290us/step - loss: -0.0119 - accuracy: 0.9610\n",
      "At the end of episode 372 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2817/2817 [==============================] - 1s 279us/step - loss: 0.0033 - accuracy: 0.9666\n",
      "At the end of episode 373 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1923/1923 [==============================] - 1s 299us/step - loss: -0.0033 - accuracy: 0.9584\n",
      "At the end of episode 374 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2802/2802 [==============================] - 1s 277us/step - loss: -0.0064 - accuracy: 0.9604\n",
      "At the end of episode 375 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2121/2121 [==============================] - 1s 301us/step - loss: 0.0051 - accuracy: 0.9623\n",
      "At the end of episode 376 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2232/2232 [==============================] - 1s 289us/step - loss: 0.0065 - accuracy: 0.9691\n",
      "At the end of episode 377 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2004/2004 [==============================] - 1s 301us/step - loss: 0.0048 - accuracy: 0.9621\n",
      "At the end of episode 378 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2561/2561 [==============================] - 1s 278us/step - loss: -0.0018 - accuracy: 0.9633\n",
      "At the end of episode 379 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2727/2727 [==============================] - 1s 295us/step - loss: -0.0107 - accuracy: 0.9542\n",
      "At the end of episode 380 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2705/2705 [==============================] - 1s 295us/step - loss: -0.0025 - accuracy: 0.9582\n",
      "At the end of episode 381 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1833/1833 [==============================] - 1s 300us/step - loss: -5.1816e-04 - accuracy: 0.9678\n",
      "At the end of episode 382 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 1s 283us/step - loss: -0.0054 - accuracy: 0.9587\n",
      "At the end of episode 383 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2495/2495 [==============================] - 1s 289us/step - loss: -0.0015 - accuracy: 0.9695\n",
      "At the end of episode 384 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2567/2567 [==============================] - 1s 282us/step - loss: -0.0062 - accuracy: 0.9494\n",
      "At the end of episode 385 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2478/2478 [==============================] - 1s 275us/step - loss: -0.0025 - accuracy: 0.9588\n",
      "At the end of episode 386 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2525/2525 [==============================] - 1s 287us/step - loss: 0.0033 - accuracy: 0.9576\n",
      "At the end of episode 387 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1998/1998 [==============================] - 1s 278us/step - loss: 0.0160 - accuracy: 0.9585\n",
      "At the end of episode 388 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2082/2082 [==============================] - 1s 292us/step - loss: 0.0132 - accuracy: 0.9510\n",
      "At the end of episode 389 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2740/2740 [==============================] - 1s 305us/step - loss: 0.0069 - accuracy: 0.9602\n",
      "At the end of episode 390 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2095/2095 [==============================] - 1s 279us/step - loss: -0.0047 - accuracy: 0.9699\n",
      "At the end of episode 391 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2823/2823 [==============================] - 1s 288us/step - loss: 0.0106 - accuracy: 0.9639\n",
      "At the end of episode 392 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1915/1915 [==============================] - 1s 293us/step - loss: 0.0015 - accuracy: 0.9567\n",
      "At the end of episode 393 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2530/2530 [==============================] - 1s 299us/step - loss: 0.0089 - accuracy: 0.9601\n",
      "At the end of episode 394 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2744/2744 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.96 - 1s 302us/step - loss: 0.0031 - accuracy: 0.9650\n",
      "At the end of episode 395 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 1s 289us/step - loss: -0.0054 - accuracy: 0.9657\n",
      "At the end of episode 396 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2220/2220 [==============================] - 1s 287us/step - loss: 0.0061 - accuracy: 0.9685\n",
      "At the end of episode 397 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2390/2390 [==============================] - 1s 297us/step - loss: 0.0017 - accuracy: 0.9603\n",
      "At the end of episode 398 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2105/2105 [==============================] - 1s 280us/step - loss: 0.0053 - accuracy: 0.9667\n",
      "At the end of episode 399 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2881/2881 [==============================] - 1s 296us/step - loss: 0.0041 - accuracy: 0.9583\n",
      "At the end of episode 400 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3043/3043 [==============================] - 1s 282us/step - loss: 0.0100 - accuracy: 0.9645\n",
      "At the end of episode 401 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2145/2145 [==============================] - 1s 294us/step - loss: -0.0027 - accuracy: 0.9683\n",
      "At the end of episode 402 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2344/2344 [==============================] - 1s 292us/step - loss: -7.0421e-04 - accuracy: 0.9684\n",
      "At the end of episode 403 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2832/2832 [==============================] - 1s 283us/step - loss: -0.0045 - accuracy: 0.9622\n",
      "At the end of episode 404 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1981/1981 [==============================] - 1s 288us/step - loss: -0.0017 - accuracy: 0.9642\n",
      "At the end of episode 405 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2179/2179 [==============================] - 1s 278us/step - loss: -0.0044 - accuracy: 0.9582\n",
      "At the end of episode 406 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2317/2317 [==============================] - 1s 276us/step - loss: 0.0161 - accuracy: 0.9538\n",
      "At the end of episode 407 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2352/2352 [==============================] - 1s 281us/step - loss: 0.0029 - accuracy: 0.9549\n",
      "At the end of episode 408 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1997/1997 [==============================] - 1s 298us/step - loss: 0.0088 - accuracy: 0.9619\n",
      "At the end of episode 409 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2067/2067 [==============================] - 1s 295us/step - loss: -0.0091 - accuracy: 0.9560\n",
      "At the end of episode 410 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1909/1909 [==============================] - 1s 295us/step - loss: 0.0146 - accuracy: 0.9691\n",
      "At the end of episode 411 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2014/2014 [==============================] - 1s 300us/step - loss: -0.0023 - accuracy: 0.9633\n",
      "At the end of episode 412 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2587/2587 [==============================] - 1s 285us/step - loss: -0.0074 - accuracy: 0.9552\n",
      "At the end of episode 413 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2245/2245 [==============================] - 1s 299us/step - loss: -0.0127 - accuracy: 0.9577\n",
      "At the end of episode 414 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2351/2351 [==============================] - 1s 286us/step - loss: -0.0098 - accuracy: 0.9655\n",
      "At the end of episode 415 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2036/2036 [==============================] - 1s 284us/step - loss: 0.0177 - accuracy: 0.9543\n",
      "At the end of episode 416 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2190/2190 [==============================] - 1s 285us/step - loss: -0.0066 - accuracy: 0.9571\n",
      "At the end of episode 417 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2253/2253 [==============================] - 1s 286us/step - loss: -0.0074 - accuracy: 0.9667\n",
      "At the end of episode 418 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2494/2494 [==============================] - 1s 286us/step - loss: 0.0055 - accuracy: 0.9615\n",
      "At the end of episode 419 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2603/2603 [==============================] - 1s 300us/step - loss: 0.0103 - accuracy: 0.9612\n",
      "At the end of episode 420 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1589/1589 [==============================] - 0s 284us/step - loss: -5.2672e-04 - accuracy: 0.9698\n",
      "At the end of episode 421 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1972/1972 [==============================] - 1s 284us/step - loss: 0.0088 - accuracy: 0.9579\n",
      "At the end of episode 422 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2204/2204 [==============================] - 1s 312us/step - loss: 0.0066 - accuracy: 0.9691\n",
      "At the end of episode 423 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2149/2149 [==============================] - 1s 284us/step - loss: -0.0089 - accuracy: 0.9553\n",
      "At the end of episode 424 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2777/2777 [==============================] - 1s 289us/step - loss: -0.0038 - accuracy: 0.9561\n",
      "At the end of episode 425 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2034/2034 [==============================] - 1s 277us/step - loss: 0.0083 - accuracy: 0.9735\n",
      "At the end of episode 426 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2300/2300 [==============================] - 1s 271us/step - loss: 0.0066 - accuracy: 0.9622\n",
      "At the end of episode 427 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1903/1903 [==============================] - 1s 295us/step - loss: 0.0069 - accuracy: 0.9543\n",
      "At the end of episode 428 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1973/1973 [==============================] - 1s 281us/step - loss: -0.0128 - accuracy: 0.9564\n",
      "At the end of episode 429 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2183/2183 [==============================] - 1s 296us/step - loss: 0.0098 - accuracy: 0.9597\n",
      "At the end of episode 430 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2054/2054 [==============================] - 1s 304us/step - loss: 0.0098 - accuracy: 0.9601\n",
      "At the end of episode 431 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2250/2250 [==============================] - 1s 300us/step - loss: 0.0047 - accuracy: 0.9604\n",
      "At the end of episode 432 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2631/2631 [==============================] - 1s 284us/step - loss: -0.0034 - accuracy: 0.9612\n",
      "At the end of episode 433 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2339/2339 [==============================] - 1s 279us/step - loss: 0.0171 - accuracy: 0.9645\n",
      "At the end of episode 434 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2126/2126 [==============================] - 1s 290us/step - loss: 0.0132 - accuracy: 0.9657\n",
      "At the end of episode 435 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 1s 295us/step - loss: 0.0045 - accuracy: 0.9676\n",
      "At the end of episode 436 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2074/2074 [==============================] - 1s 292us/step - loss: 0.0173 - accuracy: 0.9658\n",
      "At the end of episode 437 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2661/2661 [==============================] - 1s 287us/step - loss: -0.0012 - accuracy: 0.9639\n",
      "At the end of episode 438 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "2975/2975 [==============================] - 1s 278us/step - loss: 0.0019 - accuracy: 0.9634\n",
      "At the end of episode 439 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 1s 276us/step - loss: 0.0024 - accuracy: 0.9649\n",
      "At the end of episode 440 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2672/2672 [==============================] - 1s 278us/step - loss: 0.0037 - accuracy: 0.9701\n",
      "At the end of episode 441 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2255/2255 [==============================] - 1s 275us/step - loss: 0.0042 - accuracy: 0.9650\n",
      "At the end of episode 442 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1884/1884 [==============================] - 1s 279us/step - loss: 0.0032 - accuracy: 0.9692\n",
      "At the end of episode 443 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1335/1335 [==============================] - 0s 294us/step - loss: 0.0059 - accuracy: 0.9678\n",
      "At the end of episode 444 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2340/2340 [==============================] - 1s 287us/step - loss: -8.9689e-04 - accuracy: 0.9714\n",
      "At the end of episode 445 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2166/2166 [==============================] - 1s 284us/step - loss: -0.0018 - accuracy: 0.9723\n",
      "At the end of episode 446 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2003/2003 [==============================] - 1s 279us/step - loss: 0.0199 - accuracy: 0.9576\n",
      "At the end of episode 447 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1817/1817 [==============================] - 1s 295us/step - loss: 0.0126 - accuracy: 0.9626\n",
      "At the end of episode 448 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 1s 281us/step - loss: -0.0115 - accuracy: 0.9578\n",
      "At the end of episode 449 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2329/2329 [==============================] - 1s 293us/step - loss: 0.0130 - accuracy: 0.9584\n",
      "At the end of episode 450 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1591/1591 [==============================] - 0s 286us/step - loss: -0.0244 - accuracy: 0.9598\n",
      "At the end of episode 451 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 1s 285us/step - loss: 0.0033 - accuracy: 0.9685\n",
      "At the end of episode 452 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2528/2528 [==============================] - 1s 287us/step - loss: -2.9563e-04 - accuracy: 0.9735\n",
      "At the end of episode 453 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2676/2676 [==============================] - 1s 284us/step - loss: 0.0014 - accuracy: 0.9675\n",
      "At the end of episode 454 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2414/2414 [==============================] - 1s 316us/step - loss: 0.0020 - accuracy: 0.9623\n",
      "At the end of episode 455 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2579/2579 [==============================] - 1s 287us/step - loss: 7.0204e-04 - accuracy: 0.9601\n",
      "At the end of episode 456 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2104/2104 [==============================] - 1s 290us/step - loss: -0.0026 - accuracy: 0.9610\n",
      "At the end of episode 457 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2370/2370 [==============================] - 1s 302us/step - loss: 0.0251 - accuracy: 0.9684\n",
      "At the end of episode 458 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2001/2001 [==============================] - 1s 288us/step - loss: 0.0024 - accuracy: 0.9680\n",
      "At the end of episode 459 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2213/2213 [==============================] - 1s 288us/step - loss: 0.0017 - accuracy: 0.9629\n",
      "At the end of episode 460 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2555/2555 [==============================] - 1s 325us/step - loss: -0.0070 - accuracy: 0.9569\n",
      "At the end of episode 461 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2512/2512 [==============================] - 1s 285us/step - loss: -0.0082 - accuracy: 0.9670\n",
      "At the end of episode 462 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1663/1663 [==============================] - 0s 283us/step - loss: 0.0058 - accuracy: 0.9645\n",
      "At the end of episode 463 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1973/1973 [==============================] - 1s 297us/step - loss: -0.0145 - accuracy: 0.9620\n",
      "At the end of episode 464 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2061/2061 [==============================] - 1s 289us/step - loss: -0.0102 - accuracy: 0.9665\n",
      "At the end of episode 465 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1822/1822 [==============================] - 1s 275us/step - loss: -0.0054 - accuracy: 0.9654\n",
      "At the end of episode 466 the total reward was : -21.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2315/2315 [==============================] - 1s 288us/step - loss: 0.0024 - accuracy: 0.9762\n",
      "At the end of episode 467 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2251/2251 [==============================] - 1s 308us/step - loss: -0.0089 - accuracy: 0.9622\n",
      "At the end of episode 468 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2635/2635 [==============================] - 1s 290us/step - loss: -0.0146 - accuracy: 0.9643\n",
      "At the end of episode 469 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2120/2120 [==============================] - 1s 295us/step - loss: 0.0059 - accuracy: 0.9665\n",
      "At the end of episode 470 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1737/1737 [==============================] - 1s 291us/step - loss: -0.0027 - accuracy: 0.9620\n",
      "At the end of episode 471 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1997/1997 [==============================] - 1s 294us/step - loss: 0.0058 - accuracy: 0.9740\n",
      "At the end of episode 472 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2792/2792 [==============================] - 1s 277us/step - loss: -0.0019 - accuracy: 0.9656\n",
      "At the end of episode 473 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1976/1976 [==============================] - 1s 286us/step - loss: -0.0049 - accuracy: 0.9701\n",
      "At the end of episode 474 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2157/2157 [==============================] - 1s 283us/step - loss: -0.0108 - accuracy: 0.9629\n",
      "At the end of episode 475 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1734/1734 [==============================] - 0s 287us/step - loss: 0.0018 - accuracy: 0.9706\n",
      "At the end of episode 476 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2350/2350 [==============================] - 1s 295us/step - loss: 8.1226e-04 - accuracy: 0.9728\n",
      "At the end of episode 477 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2084/2084 [==============================] - 1s 290us/step - loss: 0.0117 - accuracy: 0.9679\n",
      "At the end of episode 478 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2645/2645 [==============================] - 1s 274us/step - loss: -0.0018 - accuracy: 0.9652\n",
      "At the end of episode 479 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2299/2299 [==============================] - 1s 293us/step - loss: -0.0033 - accuracy: 0.9635\n",
      "At the end of episode 480 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 1s 290us/step - loss: -0.0013 - accuracy: 0.9709\n",
      "At the end of episode 481 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3061/3061 [==============================] - 1s 292us/step - loss: 0.0059 - accuracy: 0.9664\n",
      "At the end of episode 482 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2645/2645 [==============================] - 1s 288us/step - loss: -0.0105 - accuracy: 0.9686\n",
      "At the end of episode 483 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 1s 287us/step - loss: 0.0067 - accuracy: 0.9743\n",
      "At the end of episode 484 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1922/1922 [==============================] - 1s 288us/step - loss: 0.0162 - accuracy: 0.9672\n",
      "At the end of episode 485 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3019/3019 [==============================] - 1s 294us/step - loss: 0.0047 - accuracy: 0.9699\n",
      "At the end of episode 486 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 1s 282us/step - loss: -7.7317e-04 - accuracy: 0.9627\n",
      "At the end of episode 487 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2157/2157 [==============================] - 1s 315us/step - loss: 0.0032 - accuracy: 0.9722\n",
      "At the end of episode 488 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 1s 305us/step - loss: 0.0039 - accuracy: 0.9646\n",
      "At the end of episode 489 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2576/2576 [==============================] - 1s 291us/step - loss: 0.0041 - accuracy: 0.9713\n",
      "At the end of episode 490 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2677/2677 [==============================] - 1s 286us/step - loss: -0.0129 - accuracy: 0.9690\n",
      "At the end of episode 491 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 1s 304us/step - loss: 0.0063 - accuracy: 0.9732\n",
      "At the end of episode 492 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2190/2190 [==============================] - 1s 284us/step - loss: 0.0032 - accuracy: 0.9685\n",
      "At the end of episode 493 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2053/2053 [==============================] - 1s 278us/step - loss: -1.0103e-04 - accuracy: 0.9732\n",
      "At the end of episode 494 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2038/2038 [==============================] - 1s 276us/step - loss: 0.0172 - accuracy: 0.9730 0s - loss: 0.0146 - accuracy\n",
      "At the end of episode 495 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2634/2634 [==============================] - 1s 293us/step - loss: -6.0248e-04 - accuracy: 0.9670\n",
      "At the end of episode 496 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2041/2041 [==============================] - 1s 281us/step - loss: 0.0075 - accuracy: 0.9686\n",
      "At the end of episode 497 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2693/2693 [==============================] - 1s 295us/step - loss: 0.0019 - accuracy: 0.9725\n",
      "At the end of episode 498 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2355/2355 [==============================] - 1s 288us/step - loss: -2.9189e-04 - accuracy: 0.9690\n",
      "At the end of episode 499 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 1s 296us/step - loss: -0.0153 - accuracy: 0.9686\n",
      "At the end of episode 500 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2568/2568 [==============================] - 1s 299us/step - loss: -0.0105 - accuracy: 0.9778\n",
      "At the end of episode 501 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1958/1958 [==============================] - 1s 299us/step - loss: 0.0050 - accuracy: 0.9760\n",
      "At the end of episode 502 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2162/2162 [==============================] - 1s 289us/step - loss: 0.0087 - accuracy: 0.9741\n",
      "At the end of episode 503 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2492/2492 [==============================] - 1s 277us/step - loss: 0.0169 - accuracy: 0.9691\n",
      "At the end of episode 504 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2184/2184 [==============================] - 1s 279us/step - loss: -0.0012 - accuracy: 0.9762\n",
      "At the end of episode 505 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2159/2159 [==============================] - 1s 305us/step - loss: -0.0021 - accuracy: 0.9657\n",
      "At the end of episode 506 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2363/2363 [==============================] - 1s 294us/step - loss: -0.0049 - accuracy: 0.9645\n",
      "At the end of episode 507 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2658/2658 [==============================] - 1s 288us/step - loss: 0.0055 - accuracy: 0.9729\n",
      "At the end of episode 508 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2257/2257 [==============================] - 1s 295us/step - loss: -0.0050 - accuracy: 0.9730\n",
      "At the end of episode 509 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2581/2581 [==============================] - 1s 295us/step - loss: 0.0104 - accuracy: 0.9717\n",
      "At the end of episode 510 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1957/1957 [==============================] - 1s 300us/step - loss: -0.0117 - accuracy: 0.9719\n",
      "At the end of episode 511 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2155/2155 [==============================] - 1s 280us/step - loss: -0.0016 - accuracy: 0.9763\n",
      "At the end of episode 512 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2681/2681 [==============================] - 1s 294us/step - loss: -3.0080e-04 - accuracy: 0.9690\n",
      "At the end of episode 513 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2135/2135 [==============================] - 1s 297us/step - loss: 0.0019 - accuracy: 0.9785\n",
      "At the end of episode 514 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 1s 291us/step - loss: 0.0110 - accuracy: 0.9672\n",
      "At the end of episode 515 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2242/2242 [==============================] - 1s 295us/step - loss: -0.0014 - accuracy: 0.9692\n",
      "At the end of episode 516 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2362/2362 [==============================] - 1s 284us/step - loss: 0.0090 - accuracy: 0.9678\n",
      "At the end of episode 517 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1852/1852 [==============================] - 1s 294us/step - loss: 0.0227 - accuracy: 0.9703\n",
      "At the end of episode 518 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2893/2893 [==============================] - 1s 340us/step - loss: -0.0083 - accuracy: 0.9689\n",
      "At the end of episode 519 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1684/1684 [==============================] - 1s 300us/step - loss: 0.0156 - accuracy: 0.9774\n",
      "At the end of episode 520 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1824/1824 [==============================] - 1s 287us/step - loss: 0.0125 - accuracy: 0.9781\n",
      "At the end of episode 521 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2913/2913 [==============================] - 1s 275us/step - loss: 0.0020 - accuracy: 0.9626\n",
      "At the end of episode 522 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2254/2254 [==============================] - 1s 314us/step - loss: 0.0062 - accuracy: 0.9716\n",
      "At the end of episode 523 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1923/1923 [==============================] - 1s 286us/step - loss: 0.0074 - accuracy: 0.9641\n",
      "At the end of episode 524 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2358/2358 [==============================] - 1s 284us/step - loss: 0.0062 - accuracy: 0.9712\n",
      "At the end of episode 525 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2083/2083 [==============================] - 1s 283us/step - loss: -0.0027 - accuracy: 0.9683\n",
      "At the end of episode 526 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2241/2241 [==============================] - 1s 294us/step - loss: -0.0114 - accuracy: 0.9741\n",
      "At the end of episode 527 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1811/1811 [==============================] - 1s 300us/step - loss: -0.0039 - accuracy: 0.9641\n",
      "At the end of episode 528 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2103/2103 [==============================] - 1s 275us/step - loss: 0.0023 - accuracy: 0.9719\n",
      "At the end of episode 529 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 1s 295us/step - loss: -0.0230 - accuracy: 0.9630\n",
      "At the end of episode 530 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2492/2492 [==============================] - 1s 285us/step - loss: 0.0066 - accuracy: 0.9671\n",
      "At the end of episode 531 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2116/2116 [==============================] - 1s 296us/step - loss: 0.0069 - accuracy: 0.9693\n",
      "At the end of episode 532 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2558/2558 [==============================] - 1s 293us/step - loss: 0.0052 - accuracy: 0.9754\n",
      "At the end of episode 533 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2797/2797 [==============================] - 1s 293us/step - loss: -0.0014 - accuracy: 0.9689\n",
      "At the end of episode 534 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2126/2126 [==============================] - 1s 282us/step - loss: 0.0039 - accuracy: 0.9770\n",
      "At the end of episode 535 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2143/2143 [==============================] - 1s 292us/step - loss: -6.7984e-04 - accuracy: 0.9781\n",
      "At the end of episode 536 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2259/2259 [==============================] - 1s 276us/step - loss: -0.0158 - accuracy: 0.9726\n",
      "At the end of episode 537 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2992/2992 [==============================] - 1s 281us/step - loss: -0.0028 - accuracy: 0.9739\n",
      "At the end of episode 538 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2735/2735 [==============================] - 1s 278us/step - loss: -0.0015 - accuracy: 0.9733\n",
      "At the end of episode 539 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 1s 283us/step - loss: -0.0086 - accuracy: 0.9700\n",
      "At the end of episode 540 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2227/2227 [==============================] - 1s 318us/step - loss: 0.0010 - accuracy: 0.9740\n",
      "At the end of episode 541 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2315/2315 [==============================] - 1s 299us/step - loss: 0.0052 - accuracy: 0.9706\n",
      "At the end of episode 542 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2594/2594 [==============================] - 1s 294us/step - loss: 4.6479e-04 - accuracy: 0.9827\n",
      "At the end of episode 543 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2655/2655 [==============================] - 1s 286us/step - loss: -0.0058 - accuracy: 0.9718\n",
      "At the end of episode 544 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2024/2024 [==============================] - 1s 285us/step - loss: -0.0098 - accuracy: 0.9812\n",
      "At the end of episode 545 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1905/1905 [==============================] - 1s 275us/step - loss: 0.0108 - accuracy: 0.9732\n",
      "At the end of episode 546 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 1s 287us/step - loss: -0.0092 - accuracy: 0.9725\n",
      "At the end of episode 547 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1478/1478 [==============================] - 0s 292us/step - loss: 0.0043 - accuracy: 0.9797\n",
      "At the end of episode 548 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1974/1974 [==============================] - 1s 295us/step - loss: -0.0177 - accuracy: 0.9742\n",
      "At the end of episode 549 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2783/2783 [==============================] - 1s 276us/step - loss: 0.0063 - accuracy: 0.9770\n",
      "At the end of episode 550 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2782/2782 [==============================] - 1s 301us/step - loss: -0.0017 - accuracy: 0.9730\n",
      "At the end of episode 551 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2581/2581 [==============================] - 1s 299us/step - loss: 0.0045 - accuracy: 0.9667\n",
      "At the end of episode 552 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2603/2603 [==============================] - 1s 293us/step - loss: -0.0215 - accuracy: 0.9673\n",
      "At the end of episode 553 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2279/2279 [==============================] - 1s 284us/step - loss: -0.0040 - accuracy: 0.9715\n",
      "At the end of episode 554 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1956/1956 [==============================] - 1s 299us/step - loss: 0.0064 - accuracy: 0.9678\n",
      "At the end of episode 555 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2056/2056 [==============================] - 1s 300us/step - loss: 0.0157 - accuracy: 0.9781\n",
      "At the end of episode 556 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1982/1982 [==============================] - 1s 291us/step - loss: 0.0236 - accuracy: 0.9652\n",
      "At the end of episode 557 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1833/1833 [==============================] - 1s 299us/step - loss: -1.3891e-05 - accuracy: 0.9760\n",
      "At the end of episode 558 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2331/2331 [==============================] - 1s 275us/step - loss: -0.0033 - accuracy: 0.9674\n",
      "At the end of episode 559 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2062/2062 [==============================] - 1s 289us/step - loss: -0.0027 - accuracy: 0.9733\n",
      "At the end of episode 560 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2098/2098 [==============================] - 1s 284us/step - loss: -1.7805e-04 - accuracy: 0.9795\n",
      "At the end of episode 561 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1819/1819 [==============================] - 1s 291us/step - loss: -0.0067 - accuracy: 0.9808\n",
      "At the end of episode 562 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2089/2089 [==============================] - 1s 285us/step - loss: 0.0054 - accuracy: 0.9732\n",
      "At the end of episode 563 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2712/2712 [==============================] - 1s 275us/step - loss: -0.0100 - accuracy: 0.9672\n",
      "At the end of episode 564 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2034/2034 [==============================] - 1s 294us/step - loss: 0.0019 - accuracy: 0.9749\n",
      "At the end of episode 565 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1832/1832 [==============================] - 1s 298us/step - loss: 0.0057 - accuracy: 0.9749\n",
      "At the end of episode 566 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1190/1190 [==============================] - 0s 281us/step - loss: 0.0023 - accuracy: 0.9807\n",
      "At the end of episode 567 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2638/2638 [==============================] - 1s 279us/step - loss: 0.0034 - accuracy: 0.9682\n",
      "At the end of episode 568 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2415/2415 [==============================] - 1s 281us/step - loss: -0.0022 - accuracy: 0.9677\n",
      "At the end of episode 569 the total reward was : -17.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3066/3066 [==============================] - 1s 296us/step - loss: 0.0066 - accuracy: 0.9723\n",
      "At the end of episode 570 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 1s 291us/step - loss: 0.0031 - accuracy: 0.9798\n",
      "At the end of episode 571 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2407/2407 [==============================] - 1s 292us/step - loss: -2.5175e-04 - accuracy: 0.9751\n",
      "At the end of episode 572 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 1s 279us/step - loss: -8.4964e-04 - accuracy: 0.9751\n",
      "At the end of episode 573 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 1s 297us/step - loss: 0.0152 - accuracy: 0.9783\n",
      "At the end of episode 574 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2248/2248 [==============================] - 1s 444us/step - loss: 0.0073 - accuracy: 0.9693\n",
      "At the end of episode 575 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2516/2516 [==============================] - 1s 365us/step - loss: -0.0092 - accuracy: 0.9694\n",
      "At the end of episode 576 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1669/1669 [==============================] - 1s 491us/step - loss: -0.0105 - accuracy: 0.9646\n",
      "At the end of episode 577 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1824/1824 [==============================] - 1s 423us/step - loss: 0.0015 - accuracy: 0.9666\n",
      "At the end of episode 578 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1845/1845 [==============================] - 1s 290us/step - loss: 0.0081 - accuracy: 0.9740\n",
      "At the end of episode 579 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 1s 295us/step - loss: -0.0151 - accuracy: 0.9729\n",
      "At the end of episode 580 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2641/2641 [==============================] - 1s 280us/step - loss: -0.0085 - accuracy: 0.9735\n",
      "At the end of episode 581 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2635/2635 [==============================] - 1s 298us/step - loss: -0.0044 - accuracy: 0.9761\n",
      "At the end of episode 582 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2667/2667 [==============================] - 1s 303us/step - loss: 0.0039 - accuracy: 0.9798\n",
      "At the end of episode 583 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2564/2564 [==============================] - 1s 306us/step - loss: -0.0069 - accuracy: 0.9782\n",
      "At the end of episode 584 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2244/2244 [==============================] - 1s 304us/step - loss: -0.0038 - accuracy: 0.9764\n",
      "At the end of episode 585 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 1s 281us/step - loss: 0.0130 - accuracy: 0.9783\n",
      "At the end of episode 586 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2179/2179 [==============================] - 1s 288us/step - loss: 0.0028 - accuracy: 0.9862\n",
      "At the end of episode 587 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2290/2290 [==============================] - 1s 286us/step - loss: -0.0100 - accuracy: 0.9598\n",
      "At the end of episode 588 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2337/2337 [==============================] - 1s 415us/step - loss: -0.0103 - accuracy: 0.9803\n",
      "At the end of episode 589 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1988/1988 [==============================] - 1s 500us/step - loss: -0.0051 - accuracy: 0.9733\n",
      "At the end of episode 590 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2562/2562 [==============================] - 1s 512us/step - loss: 0.0017 - accuracy: 0.9738\n",
      "At the end of episode 591 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2653/2653 [==============================] - 1s 501us/step - loss: -9.3020e-04 - accuracy: 0.9766\n",
      "At the end of episode 592 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 1s 516us/step - loss: 0.0144 - accuracy: 0.9749\n",
      "At the end of episode 593 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2247/2247 [==============================] - 1s 550us/step - loss: -0.0025 - accuracy: 0.9742\n",
      "At the end of episode 594 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2775/2775 [==============================] - 2s 566us/step - loss: -0.0044 - accuracy: 0.9737\n",
      "At the end of episode 595 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1765/1765 [==============================] - 1s 492us/step - loss: -0.0040 - accuracy: 0.9807\n",
      "At the end of episode 596 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2997/2997 [==============================] - 1s 470us/step - loss: -0.0021 - accuracy: 0.9740\n",
      "At the end of episode 597 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2229/2229 [==============================] - 1s 453us/step - loss: 0.0080 - accuracy: 0.9834\n",
      "At the end of episode 598 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1986/1986 [==============================] - 1s 287us/step - loss: -0.0016 - accuracy: 0.9854\n",
      "At the end of episode 599 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2083/2083 [==============================] - 1s 309us/step - loss: 0.0020 - accuracy: 0.9774\n",
      "At the end of episode 600 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1907/1907 [==============================] - 1s 284us/step - loss: -0.0040 - accuracy: 0.9785\n",
      "At the end of episode 601 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2221/2221 [==============================] - 1s 341us/step - loss: -0.0045 - accuracy: 0.9757\n",
      "At the end of episode 602 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2375/2375 [==============================] - 1s 372us/step - loss: -0.0180 - accuracy: 0.9756\n",
      "At the end of episode 603 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2534/2534 [==============================] - 1s 364us/step - loss: 0.0068 - accuracy: 0.9775\n",
      "At the end of episode 604 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2740/2740 [==============================] - 1s 326us/step - loss: -4.1901e-04 - accuracy: 0.9737\n",
      "At the end of episode 605 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2284/2284 [==============================] - 1s 490us/step - loss: 0.0113 - accuracy: 0.9803\n",
      "At the end of episode 606 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 1s 476us/step - loss: -0.0099 - accuracy: 0.9731\n",
      "At the end of episode 607 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2681/2681 [==============================] - 1s 291us/step - loss: 0.0021 - accuracy: 0.9702\n",
      "At the end of episode 608 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2668/2668 [==============================] - 1s 287us/step - loss: 0.0247 - accuracy: 0.9768\n",
      "At the end of episode 609 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2154/2154 [==============================] - 1s 392us/step - loss: 0.0054 - accuracy: 0.9754\n",
      "At the end of episode 610 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3073/3073 [==============================] - 1s 288us/step - loss: -0.0073 - accuracy: 0.9730\n",
      "At the end of episode 611 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2664/2664 [==============================] - 1s 309us/step - loss: -0.0018 - accuracy: 0.9790\n",
      "At the end of episode 612 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3005/3005 [==============================] - 1s 285us/step - loss: 0.0070 - accuracy: 0.9747\n",
      "At the end of episode 613 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2388/2388 [==============================] - 1s 290us/step - loss: 0.0061 - accuracy: 0.9732\n",
      "At the end of episode 614 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2933/2933 [==============================] - 1s 369us/step - loss: 0.0035 - accuracy: 0.9744\n",
      "At the end of episode 615 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2184/2184 [==============================] - 1s 291us/step - loss: 0.0089 - accuracy: 0.9817\n",
      "At the end of episode 616 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 1s 276us/step - loss: 5.4406e-04 - accuracy: 0.9770\n",
      "At the end of episode 617 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2304/2304 [==============================] - 1s 279us/step - loss: 0.0060 - accuracy: 0.9792\n",
      "At the end of episode 618 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2092/2092 [==============================] - 1s 302us/step - loss: -0.0028 - accuracy: 0.9756\n",
      "At the end of episode 619 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2888/2888 [==============================] - 1s 302us/step - loss: 0.0019 - accuracy: 0.9785\n",
      "At the end of episode 620 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2072/2072 [==============================] - 1s 335us/step - loss: 0.0053 - accuracy: 0.9821\n",
      "At the end of episode 621 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 1s 380us/step - loss: 0.0055 - accuracy: 0.9788\n",
      "At the end of episode 622 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2471/2471 [==============================] - 1s 421us/step - loss: 0.0039 - accuracy: 0.9705\n",
      "At the end of episode 623 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2403/2403 [==============================] - 1s 382us/step - loss: 0.0059 - accuracy: 0.9813\n",
      "At the end of episode 624 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2871/2871 [==============================] - 1s 314us/step - loss: 0.0074 - accuracy: 0.9763\n",
      "At the end of episode 625 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2501/2501 [==============================] - 1s 335us/step - loss: -0.0020 - accuracy: 0.9764\n",
      "At the end of episode 626 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2311/2311 [==============================] - 1s 346us/step - loss: 0.0086 - accuracy: 0.9766\n",
      "At the end of episode 627 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2404/2404 [==============================] - 1s 560us/step - loss: -0.0057 - accuracy: 0.9775\n",
      "At the end of episode 628 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2819/2819 [==============================] - 1s 477us/step - loss: 0.0049 - accuracy: 0.9819\n",
      "At the end of episode 629 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "3658/3658 [==============================] - 1s 325us/step - loss: -0.0041 - accuracy: 0.9721\n",
      "At the end of episode 630 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2794/2794 [==============================] - 1s 290us/step - loss: -0.0088 - accuracy: 0.9696\n",
      "At the end of episode 631 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1676/1676 [==============================] - 1s 361us/step - loss: -0.0088 - accuracy: 0.9720\n",
      "At the end of episode 632 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2599/2599 [==============================] - 1s 366us/step - loss: 0.0062 - accuracy: 0.9758\n",
      "At the end of episode 633 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2295/2295 [==============================] - 1s 422us/step - loss: 0.0023 - accuracy: 0.9765\n",
      "At the end of episode 634 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2729/2729 [==============================] - 1s 318us/step - loss: -0.0026 - accuracy: 0.9784\n",
      "At the end of episode 635 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1934/1934 [==============================] - 1s 560us/step - loss: -9.8181e-04 - accuracy: 0.9804loss: 1.7294e-04 - accuracy:\n",
      "At the end of episode 636 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2644/2644 [==============================] - 1s 355us/step - loss: 0.0108 - accuracy: 0.9754\n",
      "At the end of episode 637 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2842/2842 [==============================] - 1s 269us/step - loss: -0.0045 - accuracy: 0.9750\n",
      "At the end of episode 638 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2812/2812 [==============================] - 1s 282us/step - loss: -0.0016 - accuracy: 0.9794\n",
      "At the end of episode 639 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2490/2490 [==============================] - 1s 308us/step - loss: 0.0026 - accuracy: 0.9779\n",
      "At the end of episode 640 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2655/2655 [==============================] - 1s 288us/step - loss: 0.0047 - accuracy: 0.9793\n",
      "At the end of episode 641 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2148/2148 [==============================] - 1s 361us/step - loss: 0.0043 - accuracy: 0.9795\n",
      "At the end of episode 642 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3063/3063 [==============================] - 1s 274us/step - loss: 7.9566e-04 - accuracy: 0.9768\n",
      "At the end of episode 643 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 1s 284us/step - loss: -0.0020 - accuracy: 0.9790\n",
      "At the end of episode 644 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2729/2729 [==============================] - 1s 280us/step - loss: -0.0032 - accuracy: 0.9780\n",
      "At the end of episode 645 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1588/1588 [==============================] - 1s 469us/step - loss: 0.0039 - accuracy: 0.9780\n",
      "At the end of episode 646 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2185/2185 [==============================] - 1s 486us/step - loss: -5.2427e-04 - accuracy: 0.9735\n",
      "At the end of episode 647 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2804/2804 [==============================] - 1s 521us/step - loss: 0.0044 - accuracy: 0.9800\n",
      "At the end of episode 648 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2912/2912 [==============================] - ETA: 0s - loss: -6.7124e-04 - accuracy: 0.978 - 1s 329us/step - loss: -0.0012 - accuracy: 0.9787\n",
      "At the end of episode 649 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 1s 363us/step - loss: -0.0030 - accuracy: 0.9803\n",
      "At the end of episode 650 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2852/2852 [==============================] - 1s 301us/step - loss: 0.0054 - accuracy: 0.9783\n",
      "At the end of episode 651 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2769/2769 [==============================] - 1s 293us/step - loss: 0.0034 - accuracy: 0.9798\n",
      "At the end of episode 652 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2314/2314 [==============================] - 1s 432us/step - loss: -0.0053 - accuracy: 0.9754\n",
      "At the end of episode 653 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 1s 480us/step - loss: 0.0020 - accuracy: 0.9733\n",
      "At the end of episode 654 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3041/3041 [==============================] - 1s 299us/step - loss: -0.0018 - accuracy: 0.9793\n",
      "At the end of episode 655 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3224/3224 [==============================] - 1s 340us/step - loss: -0.0023 - accuracy: 0.9749\n",
      "At the end of episode 656 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2294/2294 [==============================] - 1s 287us/step - loss: -0.0043 - accuracy: 0.9808\n",
      "At the end of episode 657 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 1s 383us/step - loss: 0.0091 - accuracy: 0.9839\n",
      "At the end of episode 658 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2896/2896 [==============================] - 1s 320us/step - loss: 0.0045 - accuracy: 0.9852\n",
      "At the end of episode 659 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2755/2755 [==============================] - 1s 370us/step - loss: 0.0041 - accuracy: 0.9771\n",
      "At the end of episode 660 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2350/2350 [==============================] - 1s 304us/step - loss: 8.1272e-05 - accuracy: 0.9779\n",
      "At the end of episode 661 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2315/2315 [==============================] - 1s 298us/step - loss: -0.0117 - accuracy: 0.9767\n",
      "At the end of episode 662 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1928/1928 [==============================] - 1s 291us/step - loss: -0.0025 - accuracy: 0.9777\n",
      "At the end of episode 663 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2183/2183 [==============================] - 1s 314us/step - loss: -0.0025 - accuracy: 0.9849\n",
      "At the end of episode 664 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2632/2632 [==============================] - 1s 294us/step - loss: -0.0055 - accuracy: 0.9825\n",
      "At the end of episode 665 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2296/2296 [==============================] - 1s 293us/step - loss: -0.0167 - accuracy: 0.9804\n",
      "At the end of episode 666 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2183/2183 [==============================] - 1s 297us/step - loss: -0.0027 - accuracy: 0.9812\n",
      "At the end of episode 667 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2562/2562 [==============================] - 1s 295us/step - loss: 0.0041 - accuracy: 0.9824\n",
      "At the end of episode 668 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2309/2309 [==============================] - 1s 297us/step - loss: 7.7593e-04 - accuracy: 0.9801\n",
      "At the end of episode 669 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2123/2123 [==============================] - 1s 304us/step - loss: -0.0041 - accuracy: 0.9807\n",
      "At the end of episode 670 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2163/2163 [==============================] - 1s 295us/step - loss: -0.0059 - accuracy: 0.9792\n",
      "At the end of episode 671 the total reward was : -20.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2435/2435 [==============================] - 1s 287us/step - loss: 0.0013 - accuracy: 0.9733\n",
      "At the end of episode 672 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2083/2083 [==============================] - 1s 282us/step - loss: 0.0074 - accuracy: 0.9822\n",
      "At the end of episode 673 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2639/2639 [==============================] - 1s 305us/step - loss: -0.0012 - accuracy: 0.9803\n",
      "At the end of episode 674 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2111/2111 [==============================] - 1s 280us/step - loss: -0.0013 - accuracy: 0.9801\n",
      "At the end of episode 675 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 1s 296us/step - loss: 0.0052 - accuracy: 0.9814\n",
      "At the end of episode 676 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2802/2802 [==============================] - 1s 288us/step - loss: -0.0017 - accuracy: 0.9768\n",
      "At the end of episode 677 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2336/2336 [==============================] - 1s 294us/step - loss: 0.0028 - accuracy: 0.9812\n",
      "At the end of episode 678 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2151/2151 [==============================] - 1s 282us/step - loss: -0.0024 - accuracy: 0.9795\n",
      "At the end of episode 679 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2363/2363 [==============================] - 1s 291us/step - loss: 0.0041 - accuracy: 0.9793\n",
      "At the end of episode 680 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2163/2163 [==============================] - 1s 288us/step - loss: -0.0011 - accuracy: 0.9829\n",
      "At the end of episode 681 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2328/2328 [==============================] - 1s 289us/step - loss: -0.0036 - accuracy: 0.9751\n",
      "At the end of episode 682 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1582/1582 [==============================] - 0s 286us/step - loss: 0.0128 - accuracy: 0.9779\n",
      "At the end of episode 683 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2817/2817 [==============================] - 1s 309us/step - loss: 0.0022 - accuracy: 0.9783\n",
      "At the end of episode 684 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1505/1505 [==============================] - 0s 306us/step - loss: -0.0121 - accuracy: 0.9854\n",
      "At the end of episode 685 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2097/2097 [==============================] - 1s 295us/step - loss: 0.0031 - accuracy: 0.9709\n",
      "At the end of episode 686 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2237/2237 [==============================] - 1s 286us/step - loss: 0.0052 - accuracy: 0.9835\n",
      "At the end of episode 687 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 1s 292us/step - loss: -0.0013 - accuracy: 0.9784\n",
      "At the end of episode 688 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2667/2667 [==============================] - 1s 299us/step - loss: -0.0030 - accuracy: 0.9794\n",
      "At the end of episode 689 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2807/2807 [==============================] - 1s 300us/step - loss: 0.0064 - accuracy: 0.9822\n",
      "At the end of episode 690 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1959/1959 [==============================] - 1s 309us/step - loss: 0.0036 - accuracy: 0.9760\n",
      "At the end of episode 691 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2764/2764 [==============================] - 1s 288us/step - loss: -0.0061 - accuracy: 0.9754\n",
      "At the end of episode 692 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2130/2130 [==============================] - 1s 289us/step - loss: 0.0056 - accuracy: 0.9798\n",
      "At the end of episode 693 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2640/2640 [==============================] - 1s 298us/step - loss: -0.0134 - accuracy: 0.9750\n",
      "At the end of episode 694 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2225/2225 [==============================] - 1s 293us/step - loss: 0.0014 - accuracy: 0.9780\n",
      "At the end of episode 695 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2640/2640 [==============================] - 1s 300us/step - loss: -0.0094 - accuracy: 0.9777\n",
      "At the end of episode 696 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2262/2262 [==============================] - 1s 294us/step - loss: -0.0062 - accuracy: 0.9854\n",
      "At the end of episode 697 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2248/2248 [==============================] - 1s 296us/step - loss: 0.0016 - accuracy: 0.9809\n",
      "At the end of episode 698 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2626/2626 [==============================] - 1s 286us/step - loss: 0.0042 - accuracy: 0.9794\n",
      "At the end of episode 699 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2141/2141 [==============================] - 1s 291us/step - loss: -0.0043 - accuracy: 0.9818\n",
      "At the end of episode 700 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3199/3199 [==============================] - 1s 280us/step - loss: 0.0074 - accuracy: 0.9778\n",
      "At the end of episode 701 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1584/1584 [==============================] - 0s 287us/step - loss: -0.0021 - accuracy: 0.9691\n",
      "At the end of episode 702 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1431/1431 [==============================] - 0s 294us/step - loss: 0.0051 - accuracy: 0.9818\n",
      "At the end of episode 703 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2157/2157 [==============================] - 1s 297us/step - loss: 0.0152 - accuracy: 0.9796\n",
      "At the end of episode 704 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2227/2227 [==============================] - 1s 298us/step - loss: -0.0072 - accuracy: 0.9775\n",
      "At the end of episode 705 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1581/1581 [==============================] - 0s 301us/step - loss: -0.0042 - accuracy: 0.9810\n",
      "At the end of episode 706 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2233/2233 [==============================] - 1s 293us/step - loss: 0.0072 - accuracy: 0.9798\n",
      "At the end of episode 707 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2572/2572 [==============================] - 1s 304us/step - loss: -0.0103 - accuracy: 0.9747\n",
      "At the end of episode 708 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2347/2347 [==============================] - 1s 294us/step - loss: 0.0059 - accuracy: 0.9872\n",
      "At the end of episode 709 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2155/2155 [==============================] - 1s 306us/step - loss: 0.0065 - accuracy: 0.9791\n",
      "At the end of episode 710 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2400/2400 [==============================] - 1s 299us/step - loss: 0.0067 - accuracy: 0.9783\n",
      "At the end of episode 711 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3077/3077 [==============================] - 1s 307us/step - loss: -0.0073 - accuracy: 0.9792\n",
      "At the end of episode 712 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2925/2925 [==============================] - 1s 292us/step - loss: 0.0117 - accuracy: 0.9778\n",
      "At the end of episode 713 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3220/3220 [==============================] - 1s 288us/step - loss: -0.0021 - accuracy: 0.9733\n",
      "At the end of episode 714 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1811/1811 [==============================] - 1s 301us/step - loss: -0.0135 - accuracy: 0.9763\n",
      "At the end of episode 715 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2273/2273 [==============================] - 1s 313us/step - loss: 0.0018 - accuracy: 0.9771\n",
      "At the end of episode 716 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2730/2730 [==============================] - 1s 298us/step - loss: 0.0064 - accuracy: 0.9824\n",
      "At the end of episode 717 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2617/2617 [==============================] - 1s 317us/step - loss: 0.0047 - accuracy: 0.9809\n",
      "At the end of episode 718 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2403/2403 [==============================] - 1s 290us/step - loss: 0.0093 - accuracy: 0.9838\n",
      "At the end of episode 719 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2087/2087 [==============================] - 1s 331us/step - loss: -1.5526e-04 - accuracy: 0.9818\n",
      "At the end of episode 720 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1701/1701 [==============================] - 1s 300us/step - loss: -0.0028 - accuracy: 0.9865\n",
      "At the end of episode 721 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2493/2493 [==============================] - 1s 296us/step - loss: 0.0040 - accuracy: 0.9783\n",
      "At the end of episode 722 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2498/2498 [==============================] - 1s 307us/step - loss: 0.0144 - accuracy: 0.9808\n",
      "At the end of episode 723 the total reward was : -19.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2927/2927 [==============================] - 1s 292us/step - loss: -0.0069 - accuracy: 0.9781\n",
      "At the end of episode 724 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2407/2407 [==============================] - 1s 314us/step - loss: 0.0037 - accuracy: 0.9842\n",
      "At the end of episode 725 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2297/2297 [==============================] - 1s 296us/step - loss: 0.0041 - accuracy: 0.9804\n",
      "At the end of episode 726 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2963/2963 [==============================] - 1s 287us/step - loss: -0.0026 - accuracy: 0.9777\n",
      "At the end of episode 727 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2799/2799 [==============================] - 1s 293us/step - loss: -0.0072 - accuracy: 0.9789\n",
      "At the end of episode 728 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2508/2508 [==============================] - 1s 282us/step - loss: -0.0048 - accuracy: 0.9801\n",
      "At the end of episode 729 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "3079/3079 [==============================] - 1s 282us/step - loss: 0.0042 - accuracy: 0.9756\n",
      "At the end of episode 730 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 1s 296us/step - loss: 0.0036 - accuracy: 0.9726\n",
      "At the end of episode 731 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2478/2478 [==============================] - 1s 298us/step - loss: 0.0054 - accuracy: 0.9770\n",
      "At the end of episode 732 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2710/2710 [==============================] - 1s 286us/step - loss: 0.0038 - accuracy: 0.9756\n",
      "At the end of episode 733 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2190/2190 [==============================] - 1s 290us/step - loss: -0.0038 - accuracy: 0.9813\n",
      "At the end of episode 734 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2152/2152 [==============================] - 1s 292us/step - loss: -0.0032 - accuracy: 0.9809\n",
      "At the end of episode 735 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 1s 295us/step - loss: 0.0014 - accuracy: 0.9849\n",
      "At the end of episode 736 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2565/2565 [==============================] - 1s 293us/step - loss: -0.0048 - accuracy: 0.9789\n",
      "At the end of episode 737 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 1s 309us/step - loss: 0.0019 - accuracy: 0.9762\n",
      "At the end of episode 738 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2238/2238 [==============================] - 1s 297us/step - loss: 0.0044 - accuracy: 0.9821\n",
      "At the end of episode 739 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2813/2813 [==============================] - 1s 298us/step - loss: 0.0021 - accuracy: 0.9829\n",
      "At the end of episode 740 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2806/2806 [==============================] - 1s 290us/step - loss: 0.0033 - accuracy: 0.9840\n",
      "At the end of episode 741 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2087/2087 [==============================] - 1s 330us/step - loss: 0.0130 - accuracy: 0.9789\n",
      "At the end of episode 742 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2373/2373 [==============================] - 1s 294us/step - loss: 0.0015 - accuracy: 0.9857\n",
      "At the end of episode 743 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1625/1625 [==============================] - 0s 296us/step - loss: -0.0034 - accuracy: 0.9698\n",
      "At the end of episode 744 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2813/2813 [==============================] - 1s 298us/step - loss: -5.8672e-04 - accuracy: 0.9762\n",
      "At the end of episode 745 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2654/2654 [==============================] - 1s 291us/step - loss: 0.0060 - accuracy: 0.9766\n",
      "At the end of episode 746 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2852/2852 [==============================] - 1s 302us/step - loss: -0.0070 - accuracy: 0.9762\n",
      "At the end of episode 747 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2746/2746 [==============================] - 1s 292us/step - loss: -3.1398e-04 - accuracy: 0.9782\n",
      "At the end of episode 748 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2177/2177 [==============================] - 1s 303us/step - loss: 5.4708e-05 - accuracy: 0.9825\n",
      "At the end of episode 749 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2231/2231 [==============================] - 1s 308us/step - loss: -2.3461e-04 - accuracy: 0.9798\n",
      "At the end of episode 750 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2082/2082 [==============================] - 1s 290us/step - loss: -0.0177 - accuracy: 0.9760\n",
      "At the end of episode 751 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2230/2230 [==============================] - 1s 295us/step - loss: 0.0049 - accuracy: 0.9780\n",
      "At the end of episode 752 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2066/2066 [==============================] - 1s 307us/step - loss: 0.0011 - accuracy: 0.9826\n",
      "At the end of episode 753 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2689/2689 [==============================] - 1s 293us/step - loss: 0.0052 - accuracy: 0.9833\n",
      "At the end of episode 754 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2258/2258 [==============================] - 1s 297us/step - loss: 0.0063 - accuracy: 0.9818\n",
      "At the end of episode 755 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2687/2687 [==============================] - 1s 295us/step - loss: 0.0073 - accuracy: 0.9751\n",
      "At the end of episode 756 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 1s 293us/step - loss: -0.0053 - accuracy: 0.9825\n",
      "At the end of episode 757 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2885/2885 [==============================] - 1s 296us/step - loss: -0.0029 - accuracy: 0.9757\n",
      "At the end of episode 758 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2556/2556 [==============================] - 1s 287us/step - loss: 0.0012 - accuracy: 0.9816\n",
      "At the end of episode 759 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2741/2741 [==============================] - 1s 308us/step - loss: -0.0024 - accuracy: 0.9759\n",
      "At the end of episode 760 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2651/2651 [==============================] - 1s 293us/step - loss: -0.0064 - accuracy: 0.9819\n",
      "At the end of episode 761 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2192/2192 [==============================] - 1s 302us/step - loss: -6.9749e-05 - accuracy: 0.9872\n",
      "At the end of episode 762 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1942/1942 [==============================] - 1s 300us/step - loss: 0.0012 - accuracy: 0.9820\n",
      "At the end of episode 763 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2143/2143 [==============================] - 1s 285us/step - loss: -0.0046 - accuracy: 0.9818\n",
      "At the end of episode 764 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2853/2853 [==============================] - 1s 288us/step - loss: 7.0133e-05 - accuracy: 0.9811\n",
      "At the end of episode 765 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2318/2318 [==============================] - 1s 318us/step - loss: -9.8803e-04 - accuracy: 0.9810\n",
      "At the end of episode 766 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - ETA: 0s - loss: 0.0014 - accuracy: 0.97 - 1s 295us/step - loss: 5.3365e-05 - accuracy: 0.9782\n",
      "At the end of episode 767 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2240/2240 [==============================] - 1s 302us/step - loss: 0.0102 - accuracy: 0.9821\n",
      "At the end of episode 768 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2608/2608 [==============================] - 1s 295us/step - loss: -0.0010 - accuracy: 0.9827\n",
      "At the end of episode 769 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1727/1727 [==============================] - 1s 303us/step - loss: 0.0064 - accuracy: 0.9849\n",
      "At the end of episode 770 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1835/1835 [==============================] - 1s 300us/step - loss: -6.9925e-04 - accuracy: 0.9809\n",
      "At the end of episode 771 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2330/2330 [==============================] - 1s 292us/step - loss: 0.0025 - accuracy: 0.9820\n",
      "At the end of episode 772 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2128/2128 [==============================] - 1s 298us/step - loss: 0.0180 - accuracy: 0.9864\n",
      "At the end of episode 773 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2851/2851 [==============================] - 1s 306us/step - loss: -0.0011 - accuracy: 0.9821\n",
      "At the end of episode 774 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2304/2304 [==============================] - 1s 291us/step - loss: 0.0018 - accuracy: 0.9818\n",
      "At the end of episode 775 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2951/2951 [==============================] - 1s 290us/step - loss: -0.0067 - accuracy: 0.9807\n",
      "At the end of episode 776 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3128/3128 [==============================] - 1s 285us/step - loss: -0.0032 - accuracy: 0.9831\n",
      "At the end of episode 777 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2102/2102 [==============================] - 1s 317us/step - loss: 0.0011 - accuracy: 0.9781\n",
      "At the end of episode 778 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2708/2708 [==============================] - 1s 313us/step - loss: 0.0064 - accuracy: 0.9845\n",
      "At the end of episode 779 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3124/3124 [==============================] - 1s 301us/step - loss: 0.0044 - accuracy: 0.9805\n",
      "At the end of episode 780 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2652/2652 [==============================] - 1s 303us/step - loss: 0.0031 - accuracy: 0.9819\n",
      "At the end of episode 781 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2746/2746 [==============================] - 1s 283us/step - loss: 0.0050 - accuracy: 0.9785\n",
      "At the end of episode 782 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3084/3084 [==============================] - 1s 291us/step - loss: -0.0084 - accuracy: 0.9770\n",
      "At the end of episode 783 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2843/2843 [==============================] - 1s 301us/step - loss: 0.0061 - accuracy: 0.9807\n",
      "At the end of episode 784 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2386/2386 [==============================] - 1s 297us/step - loss: 0.0011 - accuracy: 0.9853\n",
      "At the end of episode 785 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1976/1976 [==============================] - 1s 301us/step - loss: -0.0032 - accuracy: 0.9858\n",
      "At the end of episode 786 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 1s 294us/step - loss: 0.0027 - accuracy: 0.9841\n",
      "At the end of episode 787 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1993/1993 [==============================] - 1s 304us/step - loss: 0.0061 - accuracy: 0.9844\n",
      "At the end of episode 788 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 1s 297us/step - loss: 0.0056 - accuracy: 0.9824\n",
      "At the end of episode 789 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2784/2784 [==============================] - 1s 295us/step - loss: -0.0028 - accuracy: 0.9820\n",
      "At the end of episode 790 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2099/2099 [==============================] - 1s 292us/step - loss: -0.0019 - accuracy: 0.9862\n",
      "At the end of episode 791 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2746/2746 [==============================] - 1s 287us/step - loss: -0.0022 - accuracy: 0.9829\n",
      "At the end of episode 792 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2543/2543 [==============================] - 1s 296us/step - loss: -0.0080 - accuracy: 0.9807\n",
      "At the end of episode 793 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3098/3098 [==============================] - 1s 299us/step - loss: 0.0047 - accuracy: 0.9771\n",
      "At the end of episode 794 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 1s 300us/step - loss: 0.0055 - accuracy: 0.9802\n",
      "At the end of episode 795 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2174/2174 [==============================] - 1s 296us/step - loss: 0.0152 - accuracy: 0.9738\n",
      "At the end of episode 796 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2393/2393 [==============================] - 1s 313us/step - loss: 0.0153 - accuracy: 0.9758\n",
      "At the end of episode 797 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2223/2223 [==============================] - 1s 303us/step - loss: 0.0018 - accuracy: 0.9865\n",
      "At the end of episode 798 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2313/2313 [==============================] - 1s 303us/step - loss: 0.0179 - accuracy: 0.9836\n",
      "At the end of episode 799 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2533/2533 [==============================] - 1s 305us/step - loss: 0.0048 - accuracy: 0.9779\n",
      "At the end of episode 800 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2816/2816 [==============================] - 1s 305us/step - loss: 0.0043 - accuracy: 0.9819\n",
      "At the end of episode 801 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2244/2244 [==============================] - 1s 304us/step - loss: -7.4363e-04 - accuracy: 0.9813\n",
      "At the end of episode 802 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2097/2097 [==============================] - 1s 295us/step - loss: -1.0973e-04 - accuracy: 0.9833\n",
      "At the end of episode 803 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2375/2375 [==============================] - 1s 293us/step - loss: 0.0014 - accuracy: 0.9827\n",
      "At the end of episode 804 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2904/2904 [==============================] - 1s 294us/step - loss: -0.0017 - accuracy: 0.9855\n",
      "At the end of episode 805 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2800/2800 [==============================] - 1s 299us/step - loss: 0.0030 - accuracy: 0.9832\n",
      "At the end of episode 806 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2990/2990 [==============================] - 1s 327us/step - loss: -3.6656e-05 - accuracy: 0.9803\n",
      "At the end of episode 807 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "2821/2821 [==============================] - 1s 307us/step - loss: 0.0032 - accuracy: 0.9869\n",
      "At the end of episode 808 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2114/2114 [==============================] - 1s 315us/step - loss: 2.6364e-04 - accuracy: 0.9787\n",
      "At the end of episode 809 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1990/1990 [==============================] - 1s 305us/step - loss: -0.0011 - accuracy: 0.9844\n",
      "At the end of episode 810 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2888/2888 [==============================] - 1s 303us/step - loss: 0.0058 - accuracy: 0.9803\n",
      "At the end of episode 811 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1960/1960 [==============================] - 1s 307us/step - loss: -0.0094 - accuracy: 0.9842\n",
      "At the end of episode 812 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1664/1664 [==============================] - 0s 293us/step - loss: 0.0033 - accuracy: 0.9880\n",
      "At the end of episode 813 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2871/2871 [==============================] - 1s 302us/step - loss: 1.2031e-04 - accuracy: 0.9829\n",
      "At the end of episode 814 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1847/1847 [==============================] - 1s 298us/step - loss: -0.0087 - accuracy: 0.9859\n",
      "At the end of episode 815 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2230/2230 [==============================] - 1s 305us/step - loss: -6.1571e-05 - accuracy: 0.9789\n",
      "At the end of episode 816 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2192/2192 [==============================] - 1s 292us/step - loss: -0.0072 - accuracy: 0.9831\n",
      "At the end of episode 817 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1788/1788 [==============================] - 1s 305us/step - loss: -5.5514e-04 - accuracy: 0.9843\n",
      "At the end of episode 818 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2400/2400 [==============================] - 1s 295us/step - loss: -0.0050 - accuracy: 0.9850\n",
      "At the end of episode 819 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2329/2329 [==============================] - 1s 291us/step - loss: -4.6832e-04 - accuracy: 0.9802\n",
      "At the end of episode 820 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2289/2289 [==============================] - 1s 299us/step - loss: -0.0071 - accuracy: 0.9795\n",
      "At the end of episode 821 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2314/2314 [==============================] - 1s 293us/step - loss: -5.0135e-04 - accuracy: 0.9797\n",
      "At the end of episode 822 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2015/2015 [==============================] - 1s 293us/step - loss: -0.0055 - accuracy: 0.9816\n",
      "At the end of episode 823 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2715/2715 [==============================] - 1s 296us/step - loss: -2.4859e-04 - accuracy: 0.9897\n",
      "At the end of episode 824 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2761/2761 [==============================] - 1s 302us/step - loss: -0.0068 - accuracy: 0.9833\n",
      "At the end of episode 825 the total reward was : -12.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3530/3530 [==============================] - 1s 301us/step - loss: 0.0020 - accuracy: 0.9805\n",
      "At the end of episode 826 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3368/3368 [==============================] - 1s 300us/step - loss: -0.0073 - accuracy: 0.9798\n",
      "At the end of episode 827 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2180/2180 [==============================] - 1s 302us/step - loss: 0.0075 - accuracy: 0.9862\n",
      "At the end of episode 828 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 1s 298us/step - loss: -0.0060 - accuracy: 0.9792\n",
      "At the end of episode 829 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1952/1952 [==============================] - 1s 289us/step - loss: 0.0116 - accuracy: 0.9841\n",
      "At the end of episode 830 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1930/1930 [==============================] - 1s 289us/step - loss: 0.0039 - accuracy: 0.9881\n",
      "At the end of episode 831 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2885/2885 [==============================] - 1s 293us/step - loss: 0.0034 - accuracy: 0.9795\n",
      "At the end of episode 832 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2153/2153 [==============================] - 1s 284us/step - loss: 0.0049 - accuracy: 0.9754\n",
      "At the end of episode 833 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2221/2221 [==============================] - 1s 299us/step - loss: -0.0085 - accuracy: 0.9725\n",
      "At the end of episode 834 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2126/2126 [==============================] - 1s 291us/step - loss: 0.0139 - accuracy: 0.9826\n",
      "At the end of episode 835 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2523/2523 [==============================] - 1s 283us/step - loss: 0.0050 - accuracy: 0.9770\n",
      "At the end of episode 836 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2715/2715 [==============================] - 1s 288us/step - loss: 0.0142 - accuracy: 0.9816\n",
      "At the end of episode 837 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2310/2310 [==============================] - 1s 292us/step - loss: 0.0146 - accuracy: 0.9840\n",
      "At the end of episode 838 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2731/2731 [==============================] - 1s 303us/step - loss: -5.6169e-04 - accuracy: 0.9861\n",
      "At the end of episode 839 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2618/2618 [==============================] - 1s 325us/step - loss: -5.7916e-04 - accuracy: 0.9847\n",
      "At the end of episode 840 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "2660/2660 [==============================] - 1s 299us/step - loss: 0.0102 - accuracy: 0.9789\n",
      "At the end of episode 841 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2571/2571 [==============================] - 1s 298us/step - loss: -0.0037 - accuracy: 0.9806\n",
      "At the end of episode 842 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2592/2592 [==============================] - 1s 296us/step - loss: 0.0131 - accuracy: 0.9811\n",
      "At the end of episode 843 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3020/3020 [==============================] - 1s 293us/step - loss: -0.0045 - accuracy: 0.9815\n",
      "At the end of episode 844 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2347/2347 [==============================] - 1s 287us/step - loss: -2.0333e-04 - accuracy: 0.9791\n",
      "At the end of episode 845 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2329/2329 [==============================] - 1s 293us/step - loss: 0.0111 - accuracy: 0.9820\n",
      "At the end of episode 846 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2110/2110 [==============================] - 1s 283us/step - loss: 0.0101 - accuracy: 0.9791\n",
      "At the end of episode 847 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 1s 289us/step - loss: 0.0052 - accuracy: 0.9805\n",
      "At the end of episode 848 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2406/2406 [==============================] - 1s 290us/step - loss: 0.0025 - accuracy: 0.9759\n",
      "At the end of episode 849 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 1s 306us/step - loss: 0.0105 - accuracy: 0.9769\n",
      "At the end of episode 850 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2990/2990 [==============================] - 1s 287us/step - loss: 0.0060 - accuracy: 0.9833\n",
      "At the end of episode 851 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2501/2501 [==============================] - 1s 300us/step - loss: 0.0069 - accuracy: 0.9784\n",
      "At the end of episode 852 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2651/2651 [==============================] - 1s 290us/step - loss: 0.0031 - accuracy: 0.9815\n",
      "At the end of episode 853 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2224/2224 [==============================] - 1s 285us/step - loss: 0.0056 - accuracy: 0.9834\n",
      "At the end of episode 854 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2326/2326 [==============================] - 1s 289us/step - loss: -0.0075 - accuracy: 0.9837\n",
      "At the end of episode 855 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2438/2438 [==============================] - 1s 305us/step - loss: -0.0012 - accuracy: 0.9754\n",
      "At the end of episode 856 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2563/2563 [==============================] - 1s 311us/step - loss: 0.0026 - accuracy: 0.9824\n",
      "At the end of episode 857 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2897/2897 [==============================] - 1s 296us/step - loss: -5.5473e-04 - accuracy: 0.9821\n",
      "At the end of episode 858 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2567/2567 [==============================] - 1s 296us/step - loss: 0.0083 - accuracy: 0.9825\n",
      "At the end of episode 859 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2666/2666 [==============================] - 1s 295us/step - loss: 0.0021 - accuracy: 0.9839\n",
      "At the end of episode 860 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2254/2254 [==============================] - 1s 304us/step - loss: 0.0134 - accuracy: 0.9862\n",
      "At the end of episode 861 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 1s 306us/step - loss: 0.0017 - accuracy: 0.9801\n",
      "At the end of episode 862 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2517/2517 [==============================] - 1s 297us/step - loss: -0.0052 - accuracy: 0.9789\n",
      "At the end of episode 863 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2199/2199 [==============================] - 1s 301us/step - loss: 0.0036 - accuracy: 0.9814\n",
      "At the end of episode 864 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2109/2109 [==============================] - 1s 300us/step - loss: 0.0098 - accuracy: 0.9815\n",
      "At the end of episode 865 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2076/2076 [==============================] - 1s 305us/step - loss: 0.0053 - accuracy: 0.9870\n",
      "At the end of episode 866 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2382/2382 [==============================] - 1s 300us/step - loss: 0.0048 - accuracy: 0.9882\n",
      "At the end of episode 867 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2658/2658 [==============================] - 1s 296us/step - loss: -0.0021 - accuracy: 0.9812\n",
      "At the end of episode 868 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2837/2837 [==============================] - 1s 312us/step - loss: -6.5253e-04 - accuracy: 0.9725\n",
      "At the end of episode 869 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 1s 296us/step - loss: 0.0102 - accuracy: 0.9749\n",
      "At the end of episode 870 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2420/2420 [==============================] - 1s 292us/step - loss: -0.0051 - accuracy: 0.9847\n",
      "At the end of episode 871 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2079/2079 [==============================] - 1s 299us/step - loss: -0.0105 - accuracy: 0.9817\n",
      "At the end of episode 872 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2374/2374 [==============================] - 1s 297us/step - loss: -0.0044 - accuracy: 0.9777\n",
      "At the end of episode 873 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2083/2083 [==============================] - 1s 307us/step - loss: -0.0074 - accuracy: 0.9779\n",
      "At the end of episode 874 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2392/2392 [==============================] - 1s 291us/step - loss: -0.0024 - accuracy: 0.9695\n",
      "At the end of episode 875 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2196/2196 [==============================] - 1s 313us/step - loss: -6.0526e-04 - accuracy: 0.9772\n",
      "At the end of episode 876 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1971/1971 [==============================] - 1s 302us/step - loss: 0.0064 - accuracy: 0.9827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At the end of episode 877 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2607/2607 [==============================] - 1s 306us/step - loss: 0.0156 - accuracy: 0.9785\n",
      "At the end of episode 878 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2161/2161 [==============================] - 1s 296us/step - loss: -0.0026 - accuracy: 0.9741\n",
      "At the end of episode 879 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2350/2350 [==============================] - 1s 301us/step - loss: -0.0010 - accuracy: 0.9821\n",
      "At the end of episode 880 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1792/1792 [==============================] - 1s 284us/step - loss: 0.0170 - accuracy: 0.9794\n",
      "At the end of episode 881 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2266/2266 [==============================] - 1s 298us/step - loss: -0.0047 - accuracy: 0.9801\n",
      "At the end of episode 882 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1833/1833 [==============================] - 1s 298us/step - loss: -0.0083 - accuracy: 0.9825\n",
      "At the end of episode 883 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2520/2520 [==============================] - 1s 303us/step - loss: -0.0041 - accuracy: 0.9794\n",
      "At the end of episode 884 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2093/2093 [==============================] - 1s 285us/step - loss: 0.0115 - accuracy: 0.9842\n",
      "At the end of episode 885 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1843/1843 [==============================] - 1s 299us/step - loss: 0.0129 - accuracy: 0.9691\n",
      "At the end of episode 886 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1974/1974 [==============================] - 1s 291us/step - loss: 0.0098 - accuracy: 0.9757\n",
      "At the end of episode 887 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2592/2592 [==============================] - 1s 289us/step - loss: 0.0031 - accuracy: 0.9788\n",
      "At the end of episode 888 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2099/2099 [==============================] - 1s 312us/step - loss: 0.0094 - accuracy: 0.9757\n",
      "At the end of episode 889 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2318/2318 [==============================] - 1s 300us/step - loss: -1.5058e-04 - accuracy: 0.9814\n",
      "At the end of episode 890 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2269/2269 [==============================] - 1s 299us/step - loss: -9.1929e-04 - accuracy: 0.9863\n",
      "At the end of episode 891 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2382/2382 [==============================] - 1s 304us/step - loss: -0.0036 - accuracy: 0.9857\n",
      "At the end of episode 892 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2448/2448 [==============================] - 1s 291us/step - loss: -0.0052 - accuracy: 0.9824\n",
      "At the end of episode 893 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2301/2301 [==============================] - 1s 286us/step - loss: 0.0035 - accuracy: 0.9839\n",
      "At the end of episode 894 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2568/2568 [==============================] - 1s 298us/step - loss: -0.0085 - accuracy: 0.9782\n",
      "At the end of episode 895 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1995/1995 [==============================] - 1s 307us/step - loss: 0.0052 - accuracy: 0.9799\n",
      "At the end of episode 896 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2376/2376 [==============================] - 1s 290us/step - loss: 0.0087 - accuracy: 0.9802\n",
      "At the end of episode 897 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2370/2370 [==============================] - 1s 300us/step - loss: -0.0044 - accuracy: 0.9840\n",
      "At the end of episode 898 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2668/2668 [==============================] - 1s 298us/step - loss: 0.0093 - accuracy: 0.9835\n",
      "At the end of episode 899 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2158/2158 [==============================] - 1s 300us/step - loss: 5.8360e-04 - accuracy: 0.9778\n",
      "At the end of episode 900 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2467/2467 [==============================] - 1s 290us/step - loss: 0.0042 - accuracy: 0.9809\n",
      "At the end of episode 901 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 1s 299us/step - loss: -0.0034 - accuracy: 0.9860\n",
      "At the end of episode 902 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2335/2335 [==============================] - 1s 323us/step - loss: -2.9483e-05 - accuracy: 0.9872\n",
      "At the end of episode 903 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2116/2116 [==============================] - 1s 304us/step - loss: 0.0123 - accuracy: 0.9853\n",
      "At the end of episode 904 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2509/2509 [==============================] - 1s 294us/step - loss: -0.0036 - accuracy: 0.9825\n",
      "At the end of episode 905 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2453/2453 [==============================] - 1s 296us/step - loss: 6.3295e-04 - accuracy: 0.9874\n",
      "At the end of episode 906 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2032/2032 [==============================] - 1s 294us/step - loss: 0.0034 - accuracy: 0.9867\n",
      "At the end of episode 907 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2744/2744 [==============================] - 1s 303us/step - loss: 0.0068 - accuracy: 0.9767\n",
      "At the end of episode 908 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2530/2530 [==============================] - 1s 302us/step - loss: -0.0067 - accuracy: 0.9775\n",
      "At the end of episode 909 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2001/2001 [==============================] - 1s 307us/step - loss: 0.0029 - accuracy: 0.9835\n",
      "At the end of episode 910 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2243/2243 [==============================] - 1s 297us/step - loss: 0.0031 - accuracy: 0.9786\n",
      "At the end of episode 911 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2346/2346 [==============================] - 1s 303us/step - loss: 0.0040 - accuracy: 0.9719\n",
      "At the end of episode 912 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1455/1455 [==============================] - 0s 291us/step - loss: 0.0033 - accuracy: 0.9787\n",
      "At the end of episode 913 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2099/2099 [==============================] - 1s 328us/step - loss: -0.0087 - accuracy: 0.9762\n",
      "At the end of episode 914 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1341/1341 [==============================] - 0s 294us/step - loss: 0.0013 - accuracy: 0.9843\n",
      "At the end of episode 915 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2147/2147 [==============================] - 1s 304us/step - loss: 0.0045 - accuracy: 0.9781\n",
      "At the end of episode 916 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1348/1348 [==============================] - 0s 293us/step - loss: 3.4616e-04 - accuracy: 0.9866\n",
      "At the end of episode 917 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "1948/1948 [==============================] - 1s 308us/step - loss: 0.0029 - accuracy: 0.9790\n",
      "At the end of episode 918 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "1900/1900 [==============================] - 1s 298us/step - loss: 0.0045 - accuracy: 0.9726\n",
      "At the end of episode 919 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "2725/2725 [==============================] - 1s 300us/step - loss: -0.0064 - accuracy: 0.9761\n",
      "At the end of episode 920 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1920/1920 [==============================] - 1s 286us/step - loss: 0.0073 - accuracy: 0.9828\n",
      "At the end of episode 921 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2303/2303 [==============================] - 1s 322us/step - loss: -0.0135 - accuracy: 0.9748\n",
      "At the end of episode 922 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2752/2752 [==============================] - 1s 291us/step - loss: -0.0022 - accuracy: 0.9869\n",
      "At the end of episode 923 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2994/2994 [==============================] - 1s 308us/step - loss: -0.0062 - accuracy: 0.9816\n",
      "At the end of episode 924 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1817/1817 [==============================] - 1s 292us/step - loss: -0.0254 - accuracy: 0.9747\n",
      "At the end of episode 925 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2069/2069 [==============================] - 1s 291us/step - loss: 0.0064 - accuracy: 0.9826\n",
      "At the end of episode 926 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2281/2281 [==============================] - 1s 310us/step - loss: 0.0128 - accuracy: 0.9763\n",
      "At the end of episode 927 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1938/1938 [==============================] - 1s 310us/step - loss: -0.0126 - accuracy: 0.9799\n",
      "At the end of episode 928 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2588/2588 [==============================] - 1s 303us/step - loss: 0.0038 - accuracy: 0.9826\n",
      "At the end of episode 929 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2668/2668 [==============================] - 1s 303us/step - loss: 0.0114 - accuracy: 0.9854\n",
      "At the end of episode 930 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2851/2851 [==============================] - 1s 299us/step - loss: -0.0030 - accuracy: 0.9807\n",
      "At the end of episode 931 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2197/2197 [==============================] - 1s 293us/step - loss: -0.0031 - accuracy: 0.9795\n",
      "At the end of episode 932 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2087/2087 [==============================] - 1s 303us/step - loss: -0.0030 - accuracy: 0.9818\n",
      "At the end of episode 933 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3080/3080 [==============================] - 1s 287us/step - loss: 0.0026 - accuracy: 0.9812\n",
      "At the end of episode 934 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2667/2667 [==============================] - 1s 326us/step - loss: -0.0070 - accuracy: 0.9843\n",
      "At the end of episode 935 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2434/2434 [==============================] - 1s 316us/step - loss: 0.0051 - accuracy: 0.9856\n",
      "At the end of episode 936 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1924/1924 [==============================] - 1s 296us/step - loss: -0.0014 - accuracy: 0.9808\n",
      "At the end of episode 937 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2753/2753 [==============================] - 1s 307us/step - loss: 0.0037 - accuracy: 0.9862\n",
      "At the end of episode 938 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2798/2798 [==============================] - 1s 297us/step - loss: -0.0068 - accuracy: 0.9836\n",
      "At the end of episode 939 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2569/2569 [==============================] - 1s 294us/step - loss: -0.0017 - accuracy: 0.9837\n",
      "At the end of episode 940 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2753/2753 [==============================] - 1s 290us/step - loss: -0.0036 - accuracy: 0.9764\n",
      "At the end of episode 941 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2334/2334 [==============================] - 1s 294us/step - loss: -0.0019 - accuracy: 0.9854\n",
      "At the end of episode 942 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3014/3014 [==============================] - 1s 286us/step - loss: 4.7803e-04 - accuracy: 0.9837\n",
      "At the end of episode 943 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2533/2533 [==============================] - 1s 289us/step - loss: 0.0048 - accuracy: 0.9807\n",
      "At the end of episode 944 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 1s 286us/step - loss: 0.0074 - accuracy: 0.9733\n",
      "At the end of episode 945 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2143/2143 [==============================] - 1s 300us/step - loss: -0.0019 - accuracy: 0.9776\n",
      "At the end of episode 946 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2188/2188 [==============================] - 1s 298us/step - loss: -0.0080 - accuracy: 0.9753\n",
      "At the end of episode 947 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2089/2089 [==============================] - 1s 291us/step - loss: 0.0013 - accuracy: 0.9823\n",
      "At the end of episode 948 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2056/2056 [==============================] - 1s 301us/step - loss: -0.0082 - accuracy: 0.9839\n",
      "At the end of episode 949 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1906/1906 [==============================] - 1s 289us/step - loss: -4.3372e-04 - accuracy: 0.9864\n",
      "At the end of episode 950 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2016/2016 [==============================] - 1s 289us/step - loss: 0.0038 - accuracy: 0.9871\n",
      "At the end of episode 951 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2262/2262 [==============================] - 1s 318us/step - loss: -0.0080 - accuracy: 0.9739\n",
      "At the end of episode 952 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2527/2527 [==============================] - 1s 286us/step - loss: 0.0055 - accuracy: 0.9854\n",
      "At the end of episode 953 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2966/2966 [==============================] - 1s 288us/step - loss: -0.0078 - accuracy: 0.9777\n",
      "At the end of episode 954 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2814/2814 [==============================] - 1s 300us/step - loss: 0.0022 - accuracy: 0.9765\n",
      "At the end of episode 955 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2739/2739 [==============================] - 1s 286us/step - loss: 0.0082 - accuracy: 0.9880\n",
      "At the end of episode 956 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2859/2859 [==============================] - 1s 305us/step - loss: -1.6849e-04 - accuracy: 0.9867\n",
      "At the end of episode 957 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2533/2533 [==============================] - 1s 294us/step - loss: -0.0022 - accuracy: 0.9862\n",
      "At the end of episode 958 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2341/2341 [==============================] - 1s 304us/step - loss: 0.0053 - accuracy: 0.9821\n",
      "At the end of episode 959 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2769/2769 [==============================] - 1s 300us/step - loss: 0.0034 - accuracy: 0.9769\n",
      "At the end of episode 960 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1801/1801 [==============================] - 1s 296us/step - loss: 0.0137 - accuracy: 0.9822\n",
      "At the end of episode 961 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "2889/2889 [==============================] - 1s 297us/step - loss: -0.0022 - accuracy: 0.9765\n",
      "At the end of episode 962 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2733/2733 [==============================] - 1s 297us/step - loss: 0.0011 - accuracy: 0.9832\n",
      "At the end of episode 963 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2317/2317 [==============================] - 1s 307us/step - loss: 0.0061 - accuracy: 0.9827\n",
      "At the end of episode 964 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2424/2424 [==============================] - 1s 314us/step - loss: -0.0029 - accuracy: 0.9847\n",
      "At the end of episode 965 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 1s 301us/step - loss: -7.4076e-04 - accuracy: 0.9794\n",
      "At the end of episode 966 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2547/2547 [==============================] - 1s 302us/step - loss: -0.0024 - accuracy: 0.9863\n",
      "At the end of episode 967 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2017/2017 [==============================] - 1s 306us/step - loss: 0.0091 - accuracy: 0.9826\n",
      "At the end of episode 968 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2667/2667 [==============================] - 1s 312us/step - loss: -0.0062 - accuracy: 0.9865\n",
      "At the end of episode 969 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2450/2450 [==============================] - 1s 298us/step - loss: -0.0036 - accuracy: 0.9829\n",
      "At the end of episode 970 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2678/2678 [==============================] - 1s 301us/step - loss: 0.0044 - accuracy: 0.9772\n",
      "At the end of episode 971 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 1s 308us/step - loss: 0.0142 - accuracy: 0.9828\n",
      "At the end of episode 972 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2310/2310 [==============================] - 1s 298us/step - loss: 0.0068 - accuracy: 0.9823\n",
      "At the end of episode 973 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2324/2324 [==============================] - 1s 298us/step - loss: 0.0036 - accuracy: 0.9819\n",
      "At the end of episode 974 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 1s 406us/step - loss: 0.0027 - accuracy: 0.9861\n",
      "At the end of episode 975 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1915/1915 [==============================] - 1s 313us/step - loss: -0.0018 - accuracy: 0.9802\n",
      "At the end of episode 976 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2772/2772 [==============================] - 1s 287us/step - loss: -9.6959e-04 - accuracy: 0.9820\n",
      "At the end of episode 977 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2938/2938 [==============================] - 1s 310us/step - loss: 0.0043 - accuracy: 0.9860\n",
      "At the end of episode 978 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2943/2943 [==============================] - 1s 480us/step - loss: -0.0032 - accuracy: 0.9844\n",
      "At the end of episode 979 the total reward was : -15.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2518/2518 [==============================] - 1s 481us/step - loss: 0.0082 - accuracy: 0.9817\n",
      "At the end of episode 980 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2592/2592 [==============================] - 1s 453us/step - loss: -0.0064 - accuracy: 0.9865\n",
      "At the end of episode 981 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1836/1836 [==============================] - 1s 354us/step - loss: 0.0115 - accuracy: 0.9831\n",
      "At the end of episode 982 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2420/2420 [==============================] - 1s 309us/step - loss: -0.0076 - accuracy: 0.9814\n",
      "At the end of episode 983 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2167/2167 [==============================] - 1s 293us/step - loss: 0.0018 - accuracy: 0.9843\n",
      "At the end of episode 984 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2420/2420 [==============================] - 1s 305us/step - loss: -3.9021e-05 - accuracy: 0.9814\n",
      "At the end of episode 985 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2296/2296 [==============================] - 1s 306us/step - loss: 0.0131 - accuracy: 0.9804\n",
      "At the end of episode 986 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2568/2568 [==============================] - 1s 294us/step - loss: -0.0016 - accuracy: 0.9809\n",
      "At the end of episode 987 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 1s 308us/step - loss: 0.0166 - accuracy: 0.9835\n",
      "At the end of episode 988 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2509/2509 [==============================] - 1s 293us/step - loss: 0.0039 - accuracy: 0.9825\n",
      "At the end of episode 989 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2386/2386 [==============================] - 1s 295us/step - loss: 0.0084 - accuracy: 0.9816\n",
      "At the end of episode 990 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2561/2561 [==============================] - 1s 323us/step - loss: 0.0117 - accuracy: 0.9840\n",
      "At the end of episode 991 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2370/2370 [==============================] - 1s 325us/step - loss: 0.0142 - accuracy: 0.9857\n",
      "At the end of episode 992 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2615/2615 [==============================] - 1s 343us/step - loss: 9.2968e-04 - accuracy: 0.9786\n",
      "At the end of episode 993 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "1957/1957 [==============================] - 1s 358us/step - loss: -0.0058 - accuracy: 0.9847\n",
      "At the end of episode 994 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2623/2623 [==============================] - 1s 311us/step - loss: -0.0054 - accuracy: 0.9832\n",
      "At the end of episode 995 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2280/2280 [==============================] - 1s 389us/step - loss: -0.0107 - accuracy: 0.9851\n",
      "At the end of episode 996 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2015/2015 [==============================] - 1s 351us/step - loss: 0.0166 - accuracy: 0.9772\n",
      "At the end of episode 997 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1805/1805 [==============================] - 1s 436us/step - loss: -0.0028 - accuracy: 0.9823\n",
      "At the end of episode 998 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2084/2084 [==============================] - 1s 301us/step - loss: 0.0045 - accuracy: 0.9770\n",
      "At the end of episode 999 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2723/2723 [==============================] - 1s 282us/step - loss: 0.0038 - accuracy: 0.9827\n",
      "At the end of episode 1000 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2579/2579 [==============================] - 1s 276us/step - loss: 0.0047 - accuracy: 0.9787\n",
      "At the end of episode 1001 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3024/3024 [==============================] - 1s 282us/step - loss: -3.4104e-04 - accuracy: 0.9828\n",
      "At the end of episode 1002 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2353/2353 [==============================] - 1s 284us/step - loss: 7.3902e-04 - accuracy: 0.9826\n",
      "At the end of episode 1003 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1961/1961 [==============================] - 1s 304us/step - loss: 0.0023 - accuracy: 0.9796\n",
      "At the end of episode 1004 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2197/2197 [==============================] - 1s 355us/step - loss: -0.0074 - accuracy: 0.9841\n",
      "At the end of episode 1005 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2840/2840 [==============================] - 1s 275us/step - loss: -0.0080 - accuracy: 0.9813\n",
      "At the end of episode 1006 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2252/2252 [==============================] - 1s 287us/step - loss: -0.0107 - accuracy: 0.9800\n",
      "At the end of episode 1007 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2630/2630 [==============================] - 1s 293us/step - loss: 0.0240 - accuracy: 0.9776\n",
      "At the end of episode 1008 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2988/2988 [==============================] - 1s 288us/step - loss: 0.0012 - accuracy: 0.9779\n",
      "At the end of episode 1009 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2311/2311 [==============================] - 1s 312us/step - loss: -0.0038 - accuracy: 0.9792\n",
      "At the end of episode 1010 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2516/2516 [==============================] - 1s 324us/step - loss: -0.0020 - accuracy: 0.9881\n",
      "At the end of episode 1011 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 1s 279us/step - loss: 0.0021 - accuracy: 0.9879\n",
      "At the end of episode 1012 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2320/2320 [==============================] - 1s 285us/step - loss: 0.0058 - accuracy: 0.9892\n",
      "At the end of episode 1013 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1885/1885 [==============================] - 1s 295us/step - loss: 9.5099e-04 - accuracy: 0.9793\n",
      "At the end of episode 1014 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2606/2606 [==============================] - 1s 291us/step - loss: -3.5701e-05 - accuracy: 0.9847\n",
      "At the end of episode 1015 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2609/2609 [==============================] - 1s 297us/step - loss: 0.0033 - accuracy: 0.9893 0s - loss: -0.0014 - a\n",
      "At the end of episode 1016 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2728/2728 [==============================] - 1s 288us/step - loss: -0.0065 - accuracy: 0.9864\n",
      "At the end of episode 1017 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2145/2145 [==============================] - 1s 299us/step - loss: -0.0042 - accuracy: 0.9832\n",
      "At the end of episode 1018 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2727/2727 [==============================] - 1s 298us/step - loss: -0.0045 - accuracy: 0.9875\n",
      "At the end of episode 1019 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2329/2329 [==============================] - 1s 305us/step - loss: 0.0014 - accuracy: 0.9841\n",
      "At the end of episode 1020 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2902/2902 [==============================] - 1s 314us/step - loss: -0.0023 - accuracy: 0.9852\n",
      "At the end of episode 1021 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2206/2206 [==============================] - 1s 290us/step - loss: 0.0108 - accuracy: 0.9873\n",
      "At the end of episode 1022 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1852/1852 [==============================] - 1s 371us/step - loss: 0.0080 - accuracy: 0.9789\n",
      "At the end of episode 1023 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2593/2593 [==============================] - 1s 332us/step - loss: -3.4005e-04 - accuracy: 0.9877\n",
      "At the end of episode 1024 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2688/2688 [==============================] - 1s 302us/step - loss: 0.0011 - accuracy: 0.9807\n",
      "At the end of episode 1025 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2049/2049 [==============================] - 1s 309us/step - loss: 0.0159 - accuracy: 0.9844\n",
      "At the end of episode 1026 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2854/2854 [==============================] - 1s 300us/step - loss: -4.5794e-04 - accuracy: 0.9898\n",
      "At the end of episode 1027 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2593/2593 [==============================] - 1s 314us/step - loss: 0.0020 - accuracy: 0.9869\n",
      "At the end of episode 1028 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2887/2887 [==============================] - 1s 327us/step - loss: -5.8214e-04 - accuracy: 0.9796\n",
      "At the end of episode 1029 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2901/2901 [==============================] - 1s 326us/step - loss: -0.0017 - accuracy: 0.9848\n",
      "At the end of episode 1030 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2862/2862 [==============================] - 1s 346us/step - loss: 0.0024 - accuracy: 0.9829\n",
      "At the end of episode 1031 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2169/2169 [==============================] - 1s 362us/step - loss: 0.0084 - accuracy: 0.9862\n",
      "At the end of episode 1032 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2236/2236 [==============================] - 1s 289us/step - loss: 0.0043 - accuracy: 0.9861\n",
      "At the end of episode 1033 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2623/2623 [==============================] - 1s 284us/step - loss: 0.0022 - accuracy: 0.9855\n",
      "At the end of episode 1034 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2092/2092 [==============================] - 1s 283us/step - loss: 0.0046 - accuracy: 0.9876\n",
      "At the end of episode 1035 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2353/2353 [==============================] - 1s 298us/step - loss: 0.0011 - accuracy: 0.9809\n",
      "At the end of episode 1036 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2762/2762 [==============================] - 1s 287us/step - loss: 0.0155 - accuracy: 0.9790\n",
      "At the end of episode 1037 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2637/2637 [==============================] - 1s 295us/step - loss: 0.0051 - accuracy: 0.9841\n",
      "At the end of episode 1038 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2420/2420 [==============================] - 1s 279us/step - loss: 0.0010 - accuracy: 0.9868\n",
      "At the end of episode 1039 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1753/1753 [==============================] - 1s 286us/step - loss: -0.0076 - accuracy: 0.9903\n",
      "At the end of episode 1040 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2294/2294 [==============================] - 1s 278us/step - loss: -8.7236e-04 - accuracy: 0.9852\n",
      "At the end of episode 1041 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1866/1866 [==============================] - 1s 297us/step - loss: -9.9004e-04 - accuracy: 0.9802\n",
      "At the end of episode 1042 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2604/2604 [==============================] - 1s 283us/step - loss: 5.2478e-04 - accuracy: 0.9854\n",
      "At the end of episode 1043 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2324/2324 [==============================] - 1s 286us/step - loss: 0.0019 - accuracy: 0.9824\n",
      "At the end of episode 1044 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2224/2224 [==============================] - 1s 291us/step - loss: 0.0016 - accuracy: 0.9820\n",
      "At the end of episode 1045 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "2818/2818 [==============================] - 1s 273us/step - loss: -0.0069 - accuracy: 0.9837\n",
      "At the end of episode 1046 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2672/2672 [==============================] - 1s 281us/step - loss: -0.0062 - accuracy: 0.9794\n",
      "At the end of episode 1047 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2828/2828 [==============================] - 1s 273us/step - loss: 0.0108 - accuracy: 0.9848\n",
      "At the end of episode 1048 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2162/2162 [==============================] - 1s 280us/step - loss: 0.0107 - accuracy: 0.9861\n",
      "At the end of episode 1049 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2314/2314 [==============================] - 1s 296us/step - loss: 0.0018 - accuracy: 0.9866\n",
      "At the end of episode 1050 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2306/2306 [==============================] - 1s 280us/step - loss: -0.0034 - accuracy: 0.9801\n",
      "At the end of episode 1051 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2202/2202 [==============================] - 1s 288us/step - loss: 0.0025 - accuracy: 0.9873\n",
      "At the end of episode 1052 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2554/2554 [==============================] - 1s 300us/step - loss: -4.0881e-04 - accuracy: 0.9832\n",
      "At the end of episode 1053 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2198/2198 [==============================] - 1s 290us/step - loss: 0.0020 - accuracy: 0.9882\n",
      "At the end of episode 1054 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2294/2294 [==============================] - 1s 289us/step - loss: 0.0026 - accuracy: 0.9882\n",
      "At the end of episode 1055 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2032/2032 [==============================] - 1s 288us/step - loss: 0.0041 - accuracy: 0.9897\n",
      "At the end of episode 1056 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2306/2306 [==============================] - 1s 284us/step - loss: -0.0018 - accuracy: 0.9853\n",
      "At the end of episode 1057 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2236/2236 [==============================] - 1s 280us/step - loss: -0.0090 - accuracy: 0.9843\n",
      "At the end of episode 1058 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2365/2365 [==============================] - 1s 293us/step - loss: 0.0175 - accuracy: 0.9814\n",
      "At the end of episode 1059 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2733/2733 [==============================] - 1s 295us/step - loss: 0.0058 - accuracy: 0.9865\n",
      "At the end of episode 1060 the total reward was : -11.0\n",
      "Epoch 1/1\n",
      "2963/2963 [==============================] - 1s 292us/step - loss: -0.0063 - accuracy: 0.9848\n",
      "At the end of episode 1061 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 1s 278us/step - loss: -0.0025 - accuracy: 0.9870\n",
      "At the end of episode 1062 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2208/2208 [==============================] - 1s 288us/step - loss: 0.0069 - accuracy: 0.9891\n",
      "At the end of episode 1063 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 1s 277us/step - loss: -0.0021 - accuracy: 0.9892\n",
      "At the end of episode 1064 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2163/2163 [==============================] - 1s 281us/step - loss: 0.0013 - accuracy: 0.9875\n",
      "At the end of episode 1065 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2539/2539 [==============================] - 1s 278us/step - loss: 0.0020 - accuracy: 0.9882\n",
      "At the end of episode 1066 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2392/2392 [==============================] - 1s 291us/step - loss: -0.0022 - accuracy: 0.9879\n",
      "At the end of episode 1067 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2037/2037 [==============================] - 1s 285us/step - loss: 0.0039 - accuracy: 0.9872\n",
      "At the end of episode 1068 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3489/3489 [==============================] - 1s 275us/step - loss: -0.0040 - accuracy: 0.9874\n",
      "At the end of episode 1069 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2660/2660 [==============================] - 1s 315us/step - loss: -0.0077 - accuracy: 0.9857\n",
      "At the end of episode 1070 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2123/2123 [==============================] - 1s 293us/step - loss: 0.0096 - accuracy: 0.9835\n",
      "At the end of episode 1071 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2512/2512 [==============================] - 1s 288us/step - loss: 0.0065 - accuracy: 0.9825\n",
      "At the end of episode 1072 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1909/1909 [==============================] - 1s 290us/step - loss: 4.0313e-04 - accuracy: 0.9838\n",
      "At the end of episode 1073 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2224/2224 [==============================] - 1s 301us/step - loss: -0.0022 - accuracy: 0.9838\n",
      "At the end of episode 1074 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2576/2576 [==============================] - 1s 279us/step - loss: -6.6936e-04 - accuracy: 0.9876\n",
      "At the end of episode 1075 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2672/2672 [==============================] - 1s 311us/step - loss: 0.0081 - accuracy: 0.9820\n",
      "At the end of episode 1076 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2286/2286 [==============================] - 1s 284us/step - loss: -0.0052 - accuracy: 0.9864\n",
      "At the end of episode 1077 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3137/3137 [==============================] - 1s 276us/step - loss: -0.0047 - accuracy: 0.9825\n",
      "At the end of episode 1078 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1874/1874 [==============================] - 1s 286us/step - loss: -0.0053 - accuracy: 0.9829\n",
      "At the end of episode 1079 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 1s 283us/step - loss: -0.0054 - accuracy: 0.9810\n",
      "At the end of episode 1080 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2274/2274 [==============================] - 1s 282us/step - loss: 0.0031 - accuracy: 0.9899\n",
      "At the end of episode 1081 the total reward was : -19.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2143/2143 [==============================] - 1s 272us/step - loss: -0.0025 - accuracy: 0.9818\n",
      "At the end of episode 1082 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2326/2326 [==============================] - 1s 296us/step - loss: -0.0011 - accuracy: 0.9837\n",
      "At the end of episode 1083 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2301/2301 [==============================] - 1s 291us/step - loss: 0.0035 - accuracy: 0.9844\n",
      "At the end of episode 1084 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2585/2585 [==============================] - 1s 299us/step - loss: -0.0067 - accuracy: 0.9810\n",
      "At the end of episode 1085 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2666/2666 [==============================] - 1s 293us/step - loss: -0.0044 - accuracy: 0.9797\n",
      "At the end of episode 1086 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2292/2292 [==============================] - 1s 297us/step - loss: -0.0041 - accuracy: 0.9895\n",
      "At the end of episode 1087 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2390/2390 [==============================] - 1s 281us/step - loss: -0.0065 - accuracy: 0.9862\n",
      "At the end of episode 1088 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1990/1990 [==============================] - 1s 280us/step - loss: 0.0025 - accuracy: 0.9849\n",
      "At the end of episode 1089 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2348/2348 [==============================] - 1s 289us/step - loss: 0.0045 - accuracy: 0.9813\n",
      "At the end of episode 1090 the total reward was : -11.0\n",
      "Epoch 1/1\n",
      "3053/3053 [==============================] - 1s 290us/step - loss: 2.6863e-04 - accuracy: 0.9843\n",
      "At the end of episode 1091 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2883/2883 [==============================] - 1s 280us/step - loss: -0.0097 - accuracy: 0.9775\n",
      "At the end of episode 1092 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2623/2623 [==============================] - 1s 279us/step - loss: 0.0011 - accuracy: 0.9855\n",
      "At the end of episode 1093 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2108/2108 [==============================] - 1s 271us/step - loss: -0.0016 - accuracy: 0.9858\n",
      "At the end of episode 1094 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2132/2132 [==============================] - 1s 282us/step - loss: -0.0075 - accuracy: 0.9855\n",
      "At the end of episode 1095 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2318/2318 [==============================] - 1s 297us/step - loss: 0.0251 - accuracy: 0.9849\n",
      "At the end of episode 1096 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3073/3073 [==============================] - 1s 285us/step - loss: -0.0027 - accuracy: 0.9847\n",
      "At the end of episode 1097 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3198/3198 [==============================] - 1s 280us/step - loss: -6.7972e-04 - accuracy: 0.9856\n",
      "At the end of episode 1098 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2865/2865 [==============================] - 1s 278us/step - loss: 0.0019 - accuracy: 0.9867\n",
      "At the end of episode 1099 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2095/2095 [==============================] - 1s 293us/step - loss: 2.7105e-04 - accuracy: 0.9876\n",
      "At the end of episode 1100 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2168/2168 [==============================] - 1s 276us/step - loss: 0.0023 - accuracy: 0.9908\n",
      "At the end of episode 1101 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2580/2580 [==============================] - 1s 294us/step - loss: -0.0050 - accuracy: 0.9779\n",
      "At the end of episode 1102 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2738/2738 [==============================] - 1s 279us/step - loss: 0.0010 - accuracy: 0.9785\n",
      "At the end of episode 1103 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2577/2577 [==============================] - 1s 292us/step - loss: -0.0051 - accuracy: 0.9860\n",
      "At the end of episode 1104 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2362/2362 [==============================] - 1s 319us/step - loss: -0.0032 - accuracy: 0.9860\n",
      "At the end of episode 1105 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2319/2319 [==============================] - 1s 283us/step - loss: -0.0023 - accuracy: 0.9879\n",
      "At the end of episode 1106 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2498/2498 [==============================] - 1s 274us/step - loss: -0.0010 - accuracy: 0.9832\n",
      "At the end of episode 1107 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 1s 281us/step - loss: 0.0040 - accuracy: 0.9852\n",
      "At the end of episode 1108 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1999/1999 [==============================] - 1s 288us/step - loss: 0.0014 - accuracy: 0.9915\n",
      "At the end of episode 1109 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2799/2799 [==============================] - 1s 295us/step - loss: -0.0039 - accuracy: 0.9893\n",
      "At the end of episode 1110 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2652/2652 [==============================] - 1s 273us/step - loss: -0.0113 - accuracy: 0.9744\n",
      "At the end of episode 1111 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2544/2544 [==============================] - 1s 278us/step - loss: -0.0076 - accuracy: 0.9858\n",
      "At the end of episode 1112 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2493/2493 [==============================] - 1s 295us/step - loss: -0.0020 - accuracy: 0.9880\n",
      "At the end of episode 1113 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2947/2947 [==============================] - 1s 314us/step - loss: 0.0047 - accuracy: 0.9837\n",
      "At the end of episode 1114 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2079/2079 [==============================] - 1s 294us/step - loss: -0.0012 - accuracy: 0.9841\n",
      "At the end of episode 1115 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3244/3244 [==============================] - 1s 297us/step - loss: 0.0100 - accuracy: 0.9830\n",
      "At the end of episode 1116 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1990/1990 [==============================] - 1s 284us/step - loss: 0.0102 - accuracy: 0.9834\n",
      "At the end of episode 1117 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2647/2647 [==============================] - 1s 304us/step - loss: -0.0076 - accuracy: 0.9841\n",
      "At the end of episode 1118 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2747/2747 [==============================] - 1s 285us/step - loss: -0.0071 - accuracy: 0.9851\n",
      "At the end of episode 1119 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2580/2580 [==============================] - 1s 294us/step - loss: -0.0020 - accuracy: 0.9880\n",
      "At the end of episode 1120 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 1s 294us/step - loss: 0.0011 - accuracy: 0.9842\n",
      "At the end of episode 1121 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1899/1899 [==============================] - 1s 294us/step - loss: 0.0044 - accuracy: 0.9837\n",
      "At the end of episode 1122 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1949/1949 [==============================] - 1s 300us/step - loss: -0.0067 - accuracy: 0.9800\n",
      "At the end of episode 1123 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1674/1674 [==============================] - 0s 286us/step - loss: -2.7877e-04 - accuracy: 0.9910\n",
      "At the end of episode 1124 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 1s 285us/step - loss: -0.0155 - accuracy: 0.9839\n",
      "At the end of episode 1125 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2152/2152 [==============================] - 1s 310us/step - loss: -0.0032 - accuracy: 0.9837\n",
      "At the end of episode 1126 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2026/2026 [==============================] - 1s 286us/step - loss: -0.0065 - accuracy: 0.9857\n",
      "At the end of episode 1127 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2350/2350 [==============================] - 1s 299us/step - loss: 0.0077 - accuracy: 0.9809\n",
      "At the end of episode 1128 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2713/2713 [==============================] - 1s 277us/step - loss: -0.0132 - accuracy: 0.9731\n",
      "At the end of episode 1129 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2161/2161 [==============================] - 1s 282us/step - loss: -0.0092 - accuracy: 0.9866\n",
      "At the end of episode 1130 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2400/2400 [==============================] - 1s 283us/step - loss: -6.5660e-04 - accuracy: 0.9887\n",
      "At the end of episode 1131 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2632/2632 [==============================] - 1s 295us/step - loss: -0.0015 - accuracy: 0.9852\n",
      "At the end of episode 1132 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2616/2616 [==============================] - 1s 291us/step - loss: -0.0026 - accuracy: 0.9817\n",
      "At the end of episode 1133 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1924/1924 [==============================] - 1s 333us/step - loss: 0.0015 - accuracy: 0.9854\n",
      "At the end of episode 1134 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2308/2308 [==============================] - 1s 283us/step - loss: 0.0013 - accuracy: 0.9840\n",
      "At the end of episode 1135 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2634/2634 [==============================] - 1s 281us/step - loss: -4.1616e-04 - accuracy: 0.9875\n",
      "At the end of episode 1136 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 1s 275us/step - loss: -0.0013 - accuracy: 0.9852\n",
      "At the end of episode 1137 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2678/2678 [==============================] - 1s 288us/step - loss: 3.7490e-04 - accuracy: 0.9873\n",
      "At the end of episode 1138 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2100/2100 [==============================] - 1s 285us/step - loss: 0.0093 - accuracy: 0.9852\n",
      "At the end of episode 1139 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2755/2755 [==============================] - 1s 293us/step - loss: -0.0050 - accuracy: 0.9858\n",
      "At the end of episode 1140 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2185/2185 [==============================] - 1s 290us/step - loss: -0.0088 - accuracy: 0.9835\n",
      "At the end of episode 1141 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2093/2093 [==============================] - 1s 276us/step - loss: -0.0014 - accuracy: 0.9943\n",
      "At the end of episode 1142 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2373/2373 [==============================] - 1s 276us/step - loss: -0.0102 - accuracy: 0.9882\n",
      "At the end of episode 1143 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2093/2093 [==============================] - 1s 285us/step - loss: 0.0088 - accuracy: 0.9838\n",
      "At the end of episode 1144 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2207/2207 [==============================] - 1s 306us/step - loss: -0.0020 - accuracy: 0.9928\n",
      "At the end of episode 1145 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2470/2470 [==============================] - 1s 282us/step - loss: -0.0049 - accuracy: 0.9862\n",
      "At the end of episode 1146 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2007/2007 [==============================] - 1s 276us/step - loss: -0.0081 - accuracy: 0.9900\n",
      "At the end of episode 1147 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 1s 277us/step - loss: 0.0040 - accuracy: 0.9861\n",
      "At the end of episode 1148 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2447/2447 [==============================] - 1s 304us/step - loss: 0.0026 - accuracy: 0.9828\n",
      "At the end of episode 1149 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2523/2523 [==============================] - 1s 297us/step - loss: -0.0074 - accuracy: 0.9830\n",
      "At the end of episode 1150 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 1s 302us/step - loss: -0.0038 - accuracy: 0.9876\n",
      "At the end of episode 1151 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2122/2122 [==============================] - 1s 295us/step - loss: -0.0104 - accuracy: 0.9807\n",
      "At the end of episode 1152 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2651/2651 [==============================] - 1s 278us/step - loss: -0.0039 - accuracy: 0.9838\n",
      "At the end of episode 1153 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2680/2680 [==============================] - 1s 292us/step - loss: 9.5375e-04 - accuracy: 0.9873\n",
      "At the end of episode 1154 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2545/2545 [==============================] - 1s 278us/step - loss: -0.0070 - accuracy: 0.9902\n",
      "At the end of episode 1155 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2819/2819 [==============================] - 1s 297us/step - loss: -0.0013 - accuracy: 0.9851\n",
      "At the end of episode 1156 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1863/1863 [==============================] - 1s 291us/step - loss: 0.0059 - accuracy: 0.9866\n",
      "At the end of episode 1157 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2227/2227 [==============================] - 1s 279us/step - loss: -0.0015 - accuracy: 0.9874\n",
      "At the end of episode 1158 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2257/2257 [==============================] - 1s 282us/step - loss: 0.0035 - accuracy: 0.9823\n",
      "At the end of episode 1159 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3017/3017 [==============================] - 1s 279us/step - loss: -0.0019 - accuracy: 0.9904\n",
      "At the end of episode 1160 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2636/2636 [==============================] - 1s 286us/step - loss: 0.0016 - accuracy: 0.9875\n",
      "At the end of episode 1161 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2583/2583 [==============================] - 1s 281us/step - loss: 0.0023 - accuracy: 0.9857\n",
      "At the end of episode 1162 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2007/2007 [==============================] - 1s 287us/step - loss: -0.0030 - accuracy: 0.9885\n",
      "At the end of episode 1163 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2319/2319 [==============================] - 1s 284us/step - loss: -0.0027 - accuracy: 0.9849\n",
      "At the end of episode 1164 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2495/2495 [==============================] - 1s 271us/step - loss: 0.0054 - accuracy: 0.9792\n",
      "At the end of episode 1165 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2601/2601 [==============================] - 1s 276us/step - loss: 3.8126e-04 - accuracy: 0.9835\n",
      "At the end of episode 1166 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2532/2532 [==============================] - 1s 289us/step - loss: -0.0027 - accuracy: 0.9882\n",
      "At the end of episode 1167 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 1s 290us/step - loss: -0.0013 - accuracy: 0.9862\n",
      "At the end of episode 1168 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2269/2269 [==============================] - 1s 274us/step - loss: -0.0052 - accuracy: 0.9841\n",
      "At the end of episode 1169 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 1s 296us/step - loss: -0.0105 - accuracy: 0.9846\n",
      "At the end of episode 1170 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2585/2585 [==============================] - 1s 285us/step - loss: 0.0031 - accuracy: 0.9853\n",
      "At the end of episode 1171 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2085/2085 [==============================] - 1s 296us/step - loss: -0.0038 - accuracy: 0.9871\n",
      "At the end of episode 1172 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2016/2016 [==============================] - 1s 298us/step - loss: 9.9065e-04 - accuracy: 0.9851\n",
      "At the end of episode 1173 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2395/2395 [==============================] - 1s 273us/step - loss: -0.0047 - accuracy: 0.9883\n",
      "At the end of episode 1174 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2541/2541 [==============================] - 1s 299us/step - loss: 0.0051 - accuracy: 0.9894\n",
      "At the end of episode 1175 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2353/2353 [==============================] - 1s 290us/step - loss: -0.0042 - accuracy: 0.9890\n",
      "At the end of episode 1176 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2470/2470 [==============================] - 1s 298us/step - loss: 0.0029 - accuracy: 0.9854\n",
      "At the end of episode 1177 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2284/2284 [==============================] - 1s 285us/step - loss: -0.0014 - accuracy: 0.9891\n",
      "At the end of episode 1178 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2574/2574 [==============================] - 1s 287us/step - loss: -0.0056 - accuracy: 0.9817\n",
      "At the end of episode 1179 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 1s 316us/step - loss: 0.0074 - accuracy: 0.9841\n",
      "At the end of episode 1180 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 1s 290us/step - loss: 5.6515e-04 - accuracy: 0.9868\n",
      "At the end of episode 1181 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2579/2579 [==============================] - 1s 294us/step - loss: 0.0049 - accuracy: 0.9880\n",
      "At the end of episode 1182 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3324/3324 [==============================] - 1s 283us/step - loss: 0.0093 - accuracy: 0.9823\n",
      "At the end of episode 1183 the total reward was : -18.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2297/2297 [==============================] - 1s 312us/step - loss: -0.0012 - accuracy: 0.9891\n",
      "At the end of episode 1184 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2319/2319 [==============================] - 1s 275us/step - loss: -0.0067 - accuracy: 0.9888\n",
      "At the end of episode 1185 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2176/2176 [==============================] - 1s 290us/step - loss: -0.0025 - accuracy: 0.9848\n",
      "At the end of episode 1186 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2922/2922 [==============================] - 1s 292us/step - loss: 0.0075 - accuracy: 0.9887\n",
      "At the end of episode 1187 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 1s 297us/step - loss: 0.0015 - accuracy: 0.9874\n",
      "At the end of episode 1188 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2549/2549 [==============================] - 1s 279us/step - loss: 0.0020 - accuracy: 0.9863\n",
      "At the end of episode 1189 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2811/2811 [==============================] - 1s 287us/step - loss: -0.0057 - accuracy: 0.9826\n",
      "At the end of episode 1190 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2208/2208 [==============================] - 1s 273us/step - loss: -0.0120 - accuracy: 0.9878\n",
      "At the end of episode 1191 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "3232/3232 [==============================] - 1s 296us/step - loss: -2.4229e-04 - accuracy: 0.9833\n",
      "At the end of episode 1192 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1907/1907 [==============================] - 1s 293us/step - loss: 0.0030 - accuracy: 0.9869\n",
      "At the end of episode 1193 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2577/2577 [==============================] - 1s 284us/step - loss: 0.0022 - accuracy: 0.9868\n",
      "At the end of episode 1194 the total reward was : -10.0\n",
      "Epoch 1/1\n",
      "3049/3049 [==============================] - 1s 278us/step - loss: -0.0032 - accuracy: 0.9869\n",
      "At the end of episode 1195 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2564/2564 [==============================] - 1s 325us/step - loss: -0.0031 - accuracy: 0.9899\n",
      "At the end of episode 1196 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1898/1898 [==============================] - 1s 297us/step - loss: 5.9609e-04 - accuracy: 0.9874\n",
      "At the end of episode 1197 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2197/2197 [==============================] - 1s 336us/step - loss: 0.0049 - accuracy: 0.9927\n",
      "At the end of episode 1198 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2094/2094 [==============================] - 1s 360us/step - loss: -0.0019 - accuracy: 0.9862\n",
      "At the end of episode 1199 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2752/2752 [==============================] - 1s 281us/step - loss: 0.0047 - accuracy: 0.9858\n",
      "At the end of episode 1200 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2878/2878 [==============================] - 1s 298us/step - loss: -0.0069 - accuracy: 0.9854\n",
      "At the end of episode 1201 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2884/2884 [==============================] - 1s 267us/step - loss: -0.0021 - accuracy: 0.9872\n",
      "At the end of episode 1202 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 1s 295us/step - loss: -1.2480e-04 - accuracy: 0.9881\n",
      "At the end of episode 1203 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 1s 279us/step - loss: -0.0024 - accuracy: 0.9850\n",
      "At the end of episode 1204 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2092/2092 [==============================] - 1s 290us/step - loss: -0.0067 - accuracy: 0.9909\n",
      "At the end of episode 1205 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 1s 282us/step - loss: 0.0011 - accuracy: 0.9849\n",
      "At the end of episode 1206 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1912/1912 [==============================] - 1s 294us/step - loss: -0.0041 - accuracy: 0.9848\n",
      "At the end of episode 1207 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2560/2560 [==============================] - 1s 366us/step - loss: -0.0039 - accuracy: 0.9891\n",
      "At the end of episode 1208 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2550/2550 [==============================] - 1s 324us/step - loss: -7.5405e-04 - accuracy: 0.9835\n",
      "At the end of episode 1209 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "2724/2724 [==============================] - 1s 334us/step - loss: -2.7952e-04 - accuracy: 0.9860\n",
      "At the end of episode 1210 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2249/2249 [==============================] - 1s 326us/step - loss: -0.0126 - accuracy: 0.9871\n",
      "At the end of episode 1211 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2782/2782 [==============================] - 1s 311us/step - loss: -7.0991e-04 - accuracy: 0.9899\n",
      "At the end of episode 1212 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2850/2850 [==============================] - 1s 299us/step - loss: 0.0059 - accuracy: 0.9860\n",
      "At the end of episode 1213 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2914/2914 [==============================] - 1s 272us/step - loss: -0.0031 - accuracy: 0.9852\n",
      "At the end of episode 1214 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2387/2387 [==============================] - 1s 303us/step - loss: -0.0041 - accuracy: 0.9887\n",
      "At the end of episode 1215 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2339/2339 [==============================] - 1s 271us/step - loss: 0.0051 - accuracy: 0.9889\n",
      "At the end of episode 1216 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2886/2886 [==============================] - 1s 273us/step - loss: 0.0021 - accuracy: 0.9900\n",
      "At the end of episode 1217 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "1862/1862 [==============================] - 1s 270us/step - loss: -0.0037 - accuracy: 0.9898\n",
      "At the end of episode 1218 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2242/2242 [==============================] - 1s 380us/step - loss: -0.0023 - accuracy: 0.9920\n",
      "At the end of episode 1219 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2065/2065 [==============================] - 1s 308us/step - loss: -0.0160 - accuracy: 0.9835\n",
      "At the end of episode 1220 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "2824/2824 [==============================] - 1s 307us/step - loss: 7.6654e-04 - accuracy: 0.9851\n",
      "At the end of episode 1221 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2349/2349 [==============================] - 1s 319us/step - loss: 0.0094 - accuracy: 0.9851\n",
      "At the end of episode 1222 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2642/2642 [==============================] - 1s 309us/step - loss: -0.0185 - accuracy: 0.9780\n",
      "At the end of episode 1223 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 1s 310us/step - loss: 0.0156 - accuracy: 0.9832\n",
      "At the end of episode 1224 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2953/2953 [==============================] - 1s 294us/step - loss: -0.0037 - accuracy: 0.9898\n",
      "At the end of episode 1225 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2754/2754 [==============================] - 1s 296us/step - loss: -5.9768e-04 - accuracy: 0.9855\n",
      "At the end of episode 1226 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "2914/2914 [==============================] - 1s 325us/step - loss: 0.0013 - accuracy: 0.9804\n",
      "At the end of episode 1227 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2414/2414 [==============================] - 1s 314us/step - loss: -0.0076 - accuracy: 0.9834\n",
      "At the end of episode 1228 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2496/2496 [==============================] - 1s 320us/step - loss: -0.0014 - accuracy: 0.9856\n",
      "At the end of episode 1229 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 1s 299us/step - loss: 0.0049 - accuracy: 0.9884\n",
      "At the end of episode 1230 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2297/2297 [==============================] - 1s 296us/step - loss: 6.5609e-04 - accuracy: 0.9839\n",
      "At the end of episode 1231 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2830/2830 [==============================] - 1s 338us/step - loss: -0.0026 - accuracy: 0.9883\n",
      "At the end of episode 1232 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2553/2553 [==============================] - 1s 357us/step - loss: 0.0111 - accuracy: 0.9808\n",
      "At the end of episode 1233 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2714/2714 [==============================] - 1s 301us/step - loss: -0.0037 - accuracy: 0.9849\n",
      "At the end of episode 1234 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2304/2304 [==============================] - 1s 299us/step - loss: -0.0031 - accuracy: 0.9839\n",
      "At the end of episode 1235 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2381/2381 [==============================] - 1s 307us/step - loss: -0.0051 - accuracy: 0.9878\n",
      "At the end of episode 1236 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2496/2496 [==============================] - 1s 305us/step - loss: -0.0058 - accuracy: 0.9908\n",
      "At the end of episode 1237 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2974/2974 [==============================] - 1s 299us/step - loss: 0.0035 - accuracy: 0.9815\n",
      "At the end of episode 1238 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2051/2051 [==============================] - 1s 289us/step - loss: -0.0057 - accuracy: 0.9868\n",
      "At the end of episode 1239 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2956/2956 [==============================] - 1s 303us/step - loss: 5.4616e-04 - accuracy: 0.9848\n",
      "At the end of episode 1240 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2708/2708 [==============================] - 1s 284us/step - loss: -0.0010 - accuracy: 0.9889\n",
      "At the end of episode 1241 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2936/2936 [==============================] - 1s 302us/step - loss: 0.0153 - accuracy: 0.9867\n",
      "At the end of episode 1242 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2663/2663 [==============================] - 1s 298us/step - loss: -0.0026 - accuracy: 0.9854\n",
      "At the end of episode 1243 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2731/2731 [==============================] - 1s 295us/step - loss: -0.0047 - accuracy: 0.9912\n",
      "At the end of episode 1244 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2295/2295 [==============================] - 1s 300us/step - loss: -0.0035 - accuracy: 0.9922\n",
      "At the end of episode 1245 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2532/2532 [==============================] - 1s 307us/step - loss: -0.0087 - accuracy: 0.9878\n",
      "At the end of episode 1246 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2777/2777 [==============================] - 1s 302us/step - loss: -0.0055 - accuracy: 0.9914\n",
      "At the end of episode 1247 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2751/2751 [==============================] - 1s 286us/step - loss: 0.0027 - accuracy: 0.9858\n",
      "At the end of episode 1248 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2830/2830 [==============================] - 1s 331us/step - loss: 0.0051 - accuracy: 0.9887\n",
      "At the end of episode 1249 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1888/1888 [==============================] - 1s 295us/step - loss: 0.0044 - accuracy: 0.9883\n",
      "At the end of episode 1250 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2912/2912 [==============================] - 1s 279us/step - loss: -0.0025 - accuracy: 0.9842\n",
      "At the end of episode 1251 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2649/2649 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.98 - 1s 285us/step - loss: 0.0016 - accuracy: 0.9853\n",
      "At the end of episode 1252 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2912/2912 [==============================] - 1s 278us/step - loss: 0.0060 - accuracy: 0.9880\n",
      "At the end of episode 1253 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2666/2666 [==============================] - 1s 305us/step - loss: -3.0752e-04 - accuracy: 0.9910\n",
      "At the end of episode 1254 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2623/2623 [==============================] - 1s 287us/step - loss: 0.0062 - accuracy: 0.9840\n",
      "At the end of episode 1255 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2720/2720 [==============================] - 1s 296us/step - loss: 2.9755e-04 - accuracy: 0.9893\n",
      "At the end of episode 1256 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2252/2252 [==============================] - 1s 344us/step - loss: 0.0018 - accuracy: 0.9893\n",
      "At the end of episode 1257 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3738/3738 [==============================] - 1s 297us/step - loss: 0.0035 - accuracy: 0.9893\n",
      "At the end of episode 1258 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2505/2505 [==============================] - 1s 321us/step - loss: -0.0026 - accuracy: 0.9888\n",
      "At the end of episode 1259 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2990/2990 [==============================] - 1s 342us/step - loss: -6.1658e-04 - accuracy: 0.9893\n",
      "At the end of episode 1260 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2213/2213 [==============================] - 1s 335us/step - loss: 0.0048 - accuracy: 0.9896\n",
      "At the end of episode 1261 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2918/2918 [==============================] - 1s 336us/step - loss: 0.0132 - accuracy: 0.9863\n",
      "At the end of episode 1262 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1998/1998 [==============================] - 1s 322us/step - loss: 5.5297e-06 - accuracy: 0.9875\n",
      "At the end of episode 1263 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2172/2172 [==============================] - 1s 347us/step - loss: -0.0129 - accuracy: 0.9839\n",
      "At the end of episode 1264 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2709/2709 [==============================] - 1s 315us/step - loss: 0.0054 - accuracy: 0.9819\n",
      "At the end of episode 1265 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1753/1753 [==============================] - 1s 295us/step - loss: 0.0030 - accuracy: 0.9840\n",
      "At the end of episode 1266 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2845/2845 [==============================] - 1s 301us/step - loss: -0.0011 - accuracy: 0.9902\n",
      "At the end of episode 1267 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2225/2225 [==============================] - 1s 311us/step - loss: -0.0092 - accuracy: 0.9861\n",
      "At the end of episode 1268 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2402/2402 [==============================] - 1s 301us/step - loss: -8.6330e-04 - accuracy: 0.9854\n",
      "At the end of episode 1269 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2852/2852 [==============================] - 1s 305us/step - loss: -0.0053 - accuracy: 0.9870\n",
      "At the end of episode 1270 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2548/2548 [==============================] - 1s 302us/step - loss: 0.0069 - accuracy: 0.9898\n",
      "At the end of episode 1271 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 1s 324us/step - loss: -0.0073 - accuracy: 0.9876ETA: 0s - loss: -0.0085 - accu\n",
      "At the end of episode 1272 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2168/2168 [==============================] - 1s 291us/step - loss: -0.0023 - accuracy: 0.9862\n",
      "At the end of episode 1273 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1968/1968 [==============================] - 1s 300us/step - loss: -0.0018 - accuracy: 0.9848\n",
      "At the end of episode 1274 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2721/2721 [==============================] - 1s 314us/step - loss: 0.0018 - accuracy: 0.9838\n",
      "At the end of episode 1275 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2678/2678 [==============================] - 1s 312us/step - loss: -0.0041 - accuracy: 0.9910\n",
      "At the end of episode 1276 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2122/2122 [==============================] - 1s 337us/step - loss: 0.0030 - accuracy: 0.9859\n",
      "At the end of episode 1277 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2194/2194 [==============================] - 1s 334us/step - loss: -0.0085 - accuracy: 0.9877\n",
      "At the end of episode 1278 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2212/2212 [==============================] - 1s 306us/step - loss: -0.0018 - accuracy: 0.9855\n",
      "At the end of episode 1279 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2205/2205 [==============================] - 1s 340us/step - loss: 0.0115 - accuracy: 0.9859\n",
      "At the end of episode 1280 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1890/1890 [==============================] - 1s 329us/step - loss: -4.6515e-04 - accuracy: 0.9921\n",
      "At the end of episode 1281 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2296/2296 [==============================] - 1s 304us/step - loss: -0.0040 - accuracy: 0.9874\n",
      "At the end of episode 1282 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2286/2286 [==============================] - 1s 313us/step - loss: 8.8708e-04 - accuracy: 0.9904\n",
      "At the end of episode 1283 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2166/2166 [==============================] - 1s 308us/step - loss: -0.0053 - accuracy: 0.9898\n",
      "At the end of episode 1284 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2450/2450 [==============================] - 1s 294us/step - loss: -0.0068 - accuracy: 0.9902\n",
      "At the end of episode 1285 the total reward was : -17.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2180/2180 [==============================] - 1s 293us/step - loss: 0.0106 - accuracy: 0.9899\n",
      "At the end of episode 1286 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2343/2343 [==============================] - 1s 287us/step - loss: -0.0023 - accuracy: 0.9936\n",
      "At the end of episode 1287 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2517/2517 [==============================] - 1s 285us/step - loss: -0.0087 - accuracy: 0.9849\n",
      "At the end of episode 1288 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2220/2220 [==============================] - 1s 304us/step - loss: -0.0015 - accuracy: 0.9865\n",
      "At the end of episode 1289 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2382/2382 [==============================] - 1s 299us/step - loss: 0.0058 - accuracy: 0.9912\n",
      "At the end of episode 1290 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2774/2774 [==============================] - 1s 302us/step - loss: 0.0025 - accuracy: 0.9924\n",
      "At the end of episode 1291 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2773/2773 [==============================] - 1s 307us/step - loss: -0.0088 - accuracy: 0.9877\n",
      "At the end of episode 1292 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1908/1908 [==============================] - 1s 295us/step - loss: 0.0033 - accuracy: 0.9869\n",
      "At the end of episode 1293 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2541/2541 [==============================] - 1s 303us/step - loss: 0.0026 - accuracy: 0.9917\n",
      "At the end of episode 1294 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 1s 288us/step - loss: 0.0087 - accuracy: 0.9863\n",
      "At the end of episode 1295 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 1s 287us/step - loss: 0.0013 - accuracy: 0.9934\n",
      "At the end of episode 1296 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2599/2599 [==============================] - 1s 286us/step - loss: 0.0064 - accuracy: 0.9885\n",
      "At the end of episode 1297 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2631/2631 [==============================] - 1s 297us/step - loss: -0.0090 - accuracy: 0.9875\n",
      "At the end of episode 1298 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2832/2832 [==============================] - 1s 300us/step - loss: -0.0021 - accuracy: 0.9901\n",
      "At the end of episode 1299 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2154/2154 [==============================] - 1s 327us/step - loss: 0.0065 - accuracy: 0.9838\n",
      "At the end of episode 1300 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2920/2920 [==============================] - 1s 309us/step - loss: -0.0076 - accuracy: 0.9856\n",
      "At the end of episode 1301 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2102/2102 [==============================] - 1s 301us/step - loss: -0.0046 - accuracy: 0.9867\n",
      "At the end of episode 1302 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2377/2377 [==============================] - 1s 339us/step - loss: 0.0016 - accuracy: 0.9857\n",
      "At the end of episode 1303 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2075/2075 [==============================] - 1s 328us/step - loss: -7.7496e-04 - accuracy: 0.9904\n",
      "At the end of episode 1304 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2322/2322 [==============================] - 1s 290us/step - loss: -0.0096 - accuracy: 0.9858\n",
      "At the end of episode 1305 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 1s 310us/step - loss: 0.0067 - accuracy: 0.9850\n",
      "At the end of episode 1306 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2563/2563 [==============================] - 1s 303us/step - loss: 0.0038 - accuracy: 0.9891\n",
      "At the end of episode 1307 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2741/2741 [==============================] - 1s 316us/step - loss: -0.0031 - accuracy: 0.9887\n",
      "At the end of episode 1308 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2016/2016 [==============================] - 1s 299us/step - loss: 0.0170 - accuracy: 0.9926\n",
      "At the end of episode 1309 the total reward was : -11.0\n",
      "Epoch 1/1\n",
      "2934/2934 [==============================] - 1s 315us/step - loss: 0.0015 - accuracy: 0.9901\n",
      "At the end of episode 1310 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2195/2195 [==============================] - 1s 308us/step - loss: -0.0025 - accuracy: 0.9845\n",
      "At the end of episode 1311 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "2923/2923 [==============================] - 1s 324us/step - loss: -0.0064 - accuracy: 0.9894\n",
      "At the end of episode 1312 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2437/2437 [==============================] - 1s 328us/step - loss: -0.0040 - accuracy: 0.9893\n",
      "At the end of episode 1313 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2090/2090 [==============================] - 1s 348us/step - loss: -0.0054 - accuracy: 0.9885\n",
      "At the end of episode 1314 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2982/2982 [==============================] - 1s 287us/step - loss: 0.0015 - accuracy: 0.9889\n",
      "At the end of episode 1315 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2665/2665 [==============================] - 1s 321us/step - loss: -0.0080 - accuracy: 0.9865\n",
      "At the end of episode 1316 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2315/2315 [==============================] - 1s 316us/step - loss: 0.0089 - accuracy: 0.9888\n",
      "At the end of episode 1317 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2328/2328 [==============================] - 1s 307us/step - loss: -0.0081 - accuracy: 0.9888\n",
      "At the end of episode 1318 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2891/2891 [==============================] - 1s 320us/step - loss: 0.0021 - accuracy: 0.9875\n",
      "At the end of episode 1319 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2888/2888 [==============================] - 1s 311us/step - loss: -9.6129e-04 - accuracy: 0.9938\n",
      "At the end of episode 1320 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2889/2889 [==============================] - 1s 294us/step - loss: 1.2524e-04 - accuracy: 0.9879\n",
      "At the end of episode 1321 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2339/2339 [==============================] - 1s 287us/step - loss: -0.0034 - accuracy: 0.9889\n",
      "At the end of episode 1322 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2166/2166 [==============================] - 1s 296us/step - loss: 0.0086 - accuracy: 0.9898\n",
      "At the end of episode 1323 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2702/2702 [==============================] - 1s 296us/step - loss: 0.0048 - accuracy: 0.9878\n",
      "At the end of episode 1324 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2346/2346 [==============================] - 1s 309us/step - loss: -0.0027 - accuracy: 0.9915\n",
      "At the end of episode 1325 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2911/2911 [==============================] - 1s 322us/step - loss: 0.0066 - accuracy: 0.9890\n",
      "At the end of episode 1326 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 1s 297us/step - loss: -0.0102 - accuracy: 0.9867\n",
      "At the end of episode 1327 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2447/2447 [==============================] - 1s 305us/step - loss: 0.0031 - accuracy: 0.9943\n",
      "At the end of episode 1328 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3060/3060 [==============================] - 1s 301us/step - loss: 0.0059 - accuracy: 0.9882\n",
      "At the end of episode 1329 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2471/2471 [==============================] - 1s 302us/step - loss: 7.9109e-04 - accuracy: 0.9895\n",
      "At the end of episode 1330 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2731/2731 [==============================] - 1s 296us/step - loss: -0.0022 - accuracy: 0.9905\n",
      "At the end of episode 1331 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2938/2938 [==============================] - 1s 305us/step - loss: -0.0043 - accuracy: 0.9888\n",
      "At the end of episode 1332 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1879/1879 [==============================] - 1s 315us/step - loss: -6.8187e-04 - accuracy: 0.9920\n",
      "At the end of episode 1333 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2575/2575 [==============================] - 1s 298us/step - loss: -0.0053 - accuracy: 0.9883\n",
      "At the end of episode 1334 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 1s 311us/step - loss: 1.9237e-04 - accuracy: 0.9883\n",
      "At the end of episode 1335 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3306/3306 [==============================] - 1s 291us/step - loss: -0.0050 - accuracy: 0.9912\n",
      "At the end of episode 1336 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2559/2559 [==============================] - 1s 285us/step - loss: -9.6043e-04 - accuracy: 0.9894\n",
      "At the end of episode 1337 the total reward was : -10.0\n",
      "Epoch 1/1\n",
      "3402/3402 [==============================] - 1s 291us/step - loss: -0.0050 - accuracy: 0.9903\n",
      "At the end of episode 1338 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 1s 311us/step - loss: 0.0013 - accuracy: 0.9916\n",
      "At the end of episode 1339 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2412/2412 [==============================] - 1s 290us/step - loss: -0.0107 - accuracy: 0.9880\n",
      "At the end of episode 1340 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2493/2493 [==============================] - 1s 305us/step - loss: -0.0074 - accuracy: 0.9848\n",
      "At the end of episode 1341 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2190/2190 [==============================] - 1s 284us/step - loss: -6.1348e-05 - accuracy: 0.9895\n",
      "At the end of episode 1342 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2705/2705 [==============================] - 1s 282us/step - loss: -0.0064 - accuracy: 0.9871\n",
      "At the end of episode 1343 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3239/3239 [==============================] - 1s 299us/step - loss: 7.6574e-04 - accuracy: 0.9892\n",
      "At the end of episode 1344 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "3057/3057 [==============================] - 1s 335us/step - loss: -0.0028 - accuracy: 0.9905\n",
      "At the end of episode 1345 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 1s 313us/step - loss: -0.0011 - accuracy: 0.9887\n",
      "At the end of episode 1346 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2200/2200 [==============================] - 1s 321us/step - loss: 0.0040 - accuracy: 0.9864\n",
      "At the end of episode 1347 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 1s 309us/step - loss: -0.0086 - accuracy: 0.9903\n",
      "At the end of episode 1348 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2996/2996 [==============================] - 1s 321us/step - loss: -0.0030 - accuracy: 0.9883\n",
      "At the end of episode 1349 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3314/3314 [==============================] - 1s 298us/step - loss: -0.0088 - accuracy: 0.9888\n",
      "At the end of episode 1350 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2091/2091 [==============================] - 1s 292us/step - loss: 0.0024 - accuracy: 0.9871\n",
      "At the end of episode 1351 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2640/2640 [==============================] - 1s 304us/step - loss: -0.0050 - accuracy: 0.9890\n",
      "At the end of episode 1352 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2521/2521 [==============================] - 1s 378us/step - loss: -0.0057 - accuracy: 0.9885\n",
      "At the end of episode 1353 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2917/2917 [==============================] - 1s 340us/step - loss: 0.0030 - accuracy: 0.9928\n",
      "At the end of episode 1354 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1972/1972 [==============================] - 1s 315us/step - loss: 0.0071 - accuracy: 0.9919\n",
      "At the end of episode 1355 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2381/2381 [==============================] - 1s 323us/step - loss: 0.0116 - accuracy: 0.9861\n",
      "At the end of episode 1356 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2354/2354 [==============================] - 1s 314us/step - loss: -0.0058 - accuracy: 0.9885\n",
      "At the end of episode 1357 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2357/2357 [==============================] - 1s 303us/step - loss: 0.0063 - accuracy: 0.9890\n",
      "At the end of episode 1358 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 1s 309us/step - loss: -0.0028 - accuracy: 0.9903\n",
      "At the end of episode 1359 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2329/2329 [==============================] - 1s 308us/step - loss: -0.0048 - accuracy: 0.9927\n",
      "At the end of episode 1360 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2775/2775 [==============================] - 1s 314us/step - loss: -0.0114 - accuracy: 0.9899\n",
      "At the end of episode 1361 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2636/2636 [==============================] - 1s 285us/step - loss: -6.4648e-04 - accuracy: 0.9909\n",
      "At the end of episode 1362 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3005/3005 [==============================] - 1s 303us/step - loss: -0.0035 - accuracy: 0.9860\n",
      "At the end of episode 1363 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1769/1769 [==============================] - 1s 309us/step - loss: -0.0056 - accuracy: 0.9904\n",
      "At the end of episode 1364 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2849/2849 [==============================] - 1s 294us/step - loss: -0.0025 - accuracy: 0.9912\n",
      "At the end of episode 1365 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2514/2514 [==============================] - 1s 297us/step - loss: 0.0010 - accuracy: 0.9912\n",
      "At the end of episode 1366 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2305/2305 [==============================] - 1s 305us/step - loss: -0.0046 - accuracy: 0.9883\n",
      "At the end of episode 1367 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 1s 297us/step - loss: -3.7069e-04 - accuracy: 0.9924\n",
      "At the end of episode 1368 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3167/3167 [==============================] - 1s 285us/step - loss: 0.0099 - accuracy: 0.9864\n",
      "At the end of episode 1369 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2535/2535 [==============================] - 1s 299us/step - loss: -0.0160 - accuracy: 0.9858\n",
      "At the end of episode 1370 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2377/2377 [==============================] - 1s 298us/step - loss: -0.0031 - accuracy: 0.9928\n",
      "At the end of episode 1371 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2641/2641 [==============================] - 1s 292us/step - loss: -0.0037 - accuracy: 0.9898\n",
      "At the end of episode 1372 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2007/2007 [==============================] - 1s 315us/step - loss: 0.0054 - accuracy: 0.9890\n",
      "At the end of episode 1373 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1993/1993 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.98 - 1s 308us/step - loss: 0.0106 - accuracy: 0.9849\n",
      "At the end of episode 1374 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2618/2618 [==============================] - 1s 288us/step - loss: -0.0066 - accuracy: 0.9893\n",
      "At the end of episode 1375 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2991/2991 [==============================] - 1s 309us/step - loss: 0.0046 - accuracy: 0.9890\n",
      "At the end of episode 1376 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2404/2404 [==============================] - 1s 326us/step - loss: -0.0017 - accuracy: 0.9892\n",
      "At the end of episode 1377 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2259/2259 [==============================] - 1s 372us/step - loss: -7.6779e-04 - accuracy: 0.9898\n",
      "At the end of episode 1378 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "1961/1961 [==============================] - 1s 337us/step - loss: 0.0028 - accuracy: 0.9857\n",
      "At the end of episode 1379 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2156/2156 [==============================] - 1s 403us/step - loss: -0.0027 - accuracy: 0.9944\n",
      "At the end of episode 1380 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2080/2080 [==============================] - 1s 290us/step - loss: 0.0024 - accuracy: 0.9918\n",
      "At the end of episode 1381 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3219/3219 [==============================] - 1s 289us/step - loss: 0.0014 - accuracy: 0.9879\n",
      "At the end of episode 1382 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2800/2800 [==============================] - 1s 303us/step - loss: 0.0011 - accuracy: 0.9886\n",
      "At the end of episode 1383 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2722/2722 [==============================] - 1s 316us/step - loss: 0.0017 - accuracy: 0.9923\n",
      "At the end of episode 1384 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2050/2050 [==============================] - 1s 311us/step - loss: -0.0055 - accuracy: 0.9907\n",
      "At the end of episode 1385 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2343/2343 [==============================] - 1s 299us/step - loss: 0.0012 - accuracy: 0.9889\n",
      "At the end of episode 1386 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2732/2732 [==============================] - 1s 340us/step - loss: -0.0053 - accuracy: 0.9912\n",
      "At the end of episode 1387 the total reward was : -20.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2586/2586 [==============================] - 1s 293us/step - loss: -0.0037 - accuracy: 0.9927\n",
      "At the end of episode 1388 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2525/2525 [==============================] - 1s 298us/step - loss: -0.0035 - accuracy: 0.9909\n",
      "At the end of episode 1389 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2436/2436 [==============================] - 1s 316us/step - loss: 0.0012 - accuracy: 0.9926\n",
      "At the end of episode 1390 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2058/2058 [==============================] - 1s 302us/step - loss: -0.0037 - accuracy: 0.9908\n",
      "At the end of episode 1391 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2584/2584 [==============================] - 1s 294us/step - loss: -7.9416e-04 - accuracy: 0.9861\n",
      "At the end of episode 1392 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2809/2809 [==============================] - 1s 293us/step - loss: -9.5361e-05 - accuracy: 0.9911\n",
      "At the end of episode 1393 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2356/2356 [==============================] - 1s 306us/step - loss: -2.7733e-06 - accuracy: 0.9928\n",
      "At the end of episode 1394 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2798/2798 [==============================] - 1s 297us/step - loss: 0.0036 - accuracy: 0.9929\n",
      "At the end of episode 1395 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2375/2375 [==============================] - 1s 305us/step - loss: -0.0050 - accuracy: 0.9882\n",
      "At the end of episode 1396 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2688/2688 [==============================] - 1s 305us/step - loss: -0.0017 - accuracy: 0.9922\n",
      "At the end of episode 1397 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2737/2737 [==============================] - 1s 315us/step - loss: -0.0092 - accuracy: 0.9832\n",
      "At the end of episode 1398 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2788/2788 [==============================] - 1s 336us/step - loss: -0.0033 - accuracy: 0.9882\n",
      "At the end of episode 1399 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2162/2162 [==============================] - 1s 344us/step - loss: 0.0024 - accuracy: 0.9972\n",
      "At the end of episode 1400 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2353/2353 [==============================] - 1s 304us/step - loss: -0.0057 - accuracy: 0.9936\n",
      "At the end of episode 1401 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2314/2314 [==============================] - 1s 300us/step - loss: -0.0054 - accuracy: 0.9879\n",
      "At the end of episode 1402 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2007/2007 [==============================] - 1s 293us/step - loss: 0.0040 - accuracy: 0.9945\n",
      "At the end of episode 1403 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2374/2374 [==============================] - 1s 351us/step - loss: 0.0037 - accuracy: 0.9954\n",
      "At the end of episode 1404 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2620/2620 [==============================] - 1s 292us/step - loss: -0.0038 - accuracy: 0.9893\n",
      "At the end of episode 1405 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2101/2101 [==============================] - 1s 285us/step - loss: -0.0013 - accuracy: 0.9910\n",
      "At the end of episode 1406 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2214/2214 [==============================] - 1s 279us/step - loss: 0.0013 - accuracy: 0.9883\n",
      "At the end of episode 1407 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2541/2541 [==============================] - 1s 281us/step - loss: -0.0149 - accuracy: 0.9898\n",
      "At the end of episode 1408 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2383/2383 [==============================] - 1s 312us/step - loss: -3.6953e-04 - accuracy: 0.9883\n",
      "At the end of episode 1409 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2242/2242 [==============================] - 1s 284us/step - loss: 0.0038 - accuracy: 0.9924\n",
      "At the end of episode 1410 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 1s 294us/step - loss: -0.0046 - accuracy: 0.9887\n",
      "At the end of episode 1411 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2915/2915 [==============================] - 2s 746us/step - loss: 0.0018 - accuracy: 0.9883\n",
      "At the end of episode 1412 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 1s 319us/step - loss: -0.0030 - accuracy: 0.9903\n",
      "At the end of episode 1413 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3659/3659 [==============================] - 1s 334us/step - loss: 0.0041 - accuracy: 0.9910\n",
      "At the end of episode 1414 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2087/2087 [==============================] - 1s 379us/step - loss: 0.0109 - accuracy: 0.9890\n",
      "At the end of episode 1415 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2566/2566 [==============================] - 1s 312us/step - loss: 0.0030 - accuracy: 0.9926\n",
      "At the end of episode 1416 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2829/2829 [==============================] - 1s 310us/step - loss: -0.0054 - accuracy: 0.9880\n",
      "At the end of episode 1417 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2526/2526 [==============================] - 1s 328us/step - loss: -0.0032 - accuracy: 0.9885\n",
      "At the end of episode 1418 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3159/3159 [==============================] - 1s 313us/step - loss: -0.0035 - accuracy: 0.9886\n",
      "At the end of episode 1419 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "1935/1935 [==============================] - 1s 358us/step - loss: -0.0037 - accuracy: 0.9897\n",
      "At the end of episode 1420 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2831/2831 [==============================] - 1s 344us/step - loss: -0.0096 - accuracy: 0.9816\n",
      "At the end of episode 1421 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2533/2533 [==============================] - 1s 352us/step - loss: 0.0038 - accuracy: 0.9909\n",
      "At the end of episode 1422 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2566/2566 [==============================] - 1s 418us/step - loss: -0.0026 - accuracy: 0.9918\n",
      "At the end of episode 1423 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2641/2641 [==============================] - 1s 308us/step - loss: -6.1757e-04 - accuracy: 0.9860\n",
      "At the end of episode 1424 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2750/2750 [==============================] - 1s 314us/step - loss: 0.0021 - accuracy: 0.9887\n",
      "At the end of episode 1425 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2424/2424 [==============================] - 1s 347us/step - loss: -0.0042 - accuracy: 0.9934\n",
      "At the end of episode 1426 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2582/2582 [==============================] - 1s 298us/step - loss: 5.1444e-04 - accuracy: 0.9864\n",
      "At the end of episode 1427 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2311/2311 [==============================] - 1s 327us/step - loss: -0.0038 - accuracy: 0.9909\n",
      "At the end of episode 1428 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2719/2719 [==============================] - 1s 288us/step - loss: -0.0018 - accuracy: 0.9949\n",
      "At the end of episode 1429 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2167/2167 [==============================] - 1s 308us/step - loss: 0.0025 - accuracy: 0.9898\n",
      "At the end of episode 1430 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2134/2134 [==============================] - 1s 299us/step - loss: -0.0068 - accuracy: 0.9822\n",
      "At the end of episode 1431 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2508/2508 [==============================] - 1s 319us/step - loss: 8.7778e-04 - accuracy: 0.9868\n",
      "At the end of episode 1432 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2742/2742 [==============================] - 1s 331us/step - loss: -0.0020 - accuracy: 0.9905\n",
      "At the end of episode 1433 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3078/3078 [==============================] - 1s 371us/step - loss: -0.0033 - accuracy: 0.9860\n",
      "At the end of episode 1434 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3069/3069 [==============================] - 1s 334us/step - loss: -0.0018 - accuracy: 0.9860\n",
      "At the end of episode 1435 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2327/2327 [==============================] - 1s 308us/step - loss: -0.0012 - accuracy: 0.9918\n",
      "At the end of episode 1436 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 1s 332us/step - loss: -0.0156 - accuracy: 0.9814\n",
      "At the end of episode 1437 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2136/2136 [==============================] - 1s 301us/step - loss: -0.0023 - accuracy: 0.9888\n",
      "At the end of episode 1438 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2778/2778 [==============================] - 1s 301us/step - loss: 1.2241e-04 - accuracy: 0.9881\n",
      "At the end of episode 1439 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 1s 312us/step - loss: 0.0047 - accuracy: 0.9887\n",
      "At the end of episode 1440 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2155/2155 [==============================] - 1s 331us/step - loss: -0.0063 - accuracy: 0.9870\n",
      "At the end of episode 1441 the total reward was : -11.0\n",
      "Epoch 1/1\n",
      "2860/2860 [==============================] - 1s 305us/step - loss: -9.6021e-04 - accuracy: 0.9871\n",
      "At the end of episode 1442 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2672/2672 [==============================] - 1s 293us/step - loss: 0.0015 - accuracy: 0.9876\n",
      "At the end of episode 1443 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2597/2597 [==============================] - 1s 284us/step - loss: -0.0033 - accuracy: 0.9904\n",
      "At the end of episode 1444 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2584/2584 [==============================] - 1s 293us/step - loss: -0.0142 - accuracy: 0.9872\n",
      "At the end of episode 1445 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 1s 284us/step - loss: -0.0071 - accuracy: 0.9872\n",
      "At the end of episode 1446 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2783/2783 [==============================] - 1s 323us/step - loss: -0.0082 - accuracy: 0.9845\n",
      "At the end of episode 1447 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2334/2334 [==============================] - 1s 288us/step - loss: 0.0122 - accuracy: 0.9837\n",
      "At the end of episode 1448 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2253/2253 [==============================] - 1s 307us/step - loss: 0.0070 - accuracy: 0.9898\n",
      "At the end of episode 1449 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2619/2619 [==============================] - 1s 289us/step - loss: -0.0105 - accuracy: 0.9885\n",
      "At the end of episode 1450 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 1s 294us/step - loss: -0.0018 - accuracy: 0.9894\n",
      "At the end of episode 1451 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3094/3094 [==============================] - 1s 304us/step - loss: -0.0114 - accuracy: 0.9893\n",
      "At the end of episode 1452 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 1s 299us/step - loss: -0.0025 - accuracy: 0.9897\n",
      "At the end of episode 1453 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 1s 310us/step - loss: 0.0027 - accuracy: 0.9850\n",
      "At the end of episode 1454 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2721/2721 [==============================] - 1s 290us/step - loss: 3.3340e-04 - accuracy: 0.9901\n",
      "At the end of episode 1455 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2950/2950 [==============================] - 1s 286us/step - loss: 8.2044e-04 - accuracy: 0.9898\n",
      "At the end of episode 1456 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2801/2801 [==============================] - 1s 339us/step - loss: 0.0100 - accuracy: 0.9929\n",
      "At the end of episode 1457 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2109/2109 [==============================] - 1s 312us/step - loss: -0.0066 - accuracy: 0.9905\n",
      "At the end of episode 1458 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2603/2603 [==============================] - 1s 332us/step - loss: -0.0049 - accuracy: 0.9866\n",
      "At the end of episode 1459 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2799/2799 [==============================] - 1s 412us/step - loss: -0.0023 - accuracy: 0.9889\n",
      "At the end of episode 1460 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2285/2285 [==============================] - 1s 315us/step - loss: -0.0020 - accuracy: 0.9934\n",
      "At the end of episode 1461 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2536/2536 [==============================] - 1s 313us/step - loss: -0.0030 - accuracy: 0.9905\n",
      "At the end of episode 1462 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2743/2743 [==============================] - 1s 297us/step - loss: 0.0027 - accuracy: 0.9887\n",
      "At the end of episode 1463 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2775/2775 [==============================] - 1s 309us/step - loss: -0.0066 - accuracy: 0.9932\n",
      "At the end of episode 1464 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2744/2744 [==============================] - 1s 295us/step - loss: -0.0018 - accuracy: 0.9883\n",
      "At the end of episode 1465 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 1s 312us/step - loss: 0.0013 - accuracy: 0.9897\n",
      "At the end of episode 1466 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2329/2329 [==============================] - 1s 339us/step - loss: -0.0023 - accuracy: 0.9936\n",
      "At the end of episode 1467 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2318/2318 [==============================] - 1s 304us/step - loss: -0.0068 - accuracy: 0.9862\n",
      "At the end of episode 1468 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2672/2672 [==============================] - 1s 313us/step - loss: 8.7165e-04 - accuracy: 0.9910\n",
      "At the end of episode 1469 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2252/2252 [==============================] - 1s 367us/step - loss: -0.0024 - accuracy: 0.9880\n",
      "At the end of episode 1470 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2565/2565 [==============================] - 1s 304us/step - loss: -3.6152e-04 - accuracy: 0.9906\n",
      "At the end of episode 1471 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2592/2592 [==============================] - 1s 307us/step - loss: -0.0010 - accuracy: 0.9896\n",
      "At the end of episode 1472 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "2885/2885 [==============================] - 1s 315us/step - loss: -0.0053 - accuracy: 0.9896\n",
      "At the end of episode 1473 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2778/2778 [==============================] - 1s 310us/step - loss: -0.0015 - accuracy: 0.9867\n",
      "At the end of episode 1474 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 1s 324us/step - loss: -0.0055 - accuracy: 0.9890\n",
      "At the end of episode 1475 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2143/2143 [==============================] - 1s 299us/step - loss: 0.0041 - accuracy: 0.9874\n",
      "At the end of episode 1476 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 1s 306us/step - loss: 0.0035 - accuracy: 0.9919\n",
      "At the end of episode 1477 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2539/2539 [==============================] - 1s 360us/step - loss: -0.0066 - accuracy: 0.9886\n",
      "At the end of episode 1478 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2967/2967 [==============================] - 1s 320us/step - loss: 1.2473e-04 - accuracy: 0.9879\n",
      "At the end of episode 1479 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 1s 410us/step - loss: -0.0014 - accuracy: 0.9924\n",
      "At the end of episode 1480 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2788/2788 [==============================] - 1s 357us/step - loss: 8.7150e-04 - accuracy: 0.9882\n",
      "At the end of episode 1481 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2512/2512 [==============================] - 1s 307us/step - loss: -0.0049 - accuracy: 0.9881\n",
      "At the end of episode 1482 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2960/2960 [==============================] - 1s 308us/step - loss: -0.0019 - accuracy: 0.9899\n",
      "At the end of episode 1483 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2858/2858 [==============================] - 1s 309us/step - loss: -0.0011 - accuracy: 0.9927\n",
      "At the end of episode 1484 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2479/2479 [==============================] - 1s 310us/step - loss: -0.0107 - accuracy: 0.9855\n",
      "At the end of episode 1485 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2813/2813 [==============================] - 1s 346us/step - loss: -3.0666e-04 - accuracy: 0.9893\n",
      "At the end of episode 1486 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 1s 298us/step - loss: -0.0051 - accuracy: 0.9895\n",
      "At the end of episode 1487 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1891/1891 [==============================] - 1s 379us/step - loss: -5.4073e-04 - accuracy: 0.9910\n",
      "At the end of episode 1488 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 1s 342us/step - loss: -0.0011 - accuracy: 0.9918\n",
      "At the end of episode 1489 the total reward was : -19.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2305/2305 [==============================] - 1s 369us/step - loss: 0.0080 - accuracy: 0.9909\n",
      "At the end of episode 1490 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2139/2139 [==============================] - 1s 308us/step - loss: -0.0021 - accuracy: 0.9921\n",
      "At the end of episode 1491 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2402/2402 [==============================] - 1s 304us/step - loss: 0.0140 - accuracy: 0.9846\n",
      "At the end of episode 1492 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2258/2258 [==============================] - 1s 373us/step - loss: 0.0023 - accuracy: 0.9898\n",
      "At the end of episode 1493 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2281/2281 [==============================] - 1s 396us/step - loss: -0.0116 - accuracy: 0.9890\n",
      "At the end of episode 1494 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2950/2950 [==============================] - 1s 349us/step - loss: 0.0037 - accuracy: 0.9875\n",
      "At the end of episode 1495 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2483/2483 [==============================] - 1s 289us/step - loss: -0.0019 - accuracy: 0.9944\n",
      "At the end of episode 1496 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2723/2723 [==============================] - 1s 309us/step - loss: -0.0020 - accuracy: 0.9853\n",
      "At the end of episode 1497 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1897/1897 [==============================] - ETA: 0s - loss: 9.6601e-04 - accuracy: 0.99 - 1s 326us/step - loss: 3.2827e-04 - accuracy: 0.9905\n",
      "At the end of episode 1498 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3180/3180 [==============================] - 1s 324us/step - loss: 0.0027 - accuracy: 0.9868\n",
      "At the end of episode 1499 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2949/2949 [==============================] - 1s 300us/step - loss: -0.0057 - accuracy: 0.9827\n",
      "At the end of episode 1500 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2735/2735 [==============================] - 1s 351us/step - loss: 0.0095 - accuracy: 0.9898\n",
      "At the end of episode 1501 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2471/2471 [==============================] - 1s 372us/step - loss: -7.7270e-04 - accuracy: 0.9919\n",
      "At the end of episode 1502 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2683/2683 [==============================] - 1s 319us/step - loss: 0.0010 - accuracy: 0.9922\n",
      "At the end of episode 1503 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2033/2033 [==============================] - 1s 307us/step - loss: 0.0012 - accuracy: 0.9911\n",
      "At the end of episode 1504 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2572/2572 [==============================] - 1s 302us/step - loss: 0.0035 - accuracy: 0.9899\n",
      "At the end of episode 1505 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3243/3243 [==============================] - 1s 324us/step - loss: -0.0057 - accuracy: 0.9889\n",
      "At the end of episode 1506 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2422/2422 [==============================] - 1s 289us/step - loss: 0.0027 - accuracy: 0.9889\n",
      "At the end of episode 1507 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2523/2523 [==============================] - 1s 358us/step - loss: -0.0036 - accuracy: 0.9885\n",
      "At the end of episode 1508 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 1s 307us/step - loss: -0.0063 - accuracy: 0.9925\n",
      "At the end of episode 1509 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2734/2734 [==============================] - 1s 298us/step - loss: -0.0010 - accuracy: 0.9920\n",
      "At the end of episode 1510 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2547/2547 [==============================] - 1s 294us/step - loss: -9.1869e-04 - accuracy: 0.9929\n",
      "At the end of episode 1511 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2067/2067 [==============================] - 1s 352us/step - loss: -0.0064 - accuracy: 0.9865\n",
      "At the end of episode 1512 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3232/3232 [==============================] - 1s 306us/step - loss: -0.0043 - accuracy: 0.9864\n",
      "At the end of episode 1513 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2630/2630 [==============================] - 1s 312us/step - loss: -0.0021 - accuracy: 0.9859\n",
      "At the end of episode 1514 the total reward was : -5.0\n",
      "Epoch 1/1\n",
      "3626/3626 [==============================] - 1s 323us/step - loss: 0.0067 - accuracy: 0.9870\n",
      "At the end of episode 1515 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "1899/1899 [==============================] - 1s 356us/step - loss: -0.0052 - accuracy: 0.9879\n",
      "At the end of episode 1516 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2738/2738 [==============================] - 1s 311us/step - loss: -0.0036 - accuracy: 0.9909\n",
      "At the end of episode 1517 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2903/2903 [==============================] - 1s 312us/step - loss: -0.0116 - accuracy: 0.9873\n",
      "At the end of episode 1518 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3062/3062 [==============================] - 1s 288us/step - loss: -0.0033 - accuracy: 0.9915\n",
      "At the end of episode 1519 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "2885/2885 [==============================] - 1s 295us/step - loss: 0.0020 - accuracy: 0.9834\n",
      "At the end of episode 1520 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2906/2906 [==============================] - 1s 338us/step - loss: -0.0106 - accuracy: 0.9890\n",
      "At the end of episode 1521 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2517/2517 [==============================] - 1s 315us/step - loss: -0.0035 - accuracy: 0.9893\n",
      "At the end of episode 1522 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2607/2607 [==============================] - 1s 345us/step - loss: -2.1130e-04 - accuracy: 0.9946\n",
      "At the end of episode 1523 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2676/2676 [==============================] - 1s 306us/step - loss: -0.0039 - accuracy: 0.9910\n",
      "At the end of episode 1524 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3220/3220 [==============================] - 1s 312us/step - loss: 0.0018 - accuracy: 0.9839\n",
      "At the end of episode 1525 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "2879/2879 [==============================] - 1s 315us/step - loss: -0.0021 - accuracy: 0.9906\n",
      "At the end of episode 1526 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2125/2125 [==============================] - 1s 316us/step - loss: -0.0042 - accuracy: 0.9944\n",
      "At the end of episode 1527 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2755/2755 [==============================] - 1s 321us/step - loss: 0.0038 - accuracy: 0.9898\n",
      "At the end of episode 1528 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2938/2938 [==============================] - 1s 335us/step - loss: 0.0097 - accuracy: 0.9867\n",
      "At the end of episode 1529 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3200/3200 [==============================] - 1s 328us/step - loss: 0.0040 - accuracy: 0.9903\n",
      "At the end of episode 1530 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2522/2522 [==============================] - 1s 301us/step - loss: 0.0013 - accuracy: 0.9865\n",
      "At the end of episode 1531 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 1s 304us/step - loss: -0.0020 - accuracy: 0.9894\n",
      "At the end of episode 1532 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "2796/2796 [==============================] - 1s 315us/step - loss: 0.0116 - accuracy: 0.9893\n",
      "At the end of episode 1533 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2077/2077 [==============================] - 1s 342us/step - loss: -0.0015 - accuracy: 0.9909\n",
      "At the end of episode 1534 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2630/2630 [==============================] - 1s 319us/step - loss: -0.0065 - accuracy: 0.9878\n",
      "At the end of episode 1535 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2611/2611 [==============================] - 1s 329us/step - loss: 8.5391e-04 - accuracy: 0.9912\n",
      "At the end of episode 1536 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2334/2334 [==============================] - 1s 355us/step - loss: 0.0058 - accuracy: 0.9919\n",
      "At the end of episode 1537 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2560/2560 [==============================] - 1s 322us/step - loss: -0.0047 - accuracy: 0.9859\n",
      "At the end of episode 1538 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2521/2521 [==============================] - 1s 302us/step - loss: -0.0030 - accuracy: 0.9921\n",
      "At the end of episode 1539 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2307/2307 [==============================] - 1s 349us/step - loss: -0.0065 - accuracy: 0.9861\n",
      "At the end of episode 1540 the total reward was : -14.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2729/2729 [==============================] - 1s 310us/step - loss: 0.0026 - accuracy: 0.9875\n",
      "At the end of episode 1541 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2376/2376 [==============================] - 1s 368us/step - loss: 0.0020 - accuracy: 0.9916\n",
      "At the end of episode 1542 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 1s 323us/step - loss: 0.0048 - accuracy: 0.9934\n",
      "At the end of episode 1543 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2503/2503 [==============================] - 1s 319us/step - loss: 0.0050 - accuracy: 0.9872\n",
      "At the end of episode 1544 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "3045/3045 [==============================] - 1s 335us/step - loss: 0.0021 - accuracy: 0.9898\n",
      "At the end of episode 1545 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2325/2325 [==============================] - 1s 317us/step - loss: 0.0023 - accuracy: 0.9888\n",
      "At the end of episode 1546 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2789/2789 [==============================] - 1s 292us/step - loss: -2.3106e-04 - accuracy: 0.9892\n",
      "At the end of episode 1547 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2955/2955 [==============================] - 1s 319us/step - loss: 2.1548e-04 - accuracy: 0.9868\n",
      "At the end of episode 1548 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2075/2075 [==============================] - 1s 314us/step - loss: -6.9430e-04 - accuracy: 0.9894\n",
      "At the end of episode 1549 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2103/2103 [==============================] - 1s 312us/step - loss: 0.0015 - accuracy: 0.9919\n",
      "At the end of episode 1550 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2546/2546 [==============================] - 1s 304us/step - loss: 0.0020 - accuracy: 0.9906\n",
      "At the end of episode 1551 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2339/2339 [==============================] - 1s 303us/step - loss: -0.0022 - accuracy: 0.9885\n",
      "At the end of episode 1552 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "3108/3108 [==============================] - 1s 345us/step - loss: 0.0024 - accuracy: 0.9871\n",
      "At the end of episode 1553 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2781/2781 [==============================] - 1s 290us/step - loss: 0.0011 - accuracy: 0.9917\n",
      "At the end of episode 1554 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2340/2340 [==============================] - 1s 362us/step - loss: 0.0086 - accuracy: 0.9893\n",
      "At the end of episode 1555 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2355/2355 [==============================] - 1s 326us/step - loss: 0.0018 - accuracy: 0.9864\n",
      "At the end of episode 1556 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2247/2247 [==============================] - 1s 343us/step - loss: -0.0040 - accuracy: 0.9866\n",
      "At the end of episode 1557 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1951/1951 [==============================] - 1s 343us/step - loss: 5.8503e-04 - accuracy: 0.9846\n",
      "At the end of episode 1558 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1926/1926 [==============================] - 1s 313us/step - loss: 0.0045 - accuracy: 0.9907\n",
      "At the end of episode 1559 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2624/2624 [==============================] - 1s 308us/step - loss: -0.0020 - accuracy: 0.9939\n",
      "At the end of episode 1560 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2270/2270 [==============================] - 1s 301us/step - loss: -0.0031 - accuracy: 0.9925\n",
      "At the end of episode 1561 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1859/1859 [==============================] - 1s 314us/step - loss: 6.4899e-04 - accuracy: 0.9871\n",
      "At the end of episode 1562 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2165/2165 [==============================] - 1s 338us/step - loss: -0.0024 - accuracy: 0.9885\n",
      "At the end of episode 1563 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2659/2659 [==============================] - 1s 324us/step - loss: 4.7499e-04 - accuracy: 0.9906\n",
      "At the end of episode 1564 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2512/2512 [==============================] - 1s 317us/step - loss: 0.0045 - accuracy: 0.9857\n",
      "At the end of episode 1565 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2565/2565 [==============================] - 1s 308us/step - loss: 0.0077 - accuracy: 0.9875\n",
      "At the end of episode 1566 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2618/2618 [==============================] - 1s 317us/step - loss: -0.0042 - accuracy: 0.9878\n",
      "At the end of episode 1567 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3140/3140 [==============================] - 1s 302us/step - loss: -0.0024 - accuracy: 0.9863\n",
      "At the end of episode 1568 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2305/2305 [==============================] - 1s 300us/step - loss: -0.0053 - accuracy: 0.9870\n",
      "At the end of episode 1569 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 1s 315us/step - loss: -0.0135 - accuracy: 0.9879\n",
      "At the end of episode 1570 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3188/3188 [==============================] - 1s 325us/step - loss: -6.6762e-04 - accuracy: 0.9906\n",
      "At the end of episode 1571 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2241/2241 [==============================] - 1s 309us/step - loss: 0.0100 - accuracy: 0.9893\n",
      "At the end of episode 1572 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2004/2004 [==============================] - 1s 298us/step - loss: -3.7459e-04 - accuracy: 0.9875\n",
      "At the end of episode 1573 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3220/3220 [==============================] - 1s 320us/step - loss: -0.0082 - accuracy: 0.9851\n",
      "At the end of episode 1574 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2773/2773 [==============================] - 1s 331us/step - loss: -0.0019 - accuracy: 0.9928\n",
      "At the end of episode 1575 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 1s 364us/step - loss: -0.0014 - accuracy: 0.9868\n",
      "At the end of episode 1576 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2607/2607 [==============================] - 1s 334us/step - loss: -0.0024 - accuracy: 0.9900\n",
      "At the end of episode 1577 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3191/3191 [==============================] - 1s 351us/step - loss: 0.0050 - accuracy: 0.9868\n",
      "At the end of episode 1578 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2626/2626 [==============================] - 1s 408us/step - loss: 0.0054 - accuracy: 0.9950\n",
      "At the end of episode 1579 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2434/2434 [==============================] - 1s 350us/step - loss: 0.0055 - accuracy: 0.9897\n",
      "At the end of episode 1580 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1897/1897 [==============================] - 1s 301us/step - loss: -0.0017 - accuracy: 0.9921\n",
      "At the end of episode 1581 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2811/2811 [==============================] - 1s 352us/step - loss: 0.0026 - accuracy: 0.9861\n",
      "At the end of episode 1582 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2615/2615 [==============================] - 1s 311us/step - loss: -0.0029 - accuracy: 0.9912\n",
      "At the end of episode 1583 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3327/3327 [==============================] - 1s 322us/step - loss: -0.0025 - accuracy: 0.9892\n",
      "At the end of episode 1584 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1994/1994 [==============================] - 1s 315us/step - loss: -0.0022 - accuracy: 0.9915\n",
      "At the end of episode 1585 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2321/2321 [==============================] - 1s 342us/step - loss: 0.0010 - accuracy: 0.9922\n",
      "At the end of episode 1586 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2627/2627 [==============================] - 1s 309us/step - loss: -0.0062 - accuracy: 0.9878\n",
      "At the end of episode 1587 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2696/2696 [==============================] - 1s 310us/step - loss: 0.0134 - accuracy: 0.9881\n",
      "At the end of episode 1588 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2999/2999 [==============================] - 1s 386us/step - loss: -0.0074 - accuracy: 0.9900\n",
      "At the end of episode 1589 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2331/2331 [==============================] - 1s 313us/step - loss: 0.0050 - accuracy: 0.9867\n",
      "At the end of episode 1590 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2229/2229 [==============================] - 1s 292us/step - loss: 0.0013 - accuracy: 0.9919\n",
      "At the end of episode 1591 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2965/2965 [==============================] - 1s 366us/step - loss: 0.0046 - accuracy: 0.9889\n",
      "At the end of episode 1592 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 1s 383us/step - loss: 0.0053 - accuracy: 0.9897\n",
      "At the end of episode 1593 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2315/2315 [==============================] - 1s 287us/step - loss: 0.0050 - accuracy: 0.9918\n",
      "At the end of episode 1594 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2602/2602 [==============================] - 1s 341us/step - loss: 0.0034 - accuracy: 0.9900\n",
      "At the end of episode 1595 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2703/2703 [==============================] - 1s 349us/step - loss: 0.0016 - accuracy: 0.9937\n",
      "At the end of episode 1596 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2715/2715 [==============================] - 1s 278us/step - loss: -0.0045 - accuracy: 0.9948\n",
      "At the end of episode 1597 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2311/2311 [==============================] - 1s 334us/step - loss: -0.0033 - accuracy: 0.9887\n",
      "At the end of episode 1598 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2157/2157 [==============================] - 1s 306us/step - loss: 0.0089 - accuracy: 0.9879\n",
      "At the end of episode 1599 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2102/2102 [==============================] - 1s 314us/step - loss: -0.0070 - accuracy: 0.9867\n",
      "At the end of episode 1600 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2821/2821 [==============================] - 1s 300us/step - loss: -0.0071 - accuracy: 0.9869\n",
      "At the end of episode 1601 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 1s 384us/step - loss: 0.0096 - accuracy: 0.9850\n",
      "At the end of episode 1602 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 1s 321us/step - loss: -0.0036 - accuracy: 0.9916\n",
      "At the end of episode 1603 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3170/3170 [==============================] - 1s 298us/step - loss: -0.0026 - accuracy: 0.9902\n",
      "At the end of episode 1604 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2301/2301 [==============================] - 1s 306us/step - loss: 0.0058 - accuracy: 0.9896\n",
      "At the end of episode 1605 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "3176/3176 [==============================] - 1s 307us/step - loss: -0.0021 - accuracy: 0.9906\n",
      "At the end of episode 1606 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "3301/3301 [==============================] - 1s 286us/step - loss: 0.0080 - accuracy: 0.9876\n",
      "At the end of episode 1607 the total reward was : -11.0\n",
      "Epoch 1/1\n",
      "2780/2780 [==============================] - 1s 331us/step - loss: -0.0091 - accuracy: 0.9921\n",
      "At the end of episode 1608 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3094/3094 [==============================] - 1s 289us/step - loss: 0.0076 - accuracy: 0.9887\n",
      "At the end of episode 1609 the total reward was : -9.0\n",
      "Epoch 1/1\n",
      "3799/3799 [==============================] - 1s 313us/step - loss: -0.0011 - accuracy: 0.9900\n",
      "At the end of episode 1610 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3281/3281 [==============================] - 1s 310us/step - loss: -9.4258e-04 - accuracy: 0.9890\n",
      "At the end of episode 1611 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2516/2516 [==============================] - 1s 295us/step - loss: 0.0125 - accuracy: 0.9873\n",
      "At the end of episode 1612 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1961/1961 [==============================] - 1s 339us/step - loss: -0.0035 - accuracy: 0.9913\n",
      "At the end of episode 1613 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2771/2771 [==============================] - 1s 317us/step - loss: 0.0043 - accuracy: 0.9917\n",
      "At the end of episode 1614 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2639/2639 [==============================] - 1s 306us/step - loss: 0.0041 - accuracy: 0.9898\n",
      "At the end of episode 1615 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 1s 330us/step - loss: 0.0022 - accuracy: 0.9899\n",
      "At the end of episode 1616 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2741/2741 [==============================] - 1s 358us/step - loss: 0.0011 - accuracy: 0.9909\n",
      "At the end of episode 1617 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2700/2700 [==============================] - 1s 325us/step - loss: 0.0042 - accuracy: 0.9893\n",
      "At the end of episode 1618 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2415/2415 [==============================] - 1s 298us/step - loss: -0.0064 - accuracy: 0.9851\n",
      "At the end of episode 1619 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 1s 307us/step - loss: -0.0077 - accuracy: 0.9855\n",
      "At the end of episode 1620 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3150/3150 [==============================] - 1s 318us/step - loss: -0.0033 - accuracy: 0.9883\n",
      "At the end of episode 1621 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2869/2869 [==============================] - 1s 301us/step - loss: 0.0018 - accuracy: 0.9847\n",
      "At the end of episode 1622 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2559/2559 [==============================] - 1s 319us/step - loss: -0.0028 - accuracy: 0.9934\n",
      "At the end of episode 1623 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2816/2816 [==============================] - 1s 300us/step - loss: -0.0051 - accuracy: 0.9893\n",
      "At the end of episode 1624 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3546/3546 [==============================] - 1s 310us/step - loss: -0.0021 - accuracy: 0.9882\n",
      "At the end of episode 1625 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3055/3055 [==============================] - 1s 367us/step - loss: -4.1230e-04 - accuracy: 0.9876\n",
      "At the end of episode 1626 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2589/2589 [==============================] - 1s 347us/step - loss: 3.7661e-04 - accuracy: 0.9888\n",
      "At the end of episode 1627 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3001/3001 [==============================] - 1s 308us/step - loss: 0.0135 - accuracy: 0.9853\n",
      "At the end of episode 1628 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2207/2207 [==============================] - 1s 344us/step - loss: 8.4108e-04 - accuracy: 0.9896\n",
      "At the end of episode 1629 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2929/2929 [==============================] - 1s 332us/step - loss: 0.0037 - accuracy: 0.9939\n",
      "At the end of episode 1630 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2311/2311 [==============================] - 1s 340us/step - loss: 0.0046 - accuracy: 0.9892\n",
      "At the end of episode 1631 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2837/2837 [==============================] - 1s 295us/step - loss: -0.0033 - accuracy: 0.9905\n",
      "At the end of episode 1632 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2838/2838 [==============================] - 1s 302us/step - loss: -0.0056 - accuracy: 0.9887\n",
      "At the end of episode 1633 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2169/2169 [==============================] - 1s 307us/step - loss: -0.0054 - accuracy: 0.9903\n",
      "At the end of episode 1634 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2838/2838 [==============================] - 1s 299us/step - loss: 8.1376e-04 - accuracy: 0.9877\n",
      "At the end of episode 1635 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2851/2851 [==============================] - 1s 296us/step - loss: -0.0015 - accuracy: 0.9912\n",
      "At the end of episode 1636 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3039/3039 [==============================] - 1s 290us/step - loss: -0.0039 - accuracy: 0.9911\n",
      "At the end of episode 1637 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 1s 305us/step - loss: -0.0066 - accuracy: 0.9883\n",
      "At the end of episode 1638 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2509/2509 [==============================] - 1s 288us/step - loss: 0.0011 - accuracy: 0.9888\n",
      "At the end of episode 1639 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2306/2306 [==============================] - 1s 305us/step - loss: -0.0049 - accuracy: 0.9918\n",
      "At the end of episode 1640 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2415/2415 [==============================] - 1s 299us/step - loss: 0.0012 - accuracy: 0.9892\n",
      "At the end of episode 1641 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2479/2479 [==============================] - 1s 299us/step - loss: -0.0158 - accuracy: 0.9915\n",
      "At the end of episode 1642 the total reward was : -16.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2879/2879 [==============================] - 1s 310us/step - loss: -0.0063 - accuracy: 0.9858\n",
      "At the end of episode 1643 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1977/1977 [==============================] - 1s 289us/step - loss: -0.0130 - accuracy: 0.9874\n",
      "At the end of episode 1644 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1760/1760 [==============================] - 1s 298us/step - loss: 0.0054 - accuracy: 0.9903\n",
      "At the end of episode 1645 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2598/2598 [==============================] - 1s 322us/step - loss: -0.0055 - accuracy: 0.9877\n",
      "At the end of episode 1646 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1982/1982 [==============================] - 1s 299us/step - loss: 0.0063 - accuracy: 0.9879\n",
      "At the end of episode 1647 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2098/2098 [==============================] - 1s 331us/step - loss: 0.0011 - accuracy: 0.9943\n",
      "At the end of episode 1648 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2378/2378 [==============================] - 1s 324us/step - loss: 0.0021 - accuracy: 0.9903\n",
      "At the end of episode 1649 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1900/1900 [==============================] - 1s 319us/step - loss: -0.0018 - accuracy: 0.9889\n",
      "At the end of episode 1650 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2504/2504 [==============================] - 1s 336us/step - loss: 0.0025 - accuracy: 0.9912\n",
      "At the end of episode 1651 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1575/1575 [==============================] - 1s 330us/step - loss: -0.0111 - accuracy: 0.9816\n",
      "At the end of episode 1652 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "2752/2752 [==============================] - 1s 313us/step - loss: 0.0020 - accuracy: 0.9807\n",
      "At the end of episode 1653 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1433/1433 [==============================] - 0s 343us/step - loss: 0.0056 - accuracy: 0.9874\n",
      "At the end of episode 1654 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1655/1655 [==============================] - 1s 308us/step - loss: 0.0021 - accuracy: 0.9909\n",
      "At the end of episode 1655 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2471/2471 [==============================] - 1s 299us/step - loss: -7.4512e-04 - accuracy: 0.9866\n",
      "At the end of episode 1656 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2294/2294 [==============================] - 1s 329us/step - loss: -3.5469e-04 - accuracy: 0.9917\n",
      "At the end of episode 1657 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2383/2383 [==============================] - 1s 306us/step - loss: -0.0034 - accuracy: 0.9916\n",
      "At the end of episode 1658 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1772/1772 [==============================] - 1s 319us/step - loss: -0.0052 - accuracy: 0.9865\n",
      "At the end of episode 1659 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "1957/1957 [==============================] - 1s 311us/step - loss: -0.0013 - accuracy: 0.9893\n",
      "At the end of episode 1660 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2139/2139 [==============================] - 1s 323us/step - loss: 0.0076 - accuracy: 0.9883\n",
      "At the end of episode 1661 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 1s 312us/step - loss: -0.0058 - accuracy: 0.9876\n",
      "At the end of episode 1662 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2864/2864 [==============================] - 1s 315us/step - loss: -0.0111 - accuracy: 0.9888\n",
      "At the end of episode 1663 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1832/1832 [==============================] - 1s 308us/step - loss: -0.0017 - accuracy: 0.9902\n",
      "At the end of episode 1664 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1568/1568 [==============================] - 1s 391us/step - loss: 0.0035 - accuracy: 0.9898\n",
      "At the end of episode 1665 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2137/2137 [==============================] - 1s 344us/step - loss: -0.0035 - accuracy: 0.9897\n",
      "At the end of episode 1666 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2422/2422 [==============================] - 1s 355us/step - loss: 0.0070 - accuracy: 0.9860\n",
      "At the end of episode 1667 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2029/2029 [==============================] - 1s 317us/step - loss: 0.0016 - accuracy: 0.9936\n",
      "At the end of episode 1668 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1423/1423 [==============================] - 1s 364us/step - loss: -0.0078 - accuracy: 0.9902\n",
      "At the end of episode 1669 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1616/1616 [==============================] - 1s 318us/step - loss: 0.0039 - accuracy: 0.9926\n",
      "At the end of episode 1670 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2074/2074 [==============================] - 1s 303us/step - loss: -0.0048 - accuracy: 0.9904\n",
      "At the end of episode 1671 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1663/1663 [==============================] - 1s 305us/step - loss: 0.0026 - accuracy: 0.9898\n",
      "At the end of episode 1672 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2633/2633 [==============================] - 1s 314us/step - loss: 1.1175e-04 - accuracy: 0.9894\n",
      "At the end of episode 1673 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1690/1690 [==============================] - 0s 289us/step - loss: -0.0023 - accuracy: 0.9917\n",
      "At the end of episode 1674 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1947/1947 [==============================] - 1s 307us/step - loss: -0.0049 - accuracy: 0.9897\n",
      "At the end of episode 1675 the total reward was : -10.0\n",
      "Epoch 1/1\n",
      "2837/2837 [==============================] - 1s 310us/step - loss: 0.0044 - accuracy: 0.9915\n",
      "At the end of episode 1676 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2345/2345 [==============================] - 1s 304us/step - loss: 0.0010 - accuracy: 0.9902\n",
      "At the end of episode 1677 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2380/2380 [==============================] - 1s 354us/step - loss: 5.3367e-04 - accuracy: 0.9908\n",
      "At the end of episode 1678 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2244/2244 [==============================] - 1s 307us/step - loss: 0.0062 - accuracy: 0.9884\n",
      "At the end of episode 1679 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1881/1881 [==============================] - 1s 316us/step - loss: -0.0026 - accuracy: 0.9904\n",
      "At the end of episode 1680 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2192/2192 [==============================] - 1s 345us/step - loss: 0.0113 - accuracy: 0.9918\n",
      "At the end of episode 1681 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2319/2319 [==============================] - 1s 339us/step - loss: 0.0010 - accuracy: 0.9909\n",
      "At the end of episode 1682 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2098/2098 [==============================] - 1s 342us/step - loss: -0.0022 - accuracy: 0.9847\n",
      "At the end of episode 1683 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2653/2653 [==============================] - 1s 310us/step - loss: -0.0059 - accuracy: 0.9864\n",
      "At the end of episode 1684 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2109/2109 [==============================] - 1s 306us/step - loss: -0.0023 - accuracy: 0.9924\n",
      "At the end of episode 1685 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3083/3083 [==============================] - 1s 352us/step - loss: -0.0028 - accuracy: 0.9912\n",
      "At the end of episode 1686 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2772/2772 [==============================] - 1s 299us/step - loss: -0.0143 - accuracy: 0.9870\n",
      "At the end of episode 1687 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2707/2707 [==============================] - 1s 291us/step - loss: 0.0066 - accuracy: 0.9915\n",
      "At the end of episode 1688 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2596/2596 [==============================] - 1s 287us/step - loss: 0.0012 - accuracy: 0.9935\n",
      "At the end of episode 1689 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3043/3043 [==============================] - 1s 273us/step - loss: -0.0038 - accuracy: 0.9908\n",
      "At the end of episode 1690 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2285/2285 [==============================] - 1s 277us/step - loss: -0.0034 - accuracy: 0.9882\n",
      "At the end of episode 1691 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2860/2860 [==============================] - 1s 281us/step - loss: 0.0015 - accuracy: 0.9864\n",
      "At the end of episode 1692 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3111/3111 [==============================] - 1s 304us/step - loss: 9.1199e-04 - accuracy: 0.9891\n",
      "At the end of episode 1693 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2965/2965 [==============================] - 1s 268us/step - loss: 0.0058 - accuracy: 0.9808\n",
      "At the end of episode 1694 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2311/2311 [==============================] - 1s 290us/step - loss: 0.0094 - accuracy: 0.9918\n",
      "At the end of episode 1695 the total reward was : -10.0\n",
      "Epoch 1/1\n",
      "3630/3630 [==============================] - 1s 265us/step - loss: -0.0022 - accuracy: 0.9840\n",
      "At the end of episode 1696 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2708/2708 [==============================] - 1s 279us/step - loss: 0.0014 - accuracy: 0.9922\n",
      "At the end of episode 1697 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2963/2963 [==============================] - 1s 262us/step - loss: 2.8697e-04 - accuracy: 0.9899\n",
      "At the end of episode 1698 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2373/2373 [==============================] - 1s 275us/step - loss: 0.0060 - accuracy: 0.9907\n",
      "At the end of episode 1699 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3119/3119 [==============================] - 1s 270us/step - loss: 0.0017 - accuracy: 0.9875\n",
      "At the end of episode 1700 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2728/2728 [==============================] - 1s 271us/step - loss: 0.0100 - accuracy: 0.9901\n",
      "At the end of episode 1701 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2544/2544 [==============================] - 1s 320us/step - loss: -0.0079 - accuracy: 0.9874\n",
      "At the end of episode 1702 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2684/2684 [==============================] - 1s 272us/step - loss: -1.4944e-04 - accuracy: 0.9925\n",
      "At the end of episode 1703 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2866/2866 [==============================] - 1s 264us/step - loss: -0.0038 - accuracy: 0.9923\n",
      "At the end of episode 1704 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3137/3137 [==============================] - 1s 276us/step - loss: 0.0033 - accuracy: 0.9895\n",
      "At the end of episode 1705 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3048/3048 [==============================] - 1s 266us/step - loss: -0.0020 - accuracy: 0.9892\n",
      "At the end of episode 1706 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2877/2877 [==============================] - 1s 265us/step - loss: 0.0050 - accuracy: 0.9910\n",
      "At the end of episode 1707 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2719/2719 [==============================] - 1s 266us/step - loss: -0.0022 - accuracy: 0.9882\n",
      "At the end of episode 1708 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3421/3421 [==============================] - 1s 264us/step - loss: -0.0115 - accuracy: 0.9877\n",
      "At the end of episode 1709 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "2830/2830 [==============================] - 1s 276us/step - loss: 8.4548e-04 - accuracy: 0.9905\n",
      "At the end of episode 1710 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2724/2724 [==============================] - 1s 274us/step - loss: 0.0051 - accuracy: 0.9930\n",
      "At the end of episode 1711 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 1s 291us/step - loss: -9.0865e-05 - accuracy: 0.9885\n",
      "At the end of episode 1712 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2800/2800 [==============================] - 1s 263us/step - loss: 0.0107 - accuracy: 0.9825\n",
      "At the end of episode 1713 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "3068/3068 [==============================] - 1s 460us/step - loss: -0.0059 - accuracy: 0.9892\n",
      "At the end of episode 1714 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2546/2546 [==============================] - 1s 317us/step - loss: 0.0031 - accuracy: 0.9878\n",
      "At the end of episode 1715 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2574/2574 [==============================] - 1s 377us/step - loss: -0.0016 - accuracy: 0.9907\n",
      "At the end of episode 1716 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2717/2717 [==============================] - 1s 307us/step - loss: 0.0022 - accuracy: 0.9937\n",
      "At the end of episode 1717 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3313/3313 [==============================] - 1s 326us/step - loss: 9.2519e-04 - accuracy: 0.9900\n",
      "At the end of episode 1718 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3102/3102 [==============================] - 1s 309us/step - loss: -0.0106 - accuracy: 0.9852\n",
      "At the end of episode 1719 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2598/2598 [==============================] - 1s 314us/step - loss: -0.0026 - accuracy: 0.9904\n",
      "At the end of episode 1720 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2202/2202 [==============================] - 1s 325us/step - loss: 0.0018 - accuracy: 0.9927\n",
      "At the end of episode 1721 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2685/2685 [==============================] - 1s 319us/step - loss: -0.0040 - accuracy: 0.9896\n",
      "At the end of episode 1722 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3480/3480 [==============================] - 1s 321us/step - loss: 0.0046 - accuracy: 0.9882\n",
      "At the end of episode 1723 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2620/2620 [==============================] - 1s 323us/step - loss: 0.0057 - accuracy: 0.9889\n",
      "At the end of episode 1724 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2939/2939 [==============================] - 1s 315us/step - loss: -5.5008e-04 - accuracy: 0.9915\n",
      "At the end of episode 1725 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2757/2757 [==============================] - 1s 320us/step - loss: -0.0034 - accuracy: 0.9862\n",
      "At the end of episode 1726 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2882/2882 [==============================] - 1s 333us/step - loss: 0.0027 - accuracy: 0.9924\n",
      "At the end of episode 1727 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2594/2594 [==============================] - 1s 325us/step - loss: -0.0058 - accuracy: 0.9900\n",
      "At the end of episode 1728 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1982/1982 [==============================] - 1s 324us/step - loss: -6.7865e-04 - accuracy: 0.9945\n",
      "At the end of episode 1729 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 1s 317us/step - loss: -0.0041 - accuracy: 0.9903\n",
      "At the end of episode 1730 the total reward was : -11.0\n",
      "Epoch 1/1\n",
      "2858/2858 [==============================] - 1s 316us/step - loss: -2.2172e-04 - accuracy: 0.9906\n",
      "At the end of episode 1731 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "2977/2977 [==============================] - 1s 321us/step - loss: 4.6165e-04 - accuracy: 0.9929\n",
      "At the end of episode 1732 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2417/2417 [==============================] - 1s 324us/step - loss: 0.0074 - accuracy: 0.9872\n",
      "At the end of episode 1733 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2344/2344 [==============================] - 1s 333us/step - loss: 0.0031 - accuracy: 0.9902\n",
      "At the end of episode 1734 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3376/3376 [==============================] - 1s 349us/step - loss: 0.0043 - accuracy: 0.9899\n",
      "At the end of episode 1735 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2908/2908 [==============================] - 1s 350us/step - loss: -0.0043 - accuracy: 0.9866\n",
      "At the end of episode 1736 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2605/2605 [==============================] - 1s 349us/step - loss: 2.2307e-04 - accuracy: 0.9908\n",
      "At the end of episode 1737 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2968/2968 [==============================] - 1s 322us/step - loss: -0.0031 - accuracy: 0.9936\n",
      "At the end of episode 1738 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2582/2582 [==============================] - 1s 329us/step - loss: 0.0011 - accuracy: 0.9907\n",
      "At the end of episode 1739 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 1s 352us/step - loss: -0.0039 - accuracy: 0.9918\n",
      "At the end of episode 1740 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3314/3314 [==============================] - 1s 320us/step - loss: 0.0034 - accuracy: 0.9849\n",
      "At the end of episode 1741 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2738/2738 [==============================] - 1s 326us/step - loss: -9.7711e-04 - accuracy: 0.9865\n",
      "At the end of episode 1742 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2515/2515 [==============================] - 1s 324us/step - loss: 0.0046 - accuracy: 0.9901\n",
      "At the end of episode 1743 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2366/2366 [==============================] - 1s 330us/step - loss: 0.0035 - accuracy: 0.9932\n",
      "At the end of episode 1744 the total reward was : -13.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2950/2950 [==============================] - 1s 320us/step - loss: -0.0049 - accuracy: 0.9892\n",
      "At the end of episode 1745 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2987/2987 [==============================] - 1s 304us/step - loss: 0.0037 - accuracy: 0.9886\n",
      "At the end of episode 1746 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 1s 294us/step - loss: -0.0040 - accuracy: 0.9899\n",
      "At the end of episode 1747 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3113/3113 [==============================] - 1s 295us/step - loss: -4.3895e-04 - accuracy: 0.9872\n",
      "At the end of episode 1748 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2903/2903 [==============================] - 1s 292us/step - loss: -5.9132e-04 - accuracy: 0.9928\n",
      "At the end of episode 1749 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 1s 307us/step - loss: 0.0097 - accuracy: 0.9890\n",
      "At the end of episode 1750 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2663/2663 [==============================] - 1s 310us/step - loss: 0.0019 - accuracy: 0.9899\n",
      "At the end of episode 1751 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2273/2273 [==============================] - 1s 291us/step - loss: 0.0050 - accuracy: 0.9868\n",
      "At the end of episode 1752 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3510/3510 [==============================] - 1s 296us/step - loss: -0.0057 - accuracy: 0.9832\n",
      "At the end of episode 1753 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2099/2099 [==============================] - 1s 288us/step - loss: -0.0075 - accuracy: 0.9909\n",
      "At the end of episode 1754 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2365/2365 [==============================] - 1s 293us/step - loss: 0.0022 - accuracy: 0.9911\n",
      "At the end of episode 1755 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2470/2470 [==============================] - 1s 306us/step - loss: 0.0034 - accuracy: 0.9891\n",
      "At the end of episode 1756 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2116/2116 [==============================] - 1s 322us/step - loss: 1.7938e-04 - accuracy: 0.9901\n",
      "At the end of episode 1757 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3136/3136 [==============================] - 1s 303us/step - loss: 0.0037 - accuracy: 0.9879\n",
      "At the end of episode 1758 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2295/2295 [==============================] - 1s 297us/step - loss: -0.0089 - accuracy: 0.9865\n",
      "At the end of episode 1759 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2363/2363 [==============================] - 1s 293us/step - loss: 3.1854e-04 - accuracy: 0.9907\n",
      "At the end of episode 1760 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2330/2330 [==============================] - 1s 290us/step - loss: 0.0096 - accuracy: 0.9914\n",
      "At the end of episode 1761 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3047/3047 [==============================] - 1s 300us/step - loss: -0.0046 - accuracy: 0.9892\n",
      "At the end of episode 1762 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2431/2431 [==============================] - 1s 311us/step - loss: -0.0079 - accuracy: 0.9815\n",
      "At the end of episode 1763 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2615/2615 [==============================] - 1s 290us/step - loss: -0.0103 - accuracy: 0.9839\n",
      "At the end of episode 1764 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3313/3313 [==============================] - 1s 310us/step - loss: -0.0010 - accuracy: 0.9879\n",
      "At the end of episode 1765 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2693/2693 [==============================] - 1s 303us/step - loss: -0.0147 - accuracy: 0.9881\n",
      "At the end of episode 1766 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2243/2243 [==============================] - 1s 299us/step - loss: -0.0033 - accuracy: 0.9947\n",
      "At the end of episode 1767 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 1s 306us/step - loss: -0.0018 - accuracy: 0.9922\n",
      "At the end of episode 1768 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2688/2688 [==============================] - 1s 294us/step - loss: -9.1561e-04 - accuracy: 0.9907\n",
      "At the end of episode 1769 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2172/2172 [==============================] - 1s 292us/step - loss: -0.0033 - accuracy: 0.9922\n",
      "At the end of episode 1770 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2001/2001 [==============================] - 1s 315us/step - loss: -0.0021 - accuracy: 0.9880\n",
      "At the end of episode 1771 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2319/2319 [==============================] - 1s 287us/step - loss: 0.0076 - accuracy: 0.9914\n",
      "At the end of episode 1772 the total reward was : -9.0\n",
      "Epoch 1/1\n",
      "3605/3605 [==============================] - 1s 292us/step - loss: -7.4141e-04 - accuracy: 0.9886\n",
      "At the end of episode 1773 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2745/2745 [==============================] - 1s 300us/step - loss: -0.0047 - accuracy: 0.9883\n",
      "At the end of episode 1774 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2582/2582 [==============================] - 1s 304us/step - loss: 0.0042 - accuracy: 0.9899\n",
      "At the end of episode 1775 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 1s 301us/step - loss: -0.0023 - accuracy: 0.9904\n",
      "At the end of episode 1776 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1848/1848 [==============================] - 1s 290us/step - loss: 2.4916e-05 - accuracy: 0.9897\n",
      "At the end of episode 1777 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2606/2606 [==============================] - 1s 297us/step - loss: 0.0071 - accuracy: 0.9919\n",
      "At the end of episode 1778 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2378/2378 [==============================] - 1s 303us/step - loss: -0.0011 - accuracy: 0.9899\n",
      "At the end of episode 1779 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2382/2382 [==============================] - 1s 292us/step - loss: -0.0024 - accuracy: 0.9916\n",
      "At the end of episode 1780 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3060/3060 [==============================] - 1s 292us/step - loss: -0.0018 - accuracy: 0.9895\n",
      "At the end of episode 1781 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3662/3662 [==============================] - 1s 312us/step - loss: 0.0054 - accuracy: 0.9850\n",
      "At the end of episode 1782 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3154/3154 [==============================] - 1s 291us/step - loss: 0.0017 - accuracy: 0.9841\n",
      "At the end of episode 1783 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2812/2812 [==============================] - 1s 295us/step - loss: 0.0062 - accuracy: 0.9847\n",
      "At the end of episode 1784 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2569/2569 [==============================] - 1s 332us/step - loss: -0.0026 - accuracy: 0.9907\n",
      "At the end of episode 1785 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3041/3041 [==============================] - 1s 298us/step - loss: 0.0015 - accuracy: 0.9878\n",
      "At the end of episode 1786 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "3088/3088 [==============================] - 1s 300us/step - loss: 0.0020 - accuracy: 0.9848\n",
      "At the end of episode 1787 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 1s 296us/step - loss: 0.0022 - accuracy: 0.9871\n",
      "At the end of episode 1788 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2651/2651 [==============================] - 1s 316us/step - loss: -6.7521e-04 - accuracy: 0.9857\n",
      "At the end of episode 1789 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3086/3086 [==============================] - 1s 300us/step - loss: -0.0028 - accuracy: 0.9903\n",
      "At the end of episode 1790 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2964/2964 [==============================] - 1s 302us/step - loss: 8.4458e-04 - accuracy: 0.9899\n",
      "At the end of episode 1791 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 1s 313us/step - loss: 0.0051 - accuracy: 0.9908\n",
      "At the end of episode 1792 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 1s 327us/step - loss: 0.0029 - accuracy: 0.9920\n",
      "At the end of episode 1793 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2598/2598 [==============================] - 1s 314us/step - loss: -0.0070 - accuracy: 0.9896\n",
      "At the end of episode 1794 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2483/2483 [==============================] - 1s 300us/step - loss: -0.0020 - accuracy: 0.9911\n",
      "At the end of episode 1795 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3164/3164 [==============================] - 1s 297us/step - loss: -0.0085 - accuracy: 0.9867\n",
      "At the end of episode 1796 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2590/2590 [==============================] - 1s 305us/step - loss: -0.0014 - accuracy: 0.9857\n",
      "At the end of episode 1797 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 1s 286us/step - loss: -0.0083 - accuracy: 0.9858\n",
      "At the end of episode 1798 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3150/3150 [==============================] - 1s 291us/step - loss: -0.0016 - accuracy: 0.9905\n",
      "At the end of episode 1799 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2844/2844 [==============================] - 1s 299us/step - loss: 0.0050 - accuracy: 0.9912\n",
      "At the end of episode 1800 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 1s 298us/step - loss: 0.0029 - accuracy: 0.9887\n",
      "At the end of episode 1801 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2211/2211 [==============================] - 1s 290us/step - loss: 0.0168 - accuracy: 0.9860\n",
      "At the end of episode 1802 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2450/2450 [==============================] - 1s 306us/step - loss: -0.0021 - accuracy: 0.9906\n",
      "At the end of episode 1803 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2692/2692 [==============================] - 1s 299us/step - loss: 0.0050 - accuracy: 0.9870\n",
      "At the end of episode 1804 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2716/2716 [==============================] - 1s 289us/step - loss: -0.0029 - accuracy: 0.9886\n",
      "At the end of episode 1805 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2213/2213 [==============================] - 1s 311us/step - loss: 0.0039 - accuracy: 0.9946\n",
      "At the end of episode 1806 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2895/2895 [==============================] - 1s 300us/step - loss: -0.0062 - accuracy: 0.9917\n",
      "At the end of episode 1807 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2842/2842 [==============================] - 1s 294us/step - loss: 0.0067 - accuracy: 0.9898\n",
      "At the end of episode 1808 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2696/2696 [==============================] - 1s 307us/step - loss: -0.0013 - accuracy: 0.9848\n",
      "At the end of episode 1809 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2806/2806 [==============================] - 1s 305us/step - loss: 5.2745e-04 - accuracy: 0.9882\n",
      "At the end of episode 1810 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2195/2195 [==============================] - 1s 307us/step - loss: 0.0105 - accuracy: 0.9872\n",
      "At the end of episode 1811 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2690/2690 [==============================] - 1s 306us/step - loss: 5.2454e-04 - accuracy: 0.9877\n",
      "At the end of episode 1812 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2571/2571 [==============================] - 1s 305us/step - loss: -0.0038 - accuracy: 0.9879\n",
      "At the end of episode 1813 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "3075/3075 [==============================] - 1s 295us/step - loss: 0.0030 - accuracy: 0.9922\n",
      "At the end of episode 1814 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2904/2904 [==============================] - 1s 302us/step - loss: 0.0102 - accuracy: 0.9897\n",
      "At the end of episode 1815 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2970/2970 [==============================] - 1s 293us/step - loss: 0.0077 - accuracy: 0.9929\n",
      "At the end of episode 1816 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3232/3232 [==============================] - 1s 292us/step - loss: 0.0090 - accuracy: 0.9879\n",
      "At the end of episode 1817 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 1s 296us/step - loss: 0.0093 - accuracy: 0.9842\n",
      "At the end of episode 1818 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "3156/3156 [==============================] - 1s 295us/step - loss: 0.0018 - accuracy: 0.9832\n",
      "At the end of episode 1819 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2750/2750 [==============================] - 1s 299us/step - loss: -0.0079 - accuracy: 0.9891\n",
      "At the end of episode 1820 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3226/3226 [==============================] - 1s 312us/step - loss: -0.0021 - accuracy: 0.9904\n",
      "At the end of episode 1821 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "3390/3390 [==============================] - 1s 295us/step - loss: 0.0029 - accuracy: 0.9850\n",
      "At the end of episode 1822 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3739/3739 [==============================] - 1s 293us/step - loss: -0.0010 - accuracy: 0.9904\n",
      "At the end of episode 1823 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2355/2355 [==============================] - 1s 302us/step - loss: 0.0038 - accuracy: 0.9860\n",
      "At the end of episode 1824 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2772/2772 [==============================] - 1s 315us/step - loss: 0.0086 - accuracy: 0.9856\n",
      "At the end of episode 1825 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2961/2961 [==============================] - 1s 294us/step - loss: -0.0039 - accuracy: 0.9858\n",
      "At the end of episode 1826 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3115/3115 [==============================] - 1s 298us/step - loss: 0.0059 - accuracy: 0.9859\n",
      "At the end of episode 1827 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3418/3418 [==============================] - 1s 290us/step - loss: 0.0048 - accuracy: 0.9860\n",
      "At the end of episode 1828 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2749/2749 [==============================] - 1s 325us/step - loss: -8.9673e-04 - accuracy: 0.9895\n",
      "At the end of episode 1829 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2672/2672 [==============================] - 1s 292us/step - loss: -0.0107 - accuracy: 0.9884\n",
      "At the end of episode 1830 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2799/2799 [==============================] - 1s 293us/step - loss: -0.0046 - accuracy: 0.9846\n",
      "At the end of episode 1831 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2521/2521 [==============================] - 1s 305us/step - loss: -0.0099 - accuracy: 0.9861\n",
      "At the end of episode 1832 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2710/2710 [==============================] - 1s 298us/step - loss: 0.0042 - accuracy: 0.9845\n",
      "At the end of episode 1833 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2402/2402 [==============================] - 1s 314us/step - loss: -0.0058 - accuracy: 0.9896\n",
      "At the end of episode 1834 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2616/2616 [==============================] - 1s 307us/step - loss: 0.0032 - accuracy: 0.9839\n",
      "At the end of episode 1835 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3162/3162 [==============================] - 1s 305us/step - loss: 0.0061 - accuracy: 0.9851\n",
      "At the end of episode 1836 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2931/2931 [==============================] - 1s 303us/step - loss: -0.0014 - accuracy: 0.9881\n",
      "At the end of episode 1837 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2582/2582 [==============================] - 1s 298us/step - loss: 0.0067 - accuracy: 0.9880\n",
      "At the end of episode 1838 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1931/1931 [==============================] - 1s 310us/step - loss: -0.0043 - accuracy: 0.9886\n",
      "At the end of episode 1839 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2597/2597 [==============================] - 1s 298us/step - loss: -0.0055 - accuracy: 0.9881\n",
      "At the end of episode 1840 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2824/2824 [==============================] - 1s 303us/step - loss: 0.0032 - accuracy: 0.9862\n",
      "At the end of episode 1841 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2824/2824 [==============================] - 1s 293us/step - loss: -1.4968e-04 - accuracy: 0.9837\n",
      "At the end of episode 1842 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2650/2650 [==============================] - 1s 310us/step - loss: -0.0084 - accuracy: 0.9875\n",
      "At the end of episode 1843 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2502/2502 [==============================] - 1s 296us/step - loss: 0.0081 - accuracy: 0.9896\n",
      "At the end of episode 1844 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2932/2932 [==============================] - 1s 300us/step - loss: -0.0085 - accuracy: 0.9853\n",
      "At the end of episode 1845 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3775/3775 [==============================] - 1s 316us/step - loss: -0.0021 - accuracy: 0.9865\n",
      "At the end of episode 1846 the total reward was : -13.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2857/2857 [==============================] - 1s 312us/step - loss: 0.0064 - accuracy: 0.9881\n",
      "At the end of episode 1847 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3185/3185 [==============================] - 1s 307us/step - loss: 0.0034 - accuracy: 0.9884\n",
      "At the end of episode 1848 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2568/2568 [==============================] - 1s 294us/step - loss: -0.0078 - accuracy: 0.9887\n",
      "At the end of episode 1849 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3170/3170 [==============================] - 1s 293us/step - loss: -0.0062 - accuracy: 0.9893\n",
      "At the end of episode 1850 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2813/2813 [==============================] - 1s 289us/step - loss: 0.0031 - accuracy: 0.9897\n",
      "At the end of episode 1851 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2299/2299 [==============================] - 1s 304us/step - loss: 0.0201 - accuracy: 0.9861\n",
      "At the end of episode 1852 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2787/2787 [==============================] - 1s 314us/step - loss: -0.0130 - accuracy: 0.9803\n",
      "At the end of episode 1853 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1992/1992 [==============================] - 1s 291us/step - loss: 0.0018 - accuracy: 0.9849\n",
      "At the end of episode 1854 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2454/2454 [==============================] - 1s 313us/step - loss: 0.0020 - accuracy: 0.9861\n",
      "At the end of episode 1855 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2832/2832 [==============================] - 1s 298us/step - loss: -0.0027 - accuracy: 0.9883\n",
      "At the end of episode 1856 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2145/2145 [==============================] - 1s 288us/step - loss: -0.0022 - accuracy: 0.9907\n",
      "At the end of episode 1857 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 1s 302us/step - loss: -0.0062 - accuracy: 0.9909\n",
      "At the end of episode 1858 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2096/2096 [==============================] - 1s 307us/step - loss: 0.0116 - accuracy: 0.9881\n",
      "At the end of episode 1859 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2387/2387 [==============================] - 1s 298us/step - loss: 0.0059 - accuracy: 0.9899\n",
      "At the end of episode 1860 the total reward was : -10.0\n",
      "Epoch 1/1\n",
      "3311/3311 [==============================] - 1s 295us/step - loss: 0.0111 - accuracy: 0.9858\n",
      "At the end of episode 1861 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2934/2934 [==============================] - 1s 293us/step - loss: -0.0036 - accuracy: 0.9881\n",
      "At the end of episode 1862 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3185/3185 [==============================] - 1s 289us/step - loss: 0.0049 - accuracy: 0.9893\n",
      "At the end of episode 1863 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2869/2869 [==============================] - 1s 297us/step - loss: 0.0034 - accuracy: 0.9888\n",
      "At the end of episode 1864 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3206/3206 [==============================] - 1s 303us/step - loss: 0.0061 - accuracy: 0.9869\n",
      "At the end of episode 1865 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2567/2567 [==============================] - 1s 290us/step - loss: -0.0062 - accuracy: 0.9914\n",
      "At the end of episode 1866 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2231/2231 [==============================] - 1s 292us/step - loss: -8.1964e-04 - accuracy: 0.9866\n",
      "At the end of episode 1867 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3116/3116 [==============================] - 1s 305us/step - loss: -0.0025 - accuracy: 0.9894\n",
      "At the end of episode 1868 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2403/2403 [==============================] - 1s 298us/step - loss: -0.0031 - accuracy: 0.9900\n",
      "At the end of episode 1869 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2585/2585 [==============================] - 1s 304us/step - loss: -0.0079 - accuracy: 0.9853\n",
      "At the end of episode 1870 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3160/3160 [==============================] - 1s 303us/step - loss: 0.0046 - accuracy: 0.9858\n",
      "At the end of episode 1871 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2640/2640 [==============================] - 1s 293us/step - loss: -0.0088 - accuracy: 0.9867\n",
      "At the end of episode 1872 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2335/2335 [==============================] - 1s 303us/step - loss: 0.0022 - accuracy: 0.9842\n",
      "At the end of episode 1873 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2537/2537 [==============================] - 1s 328us/step - loss: 0.0044 - accuracy: 0.9913\n",
      "At the end of episode 1874 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2166/2166 [==============================] - 1s 320us/step - loss: 8.4540e-04 - accuracy: 0.9894\n",
      "At the end of episode 1875 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2777/2777 [==============================] - 1s 294us/step - loss: 0.0083 - accuracy: 0.9888\n",
      "At the end of episode 1876 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2905/2905 [==============================] - 1s 323us/step - loss: -0.0030 - accuracy: 0.9893\n",
      "At the end of episode 1877 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2773/2773 [==============================] - 1s 301us/step - loss: -0.0058 - accuracy: 0.9910\n",
      "At the end of episode 1878 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2853/2853 [==============================] - 1s 310us/step - loss: 0.0017 - accuracy: 0.9877\n",
      "At the end of episode 1879 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3124/3124 [==============================] - 1s 293us/step - loss: 0.0104 - accuracy: 0.9891\n",
      "At the end of episode 1880 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2562/2562 [==============================] - 1s 293us/step - loss: -7.5271e-04 - accuracy: 0.9902\n",
      "At the end of episode 1881 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2202/2202 [==============================] - 1s 302us/step - loss: -0.0018 - accuracy: 0.9837\n",
      "At the end of episode 1882 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3076/3076 [==============================] - 1s 302us/step - loss: -0.0054 - accuracy: 0.9886\n",
      "At the end of episode 1883 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3106/3106 [==============================] - 1s 292us/step - loss: -0.0040 - accuracy: 0.9862\n",
      "At the end of episode 1884 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2331/2331 [==============================] - 1s 302us/step - loss: 0.0011 - accuracy: 0.9880\n",
      "At the end of episode 1885 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2071/2071 [==============================] - 1s 293us/step - loss: 0.0061 - accuracy: 0.9860\n",
      "At the end of episode 1886 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2220/2220 [==============================] - 1s 300us/step - loss: -2.5386e-04 - accuracy: 0.9856\n",
      "At the end of episode 1887 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2855/2855 [==============================] - 1s 299us/step - loss: 0.0049 - accuracy: 0.9856\n",
      "At the end of episode 1888 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1972/1972 [==============================] - 1s 297us/step - loss: 0.0066 - accuracy: 0.9838\n",
      "At the end of episode 1889 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2647/2647 [==============================] - 1s 300us/step - loss: -0.0028 - accuracy: 0.9860\n",
      "At the end of episode 1890 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2672/2672 [==============================] - 1s 293us/step - loss: 0.0061 - accuracy: 0.9850\n",
      "At the end of episode 1891 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2631/2631 [==============================] - 1s 304us/step - loss: -0.0029 - accuracy: 0.9886\n",
      "At the end of episode 1892 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2955/2955 [==============================] - 1s 315us/step - loss: 0.0101 - accuracy: 0.9848\n",
      "At the end of episode 1893 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2240/2240 [==============================] - 1s 293us/step - loss: 0.0019 - accuracy: 0.9871\n",
      "At the end of episode 1894 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2438/2438 [==============================] - 1s 298us/step - loss: 0.0087 - accuracy: 0.9848\n",
      "At the end of episode 1895 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3151/3151 [==============================] - 1s 303us/step - loss: 0.0103 - accuracy: 0.9864\n",
      "At the end of episode 1896 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3110/3110 [==============================] - 1s 296us/step - loss: -6.5249e-04 - accuracy: 0.9900\n",
      "At the end of episode 1897 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3189/3189 [==============================] - 1s 305us/step - loss: 0.0018 - accuracy: 0.9900\n",
      "At the end of episode 1898 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3137/3137 [==============================] - 1s 310us/step - loss: -0.0075 - accuracy: 0.9850\n",
      "At the end of episode 1899 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3176/3176 [==============================] - 1s 290us/step - loss: -0.0080 - accuracy: 0.9811\n",
      "At the end of episode 1900 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2712/2712 [==============================] - 1s 307us/step - loss: -6.3080e-04 - accuracy: 0.9819\n",
      "At the end of episode 1901 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2257/2257 [==============================] - 1s 336us/step - loss: 0.0044 - accuracy: 0.9907\n",
      "At the end of episode 1902 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2743/2743 [==============================] - 1s 326us/step - loss: 4.8292e-04 - accuracy: 0.9876\n",
      "At the end of episode 1903 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2323/2323 [==============================] - 1s 293us/step - loss: -0.0018 - accuracy: 0.9875\n",
      "At the end of episode 1904 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2406/2406 [==============================] - 1s 312us/step - loss: 0.0026 - accuracy: 0.9884\n",
      "At the end of episode 1905 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2809/2809 [==============================] - 1s 290us/step - loss: 0.0033 - accuracy: 0.9883\n",
      "At the end of episode 1906 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2285/2285 [==============================] - 1s 291us/step - loss: -0.0052 - accuracy: 0.9877\n",
      "At the end of episode 1907 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2241/2241 [==============================] - 1s 305us/step - loss: 0.0055 - accuracy: 0.9871\n",
      "At the end of episode 1908 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1936/1936 [==============================] - 1s 310us/step - loss: 0.0057 - accuracy: 0.9897\n",
      "At the end of episode 1909 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2154/2154 [==============================] - 1s 300us/step - loss: 0.0032 - accuracy: 0.9889\n",
      "At the end of episode 1910 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2141/2141 [==============================] - 1s 300us/step - loss: 0.0111 - accuracy: 0.9888\n",
      "At the end of episode 1911 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2019/2019 [==============================] - 1s 303us/step - loss: 0.0053 - accuracy: 0.9876\n",
      "At the end of episode 1912 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2436/2436 [==============================] - 1s 291us/step - loss: 0.0062 - accuracy: 0.9885\n",
      "At the end of episode 1913 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1503/1503 [==============================] - 0s 292us/step - loss: 0.0037 - accuracy: 0.9854\n",
      "At the end of episode 1914 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2614/2614 [==============================] - 1s 295us/step - loss: 0.0122 - accuracy: 0.9858\n",
      "At the end of episode 1915 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2801/2801 [==============================] - 1s 297us/step - loss: 0.0105 - accuracy: 0.9879\n",
      "At the end of episode 1916 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1866/1866 [==============================] - 1s 295us/step - loss: -2.2027e-04 - accuracy: 0.9904\n",
      "At the end of episode 1917 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2083/2083 [==============================] - 1s 295us/step - loss: 0.0070 - accuracy: 0.9890\n",
      "At the end of episode 1918 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "1880/1880 [==============================] - 1s 294us/step - loss: -0.0047 - accuracy: 0.9872\n",
      "At the end of episode 1919 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2260/2260 [==============================] - 1s 292us/step - loss: -0.0104 - accuracy: 0.9805\n",
      "At the end of episode 1920 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2648/2648 [==============================] - 1s 292us/step - loss: -0.0067 - accuracy: 0.9883\n",
      "At the end of episode 1921 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2741/2741 [==============================] - 1s 299us/step - loss: 0.0046 - accuracy: 0.9861\n",
      "At the end of episode 1922 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2096/2096 [==============================] - 1s 299us/step - loss: -5.1580e-04 - accuracy: 0.9933\n",
      "At the end of episode 1923 the total reward was : -11.0\n",
      "Epoch 1/1\n",
      "2966/2966 [==============================] - 1s 290us/step - loss: 0.0119 - accuracy: 0.9916\n",
      "At the end of episode 1924 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3020/3020 [==============================] - 1s 312us/step - loss: 0.0013 - accuracy: 0.9868\n",
      "At the end of episode 1925 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2586/2586 [==============================] - 1s 299us/step - loss: -0.0101 - accuracy: 0.9830\n",
      "At the end of episode 1926 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2245/2245 [==============================] - 1s 298us/step - loss: 0.0029 - accuracy: 0.9840\n",
      "At the end of episode 1927 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2127/2127 [==============================] - 1s 291us/step - loss: 0.0121 - accuracy: 0.9850\n",
      "At the end of episode 1928 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1690/1690 [==============================] - 1s 311us/step - loss: -0.0030 - accuracy: 0.9852\n",
      "At the end of episode 1929 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2436/2436 [==============================] - 1s 306us/step - loss: 0.0043 - accuracy: 0.9893\n",
      "At the end of episode 1930 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2217/2217 [==============================] - 1s 309us/step - loss: -0.0055 - accuracy: 0.9910\n",
      "At the end of episode 1931 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2868/2868 [==============================] - 1s 317us/step - loss: 0.0056 - accuracy: 0.9791\n",
      "At the end of episode 1932 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2332/2332 [==============================] - 1s 308us/step - loss: 0.0156 - accuracy: 0.9863\n",
      "At the end of episode 1933 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2100/2100 [==============================] - 1s 318us/step - loss: 0.0021 - accuracy: 0.9881\n",
      "At the end of episode 1934 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1497/1497 [==============================] - 0s 312us/step - loss: 0.0098 - accuracy: 0.9866\n",
      "At the end of episode 1935 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "1599/1599 [==============================] - 0s 294us/step - loss: -0.0100 - accuracy: 0.9862\n",
      "At the end of episode 1936 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2333/2333 [==============================] - 1s 297us/step - loss: -0.0021 - accuracy: 0.9863\n",
      "At the end of episode 1937 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2303/2303 [==============================] - 1s 290us/step - loss: 0.0012 - accuracy: 0.9878\n",
      "At the end of episode 1938 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2080/2080 [==============================] - 1s 290us/step - loss: 0.0119 - accuracy: 0.9904\n",
      "At the end of episode 1939 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2095/2095 [==============================] - 1s 305us/step - loss: 0.0015 - accuracy: 0.9823\n",
      "At the end of episode 1940 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2624/2624 [==============================] - 1s 307us/step - loss: 0.0023 - accuracy: 0.9931\n",
      "At the end of episode 1941 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2584/2584 [==============================] - 1s 302us/step - loss: -0.0029 - accuracy: 0.9810\n",
      "At the end of episode 1942 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2239/2239 [==============================] - 1s 307us/step - loss: -0.0012 - accuracy: 0.9879\n",
      "At the end of episode 1943 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1500/1500 [==============================] - 0s 313us/step - loss: 0.0095 - accuracy: 0.9860\n",
      "At the end of episode 1944 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2335/2335 [==============================] - 1s 304us/step - loss: -0.0019 - accuracy: 0.9876\n",
      "At the end of episode 1945 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2161/2161 [==============================] - 1s 301us/step - loss: 0.0030 - accuracy: 0.9829\n",
      "At the end of episode 1946 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2027/2027 [==============================] - 1s 307us/step - loss: -0.0025 - accuracy: 0.9862\n",
      "At the end of episode 1947 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1390/1390 [==============================] - 0s 307us/step - loss: 0.0041 - accuracy: 0.9892\n",
      "At the end of episode 1948 the total reward was : -21.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1089/1089 [==============================] - 0s 317us/step - loss: 0.0079 - accuracy: 0.9807\n",
      "At the end of episode 1949 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2271/2271 [==============================] - 1s 300us/step - loss: -0.0054 - accuracy: 0.9894\n",
      "At the end of episode 1950 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2014/2014 [==============================] - 1s 305us/step - loss: -0.0057 - accuracy: 0.9906\n",
      "At the end of episode 1951 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1685/1685 [==============================] - 0s 294us/step - loss: 0.0098 - accuracy: 0.9858\n",
      "At the end of episode 1952 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2928/2928 [==============================] - 1s 287us/step - loss: 0.0086 - accuracy: 0.9894\n",
      "At the end of episode 1953 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2753/2753 [==============================] - 1s 315us/step - loss: -0.0021 - accuracy: 0.9876\n",
      "At the end of episode 1954 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2089/2089 [==============================] - 1s 290us/step - loss: 0.0026 - accuracy: 0.9828\n",
      "At the end of episode 1955 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2054/2054 [==============================] - 1s 293us/step - loss: 0.0114 - accuracy: 0.9864\n",
      "At the end of episode 1956 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2525/2525 [==============================] - 1s 287us/step - loss: 2.2760e-04 - accuracy: 0.9877\n",
      "At the end of episode 1957 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2736/2736 [==============================] - 1s 306us/step - loss: -0.0087 - accuracy: 0.9850\n",
      "At the end of episode 1958 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1911/1911 [==============================] - 1s 294us/step - loss: 0.0072 - accuracy: 0.9843\n",
      "At the end of episode 1959 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2345/2345 [==============================] - 1s 304us/step - loss: 0.0013 - accuracy: 0.9868\n",
      "At the end of episode 1960 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2087/2087 [==============================] - 1s 293us/step - loss: -0.0038 - accuracy: 0.9847\n",
      "At the end of episode 1961 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2546/2546 [==============================] - 1s 299us/step - loss: 0.0057 - accuracy: 0.9918\n",
      "At the end of episode 1962 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2395/2395 [==============================] - 1s 287us/step - loss: 0.0071 - accuracy: 0.9850\n",
      "At the end of episode 1963 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2827/2827 [==============================] - 1s 295us/step - loss: 0.0059 - accuracy: 0.9933\n",
      "At the end of episode 1964 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2842/2842 [==============================] - 1s 289us/step - loss: -9.6419e-04 - accuracy: 0.9916\n",
      "At the end of episode 1965 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2678/2678 [==============================] - 1s 292us/step - loss: 0.0094 - accuracy: 0.9869\n",
      "At the end of episode 1966 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2365/2365 [==============================] - 1s 290us/step - loss: 0.0047 - accuracy: 0.9865\n",
      "At the end of episode 1967 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2286/2286 [==============================] - 1s 312us/step - loss: -0.0069 - accuracy: 0.9878\n",
      "At the end of episode 1968 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2384/2384 [==============================] - 1s 291us/step - loss: 4.5344e-04 - accuracy: 0.9899\n",
      "At the end of episode 1969 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2252/2252 [==============================] - 1s 288us/step - loss: 0.0043 - accuracy: 0.9876\n",
      "At the end of episode 1970 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2333/2333 [==============================] - 1s 313us/step - loss: -8.4266e-04 - accuracy: 0.9841\n",
      "At the end of episode 1971 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2864/2864 [==============================] - 1s 295us/step - loss: 0.0039 - accuracy: 0.9853\n",
      "At the end of episode 1972 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2089/2089 [==============================] - 1s 310us/step - loss: -0.0020 - accuracy: 0.9928\n",
      "At the end of episode 1973 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2657/2657 [==============================] - 1s 292us/step - loss: 1.7051e-04 - accuracy: 0.9868\n",
      "At the end of episode 1974 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2276/2276 [==============================] - 1s 310us/step - loss: 0.0037 - accuracy: 0.9846\n",
      "At the end of episode 1975 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3126/3126 [==============================] - 1s 291us/step - loss: 0.0107 - accuracy: 0.9869\n",
      "At the end of episode 1976 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 1s 295us/step - loss: -0.0115 - accuracy: 0.9875\n",
      "At the end of episode 1977 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2277/2277 [==============================] - 1s 300us/step - loss: 0.0017 - accuracy: 0.9899\n",
      "At the end of episode 1978 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2504/2504 [==============================] - 1s 301us/step - loss: -0.0026 - accuracy: 0.9932\n",
      "At the end of episode 1979 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1742/1742 [==============================] - 1s 293us/step - loss: -0.0018 - accuracy: 0.9902\n",
      "At the end of episode 1980 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1881/1881 [==============================] - 1s 311us/step - loss: 3.2719e-04 - accuracy: 0.9920\n",
      "At the end of episode 1981 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2016/2016 [==============================] - 1s 295us/step - loss: 0.0011 - accuracy: 0.9901\n",
      "At the end of episode 1982 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "1721/1721 [==============================] - 1s 313us/step - loss: 0.0103 - accuracy: 0.9890\n",
      "At the end of episode 1983 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2326/2326 [==============================] - 1s 298us/step - loss: -0.0053 - accuracy: 0.9858\n",
      "At the end of episode 1984 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2839/2839 [==============================] - 1s 304us/step - loss: -0.0087 - accuracy: 0.9866\n",
      "At the end of episode 1985 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3277/3277 [==============================] - 1s 302us/step - loss: 0.0021 - accuracy: 0.9850\n",
      "At the end of episode 1986 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2535/2535 [==============================] - 1s 299us/step - loss: -0.0030 - accuracy: 0.9850\n",
      "At the end of episode 1987 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2787/2787 [==============================] - 1s 308us/step - loss: 5.7729e-04 - accuracy: 0.9878\n",
      "At the end of episode 1988 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2165/2165 [==============================] - 1s 373us/step - loss: 0.0012 - accuracy: 0.9861\n",
      "At the end of episode 1989 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1833/1833 [==============================] - 1s 307us/step - loss: 0.0012 - accuracy: 0.9902\n",
      "At the end of episode 1990 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2562/2562 [==============================] - 1s 311us/step - loss: 0.0129 - accuracy: 0.9879\n",
      "At the end of episode 1991 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2921/2921 [==============================] - 1s 300us/step - loss: 0.0085 - accuracy: 0.9808\n",
      "At the end of episode 1992 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3167/3167 [==============================] - 1s 294us/step - loss: 0.0049 - accuracy: 0.9893\n",
      "At the end of episode 1993 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2634/2634 [==============================] - 1s 300us/step - loss: 6.5242e-04 - accuracy: 0.9905\n",
      "At the end of episode 1994 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2236/2236 [==============================] - 1s 302us/step - loss: 0.0025 - accuracy: 0.9893\n",
      "At the end of episode 1995 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2789/2789 [==============================] - 1s 299us/step - loss: 0.0075 - accuracy: 0.9846\n",
      "At the end of episode 1996 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2597/2597 [==============================] - 1s 306us/step - loss: -0.0039 - accuracy: 0.9858\n",
      "At the end of episode 1997 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2789/2789 [==============================] - 1s 327us/step - loss: -0.0083 - accuracy: 0.9907\n",
      "At the end of episode 1998 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3272/3272 [==============================] - 1s 325us/step - loss: 0.0078 - accuracy: 0.9829\n",
      "At the end of episode 1999 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2593/2593 [==============================] - 1s 291us/step - loss: 9.6705e-04 - accuracy: 0.9807\n",
      "At the end of episode 2000 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2478/2478 [==============================] - 1s 289us/step - loss: -0.0035 - accuracy: 0.9851\n",
      "At the end of episode 2001 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3480/3480 [==============================] - 1s 290us/step - loss: -6.1504e-04 - accuracy: 0.9882\n",
      "At the end of episode 2002 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2803/2803 [==============================] - 1s 314us/step - loss: -0.0029 - accuracy: 0.9932\n",
      "At the end of episode 2003 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3007/3007 [==============================] - 1s 306us/step - loss: -0.0033 - accuracy: 0.9917\n",
      "At the end of episode 2004 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2863/2863 [==============================] - 1s 293us/step - loss: -0.0022 - accuracy: 0.9839\n",
      "At the end of episode 2005 the total reward was : -10.0\n",
      "Epoch 1/1\n",
      "3240/3240 [==============================] - 1s 305us/step - loss: -1.2573e-05 - accuracy: 0.9836\n",
      "At the end of episode 2006 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3026/3026 [==============================] - 1s 302us/step - loss: 9.2543e-04 - accuracy: 0.9917\n",
      "At the end of episode 2007 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3076/3076 [==============================] - 1s 357us/step - loss: 0.0012 - accuracy: 0.9886\n",
      "At the end of episode 2008 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2838/2838 [==============================] - 1s 358us/step - loss: 0.0017 - accuracy: 0.9891\n",
      "At the end of episode 2009 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2794/2794 [==============================] - 1s 336us/step - loss: -0.0037 - accuracy: 0.9903\n",
      "At the end of episode 2010 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3211/3211 [==============================] - 1s 382us/step - loss: -0.0124 - accuracy: 0.9891\n",
      "At the end of episode 2011 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3119/3119 [==============================] - 1s 372us/step - loss: 7.7767e-04 - accuracy: 0.9910\n",
      "At the end of episode 2012 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2844/2844 [==============================] - 1s 391us/step - loss: -0.0084 - accuracy: 0.9877\n",
      "At the end of episode 2013 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 1s 383us/step - loss: -0.0066 - accuracy: 0.9882\n",
      "At the end of episode 2014 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3067/3067 [==============================] - 1s 448us/step - loss: -0.0028 - accuracy: 0.9879\n",
      "At the end of episode 2015 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2953/2953 [==============================] - 1s 410us/step - loss: 0.0065 - accuracy: 0.9858\n",
      "At the end of episode 2016 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3013/3013 [==============================] - 1s 324us/step - loss: -0.0248 - accuracy: 0.9864\n",
      "At the end of episode 2017 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3389/3389 [==============================] - 1s 281us/step - loss: 8.2153e-04 - accuracy: 0.9882\n",
      "At the end of episode 2018 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2634/2634 [==============================] - 1s 293us/step - loss: -0.0042 - accuracy: 0.9905\n",
      "At the end of episode 2019 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3154/3154 [==============================] - 1s 278us/step - loss: 7.3190e-04 - accuracy: 0.9899\n",
      "At the end of episode 2020 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3800/3800 [==============================] - 2s 415us/step - loss: -0.0027 - accuracy: 0.9895\n",
      "At the end of episode 2021 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3376/3376 [==============================] - 1s 393us/step - loss: -0.0064 - accuracy: 0.9855\n",
      "At the end of episode 2022 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3144/3144 [==============================] - 1s 291us/step - loss: 0.0087 - accuracy: 0.9901\n",
      "At the end of episode 2023 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2729/2729 [==============================] - 1s 312us/step - loss: -0.0056 - accuracy: 0.9901\n",
      "At the end of episode 2024 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3392/3392 [==============================] - 1s 299us/step - loss: -0.0018 - accuracy: 0.9929\n",
      "At the end of episode 2025 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 1s 297us/step - loss: -0.0054 - accuracy: 0.9891\n",
      "At the end of episode 2026 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3489/3489 [==============================] - 1s 275us/step - loss: -0.0068 - accuracy: 0.9871\n",
      "At the end of episode 2027 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2641/2641 [==============================] - 1s 290us/step - loss: 4.4098e-04 - accuracy: 0.9856\n",
      "At the end of episode 2028 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2918/2918 [==============================] - 1s 280us/step - loss: -0.0025 - accuracy: 0.9880\n",
      "At the end of episode 2029 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2573/2573 [==============================] - 1s 288us/step - loss: -0.0021 - accuracy: 0.9918\n",
      "At the end of episode 2030 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 1s 350us/step - loss: -8.4891e-04 - accuracy: 0.9891\n",
      "At the end of episode 2031 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3019/3019 [==============================] - 1s 339us/step - loss: -0.0052 - accuracy: 0.9877\n",
      "At the end of episode 2032 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3262/3262 [==============================] - 1s 278us/step - loss: 0.0021 - accuracy: 0.9844\n",
      "At the end of episode 2033 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2702/2702 [==============================] - 1s 290us/step - loss: 4.9845e-04 - accuracy: 0.9911\n",
      "At the end of episode 2034 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2989/2989 [==============================] - 1s 277us/step - loss: 0.0049 - accuracy: 0.9886\n",
      "At the end of episode 2035 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "3312/3312 [==============================] - 1s 271us/step - loss: 0.0011 - accuracy: 0.9915\n",
      "At the end of episode 2036 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2939/2939 [==============================] - 1s 289us/step - loss: -0.0015 - accuracy: 0.9929\n",
      "At the end of episode 2037 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2861/2861 [==============================] - 1s 282us/step - loss: -0.0022 - accuracy: 0.9871\n",
      "At the end of episode 2038 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3150/3150 [==============================] - 1s 285us/step - loss: -0.0054 - accuracy: 0.9844\n",
      "At the end of episode 2039 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "3117/3117 [==============================] - 1s 287us/step - loss: -0.0110 - accuracy: 0.9865\n",
      "At the end of episode 2040 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3070/3070 [==============================] - 1s 445us/step - loss: 3.0347e-05 - accuracy: 0.9886\n",
      "At the end of episode 2041 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2112/2112 [==============================] - 1s 286us/step - loss: 0.0090 - accuracy: 0.9872\n",
      "At the end of episode 2042 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2483/2483 [==============================] - 1s 277us/step - loss: 0.0095 - accuracy: 0.9887\n",
      "At the end of episode 2043 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2645/2645 [==============================] - 1s 292us/step - loss: -0.0044 - accuracy: 0.9898\n",
      "At the end of episode 2044 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2588/2588 [==============================] - 1s 301us/step - loss: -0.0055 - accuracy: 0.9880\n",
      "At the end of episode 2045 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2773/2773 [==============================] - 1s 292us/step - loss: -0.0011 - accuracy: 0.9903\n",
      "At the end of episode 2046 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2550/2550 [==============================] - 1s 319us/step - loss: -0.0026 - accuracy: 0.9863\n",
      "At the end of episode 2047 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2503/2503 [==============================] - 1s 398us/step - loss: -0.0037 - accuracy: 0.9908\n",
      "At the end of episode 2048 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2625/2625 [==============================] - 1s 423us/step - loss: 0.0085 - accuracy: 0.9855\n",
      "At the end of episode 2049 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2716/2716 [==============================] - 1s 407us/step - loss: -0.0083 - accuracy: 0.9886\n",
      "At the end of episode 2050 the total reward was : -19.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3390/3390 [==============================] - 1s 326us/step - loss: -8.3790e-04 - accuracy: 0.9826\n",
      "At the end of episode 2051 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2882/2882 [==============================] - 1s 309us/step - loss: 0.0036 - accuracy: 0.9854\n",
      "At the end of episode 2052 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2761/2761 [==============================] - 1s 311us/step - loss: -0.0017 - accuracy: 0.9862\n",
      "At the end of episode 2053 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3083/3083 [==============================] - 1s 295us/step - loss: 0.0049 - accuracy: 0.9864\n",
      "At the end of episode 2054 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2840/2840 [==============================] - 1s 270us/step - loss: -0.0040 - accuracy: 0.9870\n",
      "At the end of episode 2055 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2803/2803 [==============================] - 1s 268us/step - loss: 4.6032e-04 - accuracy: 0.9893\n",
      "At the end of episode 2056 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2997/2997 [==============================] - 1s 268us/step - loss: 0.0067 - accuracy: 0.9877\n",
      "At the end of episode 2057 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3165/3165 [==============================] - 1s 269us/step - loss: -0.0021 - accuracy: 0.9848\n",
      "At the end of episode 2058 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3074/3074 [==============================] - 1s 287us/step - loss: -0.0021 - accuracy: 0.9912\n",
      "At the end of episode 2059 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3114/3114 [==============================] - 1s 278us/step - loss: 0.0072 - accuracy: 0.9881\n",
      "At the end of episode 2060 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3405/3405 [==============================] - 1s 324us/step - loss: 0.0018 - accuracy: 0.9874\n",
      "At the end of episode 2061 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2572/2572 [==============================] - 1s 273us/step - loss: -0.0023 - accuracy: 0.9907\n",
      "At the end of episode 2062 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2985/2985 [==============================] - 1s 306us/step - loss: 8.6430e-04 - accuracy: 0.9883\n",
      "At the end of episode 2063 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3576/3576 [==============================] - 1s 368us/step - loss: -0.0051 - accuracy: 0.9846\n",
      "At the end of episode 2064 the total reward was : -11.0\n",
      "Epoch 1/1\n",
      "3261/3261 [==============================] - 1s 380us/step - loss: 0.0062 - accuracy: 0.9865\n",
      "At the end of episode 2065 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3717/3717 [==============================] - 1s 292us/step - loss: 0.0036 - accuracy: 0.9874\n",
      "At the end of episode 2066 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2929/2929 [==============================] - 1s 281us/step - loss: -0.0035 - accuracy: 0.9894\n",
      "At the end of episode 2067 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2990/2990 [==============================] - 1s 283us/step - loss: 0.0023 - accuracy: 0.9893\n",
      "At the end of episode 2068 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2630/2630 [==============================] - 1s 297us/step - loss: -2.6317e-04 - accuracy: 0.9920\n",
      "At the end of episode 2069 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3783/3783 [==============================] - 1s 329us/step - loss: -0.0484 - accuracy: 0.9807\n",
      "At the end of episode 2070 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2554/2554 [==============================] - 1s 340us/step - loss: 0.0061 - accuracy: 0.9890\n",
      "At the end of episode 2071 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3749/3749 [==============================] - 1s 384us/step - loss: -0.0194 - accuracy: 0.9877\n",
      "At the end of episode 2072 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2385/2385 [==============================] - 1s 389us/step - loss: -0.0033 - accuracy: 0.9853\n",
      "At the end of episode 2073 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 1s 371us/step - loss: 0.0017 - accuracy: 0.9912\n",
      "At the end of episode 2074 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2514/2514 [==============================] - 1s 305us/step - loss: -0.0021 - accuracy: 0.9861\n",
      "At the end of episode 2075 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2761/2761 [==============================] - 1s 280us/step - loss: -0.0045 - accuracy: 0.9862\n",
      "At the end of episode 2076 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2919/2919 [==============================] - 1s 295us/step - loss: 0.0040 - accuracy: 0.9904\n",
      "At the end of episode 2077 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2358/2358 [==============================] - 1s 273us/step - loss: 0.0116 - accuracy: 0.9822\n",
      "At the end of episode 2078 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2363/2363 [==============================] - 1s 300us/step - loss: 5.4886e-04 - accuracy: 0.9877\n",
      "At the end of episode 2079 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1974/1974 [==============================] - 1s 397us/step - loss: -0.0012 - accuracy: 0.9873\n",
      "At the end of episode 2080 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3014/3014 [==============================] - 1s 414us/step - loss: -0.0038 - accuracy: 0.9904\n",
      "At the end of episode 2081 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2975/2975 [==============================] - 1s 349us/step - loss: -0.0036 - accuracy: 0.9923\n",
      "At the end of episode 2082 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2543/2543 [==============================] - 1s 370us/step - loss: 0.0027 - accuracy: 0.9917\n",
      "At the end of episode 2083 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3356/3356 [==============================] - 1s 327us/step - loss: 0.0028 - accuracy: 0.9860\n",
      "At the end of episode 2084 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2835/2835 [==============================] - 1s 321us/step - loss: -0.0019 - accuracy: 0.9827\n",
      "At the end of episode 2085 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3057/3057 [==============================] - 1s 288us/step - loss: -0.0067 - accuracy: 0.9866\n",
      "At the end of episode 2086 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2749/2749 [==============================] - 1s 290us/step - loss: 0.0052 - accuracy: 0.9891\n",
      "At the end of episode 2087 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2939/2939 [==============================] - 1s 272us/step - loss: -0.0023 - accuracy: 0.9908\n",
      "At the end of episode 2088 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2898/2898 [==============================] - 1s 287us/step - loss: -0.0095 - accuracy: 0.9903\n",
      "At the end of episode 2089 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 1s 283us/step - loss: -4.5276e-04 - accuracy: 0.9905\n",
      "At the end of episode 2090 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3427/3427 [==============================] - 1s 297us/step - loss: -0.0086 - accuracy: 0.9927\n",
      "At the end of episode 2091 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "3135/3135 [==============================] - 1s 321us/step - loss: 0.0071 - accuracy: 0.9856\n",
      "At the end of episode 2092 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2848/2848 [==============================] - 1s 317us/step - loss: -4.0706e-04 - accuracy: 0.9870\n",
      "At the end of episode 2093 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2671/2671 [==============================] - 1s 309us/step - loss: -0.0021 - accuracy: 0.9918\n",
      "At the end of episode 2094 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "3446/3446 [==============================] - 1s 409us/step - loss: 0.0027 - accuracy: 0.9861\n",
      "At the end of episode 2095 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "3467/3467 [==============================] - 1s 358us/step - loss: 0.0053 - accuracy: 0.9879\n",
      "At the end of episode 2096 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3203/3203 [==============================] - 1s 294us/step - loss: 0.0056 - accuracy: 0.9884\n",
      "At the end of episode 2097 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3198/3198 [==============================] - 1s 278us/step - loss: -0.0049 - accuracy: 0.9869\n",
      "At the end of episode 2098 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3245/3245 [==============================] - 1s 279us/step - loss: -0.0012 - accuracy: 0.9846\n",
      "At the end of episode 2099 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3238/3238 [==============================] - 1s 293us/step - loss: -0.0063 - accuracy: 0.9818\n",
      "At the end of episode 2100 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "3025/3025 [==============================] - 1s 308us/step - loss: 0.0045 - accuracy: 0.9914\n",
      "At the end of episode 2101 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3549/3549 [==============================] - 1s 388us/step - loss: 3.5308e-04 - accuracy: 0.9890\n",
      "At the end of episode 2102 the total reward was : -10.0\n",
      "Epoch 1/1\n",
      "3226/3226 [==============================] - 1s 385us/step - loss: 0.0034 - accuracy: 0.9916\n",
      "At the end of episode 2103 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2577/2577 [==============================] - 1s 382us/step - loss: 0.0048 - accuracy: 0.9864\n",
      "At the end of episode 2104 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2941/2941 [==============================] - 1s 385us/step - loss: -0.0078 - accuracy: 0.9864\n",
      "At the end of episode 2105 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2735/2735 [==============================] - 1s 478us/step - loss: -0.0050 - accuracy: 0.9905\n",
      "At the end of episode 2106 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2764/2764 [==============================] - 1s 375us/step - loss: 0.0058 - accuracy: 0.9910\n",
      "At the end of episode 2107 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2942/2942 [==============================] - 1s 387us/step - loss: -0.0087 - accuracy: 0.9844\n",
      "At the end of episode 2108 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 1s 391us/step - loss: 0.0017 - accuracy: 0.9929\n",
      "At the end of episode 2109 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3209/3209 [==============================] - 1s 398us/step - loss: 0.0011 - accuracy: 0.9919\n",
      "At the end of episode 2110 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2992/2992 [==============================] - 1s 368us/step - loss: -0.0047 - accuracy: 0.9916\n",
      "At the end of episode 2111 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3004/3004 [==============================] - 1s 340us/step - loss: 0.0011 - accuracy: 0.9880\n",
      "At the end of episode 2112 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2854/2854 [==============================] - 1s 381us/step - loss: -0.0056 - accuracy: 0.9856\n",
      "At the end of episode 2113 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3096/3096 [==============================] - 1s 298us/step - loss: -0.0056 - accuracy: 0.9871\n",
      "At the end of episode 2114 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2741/2741 [==============================] - 1s 267us/step - loss: 0.0091 - accuracy: 0.9894\n",
      "At the end of episode 2115 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3008/3008 [==============================] - 1s 274us/step - loss: -6.7057e-04 - accuracy: 0.9900\n",
      "At the end of episode 2116 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3149/3149 [==============================] - 1s 288us/step - loss: 7.8194e-04 - accuracy: 0.9914\n",
      "At the end of episode 2117 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3467/3467 [==============================] - 1s 295us/step - loss: -0.0112 - accuracy: 0.9870\n",
      "At the end of episode 2118 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3233/3233 [==============================] - 1s 359us/step - loss: 0.0011 - accuracy: 0.9848\n",
      "At the end of episode 2119 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2917/2917 [==============================] - 1s 371us/step - loss: -9.9724e-04 - accuracy: 0.9890\n",
      "At the end of episode 2120 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2922/2922 [==============================] - 1s 412us/step - loss: -0.0012 - accuracy: 0.9873\n",
      "At the end of episode 2121 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3246/3246 [==============================] - 1s 264us/step - loss: -0.0080 - accuracy: 0.9871\n",
      "At the end of episode 2122 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2748/2748 [==============================] - 1s 268us/step - loss: 0.0030 - accuracy: 0.9811\n",
      "At the end of episode 2123 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3526/3526 [==============================] - 1s 269us/step - loss: 0.0025 - accuracy: 0.9838\n",
      "At the end of episode 2124 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2790/2790 [==============================] - 1s 276us/step - loss: -0.0019 - accuracy: 0.9900\n",
      "At the end of episode 2125 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2684/2684 [==============================] - 608s 226ms/step - loss: 0.0065 - accuracy: 0.9907\n",
      "At the end of episode 2126 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2685/2685 [==============================] - 1s 308us/step - loss: -0.0024 - accuracy: 0.9896\n",
      "At the end of episode 2127 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3048/3048 [==============================] - 7s 2ms/step - loss: -0.0036 - accuracy: 0.9885\n",
      "At the end of episode 2128 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2782/2782 [==============================] - 1s 274us/step - loss: -0.0012 - accuracy: 0.9928\n",
      "At the end of episode 2129 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3387/3387 [==============================] - 1s 265us/step - loss: -0.0050 - accuracy: 0.9867\n",
      "At the end of episode 2130 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3103/3103 [==============================] - 1s 284us/step - loss: 0.0011 - accuracy: 0.9916\n",
      "At the end of episode 2131 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2861/2861 [==============================] - 1s 262us/step - loss: 0.0045 - accuracy: 0.9909\n",
      "At the end of episode 2132 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2935/2935 [==============================] - 1s 262us/step - loss: 0.0100 - accuracy: 0.9891\n",
      "At the end of episode 2133 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2573/2573 [==============================] - 1s 274us/step - loss: -0.0107 - accuracy: 0.9868\n",
      "At the end of episode 2134 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2960/2960 [==============================] - 2s 568us/step - loss: -0.0067 - accuracy: 0.9851\n",
      "At the end of episode 2135 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2929/2929 [==============================] - 1s 336us/step - loss: -0.0028 - accuracy: 0.9870\n",
      "At the end of episode 2136 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2268/2268 [==============================] - 1s 348us/step - loss: -0.0024 - accuracy: 0.9921\n",
      "At the end of episode 2137 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3504/3504 [==============================] - 1s 299us/step - loss: -8.0140e-05 - accuracy: 0.9903\n",
      "At the end of episode 2138 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2919/2919 [==============================] - 1s 279us/step - loss: -0.0041 - accuracy: 0.9884\n",
      "At the end of episode 2139 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2764/2764 [==============================] - 1s 281us/step - loss: -0.0061 - accuracy: 0.9866\n",
      "At the end of episode 2140 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2403/2403 [==============================] - 1s 294us/step - loss: -0.0066 - accuracy: 0.9854\n",
      "At the end of episode 2141 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2914/2914 [==============================] - 1s 280us/step - loss: 0.0094 - accuracy: 0.9914\n",
      "At the end of episode 2142 the total reward was : -10.0\n",
      "Epoch 1/1\n",
      "4512/4512 [==============================] - 2s 338us/step - loss: -0.0064 - accuracy: 0.9894\n",
      "At the end of episode 2143 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3137/3137 [==============================] - 2s 583us/step - loss: 0.0140 - accuracy: 0.9831\n",
      "At the end of episode 2144 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2664/2664 [==============================] - 1s 292us/step - loss: -0.0029 - accuracy: 0.9910\n",
      "At the end of episode 2145 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2605/2605 [==============================] - 1s 278us/step - loss: 0.0032 - accuracy: 0.9889\n",
      "At the end of episode 2146 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2843/2843 [==============================] - 1s 303us/step - loss: 0.0066 - accuracy: 0.9905\n",
      "At the end of episode 2147 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3176/3176 [==============================] - 1s 281us/step - loss: 2.7216e-04 - accuracy: 0.9915\n",
      "At the end of episode 2148 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2912/2912 [==============================] - 1s 272us/step - loss: 0.0027 - accuracy: 0.9849\n",
      "At the end of episode 2149 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2859/2859 [==============================] - 1s 274us/step - loss: 1.3476e-04 - accuracy: 0.9906\n",
      "At the end of episode 2150 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2974/2974 [==============================] - 1s 275us/step - loss: -0.0024 - accuracy: 0.9892\n",
      "At the end of episode 2151 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2666/2666 [==============================] - 1s 317us/step - loss: -0.0040 - accuracy: 0.9910\n",
      "At the end of episode 2152 the total reward was : -19.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2747/2747 [==============================] - 1s 264us/step - loss: 2.8123e-05 - accuracy: 0.9924\n",
      "At the end of episode 2153 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2749/2749 [==============================] - 1s 275us/step - loss: -0.0052 - accuracy: 0.9887\n",
      "At the end of episode 2154 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "3095/3095 [==============================] - 1s 274us/step - loss: -7.6055e-04 - accuracy: 0.9906\n",
      "At the end of episode 2155 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2809/2809 [==============================] - 1s 285us/step - loss: -0.0058 - accuracy: 0.9833\n",
      "At the end of episode 2156 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3167/3167 [==============================] - 1s 277us/step - loss: -0.0013 - accuracy: 0.9905\n",
      "At the end of episode 2157 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2685/2685 [==============================] - 1s 271us/step - loss: -0.0047 - accuracy: 0.9896\n",
      "At the end of episode 2158 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2223/2223 [==============================] - 1s 283us/step - loss: 0.0040 - accuracy: 0.9915\n",
      "At the end of episode 2159 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2592/2592 [==============================] - 1s 277us/step - loss: -0.0084 - accuracy: 0.9892\n",
      "At the end of episode 2160 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2552/2552 [==============================] - 2s 589us/step - loss: -3.0018e-04 - accuracy: 0.9894\n",
      "At the end of episode 2161 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2745/2745 [==============================] - 1s 281us/step - loss: -0.0020 - accuracy: 0.9920\n",
      "At the end of episode 2162 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3143/3143 [==============================] - 3s 986us/step - loss: 0.0024 - accuracy: 0.9927\n",
      "At the end of episode 2163 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2745/2745 [==============================] - 1s 287us/step - loss: 0.0054 - accuracy: 0.9920\n",
      "At the end of episode 2164 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2695/2695 [==============================] - 1s 288us/step - loss: -0.0048 - accuracy: 0.9881\n",
      "At the end of episode 2165 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2939/2939 [==============================] - 1s 263us/step - loss: -0.0037 - accuracy: 0.9922\n",
      "At the end of episode 2166 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3257/3257 [==============================] - 1s 275us/step - loss: -0.0040 - accuracy: 0.9880\n",
      "At the end of episode 2167 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2631/2631 [==============================] - 1s 279us/step - loss: 0.0034 - accuracy: 0.9905\n",
      "At the end of episode 2168 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3398/3398 [==============================] - 1s 278us/step - loss: 6.0470e-04 - accuracy: 0.9853\n",
      "At the end of episode 2169 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2959/2959 [==============================] - 2s 594us/step - loss: 0.0049 - accuracy: 0.9885\n",
      "At the end of episode 2170 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3510/3510 [==============================] - 1s 285us/step - loss: 0.0021 - accuracy: 0.9926\n",
      "At the end of episode 2171 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2634/2634 [==============================] - 1s 333us/step - loss: 0.0025 - accuracy: 0.9901\n",
      "At the end of episode 2172 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2871/2871 [==============================] - 1s 283us/step - loss: 0.0185 - accuracy: 0.9875\n",
      "At the end of episode 2173 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3039/3039 [==============================] - 1s 282us/step - loss: -2.8376e-04 - accuracy: 0.9928\n",
      "At the end of episode 2174 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2902/2902 [==============================] - 1s 286us/step - loss: 0.0091 - accuracy: 0.9883\n",
      "At the end of episode 2175 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3244/3244 [==============================] - 1s 281us/step - loss: -0.0017 - accuracy: 0.9951\n",
      "At the end of episode 2176 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2604/2604 [==============================] - 1s 291us/step - loss: -0.0033 - accuracy: 0.9919\n",
      "At the end of episode 2177 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3185/3185 [==============================] - 1s 267us/step - loss: -0.0043 - accuracy: 0.9925\n",
      "At the end of episode 2178 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3238/3238 [==============================] - 1s 375us/step - loss: -0.0033 - accuracy: 0.9867\n",
      "At the end of episode 2179 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2571/2571 [==============================] - 6s 2ms/step - loss: 0.0039 - accuracy: 0.9911\n",
      "At the end of episode 2180 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2849/2849 [==============================] - 1s 283us/step - loss: 0.0065 - accuracy: 0.9923\n",
      "At the end of episode 2181 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 1s 277us/step - loss: -0.0057 - accuracy: 0.9870\n",
      "At the end of episode 2182 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3301/3301 [==============================] - 1s 266us/step - loss: -0.0073 - accuracy: 0.9894\n",
      "At the end of episode 2183 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3256/3256 [==============================] - 1s 264us/step - loss: 0.0061 - accuracy: 0.9843\n",
      "At the end of episode 2184 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3567/3567 [==============================] - 1s 264us/step - loss: -0.0052 - accuracy: 0.9899\n",
      "At the end of episode 2185 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2747/2747 [==============================] - 1s 268us/step - loss: -0.0171 - accuracy: 0.9880\n",
      "At the end of episode 2186 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3000/3000 [==============================] - 1s 489us/step - loss: -0.0033 - accuracy: 0.9877\n",
      "At the end of episode 2187 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2905/2905 [==============================] - 1s 418us/step - loss: -0.0021 - accuracy: 0.9897\n",
      "At the end of episode 2188 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2918/2918 [==============================] - 1s 439us/step - loss: -0.0032 - accuracy: 0.9911\n",
      "At the end of episode 2189 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2640/2640 [==============================] - 1s 488us/step - loss: 0.0043 - accuracy: 0.9920\n",
      "At the end of episode 2190 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2814/2814 [==============================] - 1s 386us/step - loss: 6.4369e-04 - accuracy: 0.9929\n",
      "At the end of episode 2191 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2797/2797 [==============================] - 1s 376us/step - loss: -0.0048 - accuracy: 0.9903\n",
      "At the end of episode 2192 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2990/2990 [==============================] - 1s 417us/step - loss: 0.0057 - accuracy: 0.9916\n",
      "At the end of episode 2193 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 1s 354us/step - loss: 0.0031 - accuracy: 0.9903\n",
      "At the end of episode 2194 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2528/2528 [==============================] - 1s 333us/step - loss: -0.0039 - accuracy: 0.9925\n",
      "At the end of episode 2195 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3214/3214 [==============================] - 1s 376us/step - loss: -8.8912e-04 - accuracy: 0.9910\n",
      "At the end of episode 2196 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2726/2726 [==============================] - 1s 408us/step - loss: 0.0036 - accuracy: 0.9938\n",
      "At the end of episode 2197 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3452/3452 [==============================] - 1s 321us/step - loss: -0.0136 - accuracy: 0.9878\n",
      "At the end of episode 2198 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3011/3011 [==============================] - 1s 329us/step - loss: -0.0107 - accuracy: 0.9880\n",
      "At the end of episode 2199 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2731/2731 [==============================] - 1s 338us/step - loss: -0.0078 - accuracy: 0.9894\n",
      "At the end of episode 2200 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2830/2830 [==============================] - 1s 343us/step - loss: 0.0060 - accuracy: 0.9905\n",
      "At the end of episode 2201 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2894/2894 [==============================] - 1s 395us/step - loss: -0.0034 - accuracy: 0.9934\n",
      "At the end of episode 2202 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2910/2910 [==============================] - 1s 400us/step - loss: 0.0014 - accuracy: 0.9883\n",
      "At the end of episode 2203 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2917/2917 [==============================] - 1s 342us/step - loss: -0.0179 - accuracy: 0.9846\n",
      "At the end of episode 2204 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3145/3145 [==============================] - 1s 318us/step - loss: 0.0027 - accuracy: 0.9924\n",
      "At the end of episode 2205 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3475/3475 [==============================] - 1s 313us/step - loss: 0.0116 - accuracy: 0.9917\n",
      "At the end of episode 2206 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2366/2366 [==============================] - 1s 319us/step - loss: -0.0017 - accuracy: 0.9899\n",
      "At the end of episode 2207 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2669/2669 [==============================] - 1s 331us/step - loss: 0.0023 - accuracy: 0.9921\n",
      "At the end of episode 2208 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2949/2949 [==============================] - 1s 315us/step - loss: -0.0023 - accuracy: 0.9871\n",
      "At the end of episode 2209 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3348/3348 [==============================] - 1s 359us/step - loss: 3.5650e-04 - accuracy: 0.9937\n",
      "At the end of episode 2210 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3536/3536 [==============================] - 1s 317us/step - loss: -0.0036 - accuracy: 0.9881\n",
      "At the end of episode 2211 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3065/3065 [==============================] - 1s 317us/step - loss: 0.0067 - accuracy: 0.9912\n",
      "At the end of episode 2212 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2849/2849 [==============================] - 1s 324us/step - loss: -0.0061 - accuracy: 0.9930\n",
      "At the end of episode 2213 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3098/3098 [==============================] - 1s 363us/step - loss: -0.0055 - accuracy: 0.9839\n",
      "At the end of episode 2214 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2602/2602 [==============================] - 1s 397us/step - loss: -0.0012 - accuracy: 0.9908\n",
      "At the end of episode 2215 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3673/3673 [==============================] - 1s 309us/step - loss: 0.0032 - accuracy: 0.9858\n",
      "At the end of episode 2216 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3220/3220 [==============================] - 1s 410us/step - loss: -0.0025 - accuracy: 0.9907\n",
      "At the end of episode 2217 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "3146/3146 [==============================] - 1s 331us/step - loss: -0.0086 - accuracy: 0.9863\n",
      "At the end of episode 2218 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 1s 426us/step - loss: 4.0802e-04 - accuracy: 0.9923\n",
      "At the end of episode 2219 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2619/2619 [==============================] - 1s 304us/step - loss: -0.0115 - accuracy: 0.9859\n",
      "At the end of episode 2220 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2665/2665 [==============================] - 1s 351us/step - loss: 0.0010 - accuracy: 0.9932\n",
      "At the end of episode 2221 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2669/2669 [==============================] - 1s 411us/step - loss: -0.0069 - accuracy: 0.9876\n",
      "At the end of episode 2222 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2583/2583 [==============================] - 1s 307us/step - loss: 0.0027 - accuracy: 0.9923\n",
      "At the end of episode 2223 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3187/3187 [==============================] - 1s 308us/step - loss: -0.0030 - accuracy: 0.9906\n",
      "At the end of episode 2224 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2813/2813 [==============================] - 1s 299us/step - loss: -2.8956e-04 - accuracy: 0.9925\n",
      "At the end of episode 2225 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2861/2861 [==============================] - 1s 314us/step - loss: -0.0019 - accuracy: 0.9923\n",
      "At the end of episode 2226 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3085/3085 [==============================] - 1s 308us/step - loss: 0.0010 - accuracy: 0.9900\n",
      "At the end of episode 2227 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3100/3100 [==============================] - 1s 310us/step - loss: -0.0088 - accuracy: 0.9865\n",
      "At the end of episode 2228 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "3505/3505 [==============================] - 1s 312us/step - loss: 0.0058 - accuracy: 0.9894\n",
      "At the end of episode 2229 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3644/3644 [==============================] - 1s 305us/step - loss: 7.2428e-04 - accuracy: 0.9882\n",
      "At the end of episode 2230 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3324/3324 [==============================] - 1s 313us/step - loss: 0.0035 - accuracy: 0.9898\n",
      "At the end of episode 2231 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2601/2601 [==============================] - 1s 314us/step - loss: -0.0033 - accuracy: 0.9896\n",
      "At the end of episode 2232 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2957/2957 [==============================] - 1s 307us/step - loss: -0.0024 - accuracy: 0.9946\n",
      "At the end of episode 2233 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2812/2812 [==============================] - 1s 309us/step - loss: -5.6980e-04 - accuracy: 0.9915\n",
      "At the end of episode 2234 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2818/2818 [==============================] - 1s 313us/step - loss: -0.0052 - accuracy: 0.9901\n",
      "At the end of episode 2235 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3192/3192 [==============================] - 1s 298us/step - loss: 1.7061e-04 - accuracy: 0.9928\n",
      "At the end of episode 2236 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2448/2448 [==============================] - 1s 306us/step - loss: -0.0021 - accuracy: 0.9894\n",
      "At the end of episode 2237 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "3551/3551 [==============================] - 1s 304us/step - loss: -3.2960e-04 - accuracy: 0.9839\n",
      "At the end of episode 2238 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3181/3181 [==============================] - 1s 300us/step - loss: 0.0031 - accuracy: 0.9921\n",
      "At the end of episode 2239 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3113/3113 [==============================] - 1s 299us/step - loss: 0.0028 - accuracy: 0.9942\n",
      "At the end of episode 2240 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3279/3279 [==============================] - 1s 343us/step - loss: -0.0021 - accuracy: 0.9863\n",
      "At the end of episode 2241 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2903/2903 [==============================] - 1s 315us/step - loss: -0.0057 - accuracy: 0.9921\n",
      "At the end of episode 2242 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3077/3077 [==============================] - 1s 310us/step - loss: -0.0020 - accuracy: 0.9851\n",
      "At the end of episode 2243 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2543/2543 [==============================] - 1s 305us/step - loss: -0.0055 - accuracy: 0.9921\n",
      "At the end of episode 2244 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2957/2957 [==============================] - 1s 301us/step - loss: 3.0283e-04 - accuracy: 0.9915\n",
      "At the end of episode 2245 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3090/3090 [==============================] - 1s 296us/step - loss: -0.0023 - accuracy: 0.9906\n",
      "At the end of episode 2246 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2569/2569 [==============================] - 1s 306us/step - loss: -0.0020 - accuracy: 0.9903\n",
      "At the end of episode 2247 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2666/2666 [==============================] - 1s 312us/step - loss: -0.0019 - accuracy: 0.9917\n",
      "At the end of episode 2248 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3411/3411 [==============================] - 1s 315us/step - loss: 0.0045 - accuracy: 0.9906\n",
      "At the end of episode 2249 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3062/3062 [==============================] - 1s 302us/step - loss: -0.0026 - accuracy: 0.9866\n",
      "At the end of episode 2250 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2398/2398 [==============================] - 1s 305us/step - loss: -5.9598e-04 - accuracy: 0.9958\n",
      "At the end of episode 2251 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2530/2530 [==============================] - 1s 318us/step - loss: 3.6497e-05 - accuracy: 0.9913\n",
      "At the end of episode 2252 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3341/3341 [==============================] - 1s 322us/step - loss: -0.0076 - accuracy: 0.9907\n",
      "At the end of episode 2253 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2907/2907 [==============================] - 1s 306us/step - loss: 0.0057 - accuracy: 0.9907\n",
      "At the end of episode 2254 the total reward was : -19.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3073/3073 [==============================] - 1s 297us/step - loss: -0.0025 - accuracy: 0.9889\n",
      "At the end of episode 2255 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3734/3734 [==============================] - 1s 299us/step - loss: -7.4275e-04 - accuracy: 0.9847\n",
      "At the end of episode 2256 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2728/2728 [==============================] - 1s 302us/step - loss: -3.5638e-04 - accuracy: 0.9890\n",
      "At the end of episode 2257 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3111/3111 [==============================] - 1s 293us/step - loss: 0.0035 - accuracy: 0.9904\n",
      "At the end of episode 2258 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3504/3504 [==============================] - 1s 289us/step - loss: -0.0021 - accuracy: 0.9897\n",
      "At the end of episode 2259 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3004/3004 [==============================] - 1s 318us/step - loss: 0.0049 - accuracy: 0.9903\n",
      "At the end of episode 2260 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3007/3007 [==============================] - 1s 299us/step - loss: 0.0021 - accuracy: 0.9864\n",
      "At the end of episode 2261 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3199/3199 [==============================] - 1s 315us/step - loss: -0.0117 - accuracy: 0.9856\n",
      "At the end of episode 2262 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2755/2755 [==============================] - 1s 309us/step - loss: -0.0083 - accuracy: 0.9884\n",
      "At the end of episode 2263 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2838/2838 [==============================] - 1s 309us/step - loss: -0.0061 - accuracy: 0.9870\n",
      "At the end of episode 2264 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3149/3149 [==============================] - 1s 297us/step - loss: 0.0015 - accuracy: 0.9911\n",
      "At the end of episode 2265 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2839/2839 [==============================] - 1s 298us/step - loss: 0.0029 - accuracy: 0.9859\n",
      "At the end of episode 2266 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3328/3328 [==============================] - 1s 304us/step - loss: 0.0019 - accuracy: 0.9904\n",
      "At the end of episode 2267 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "3013/3013 [==============================] - 1s 297us/step - loss: 0.0138 - accuracy: 0.9910\n",
      "At the end of episode 2268 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2936/2936 [==============================] - 1s 294us/step - loss: -0.0017 - accuracy: 0.9908\n",
      "At the end of episode 2269 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3001/3001 [==============================] - 1s 311us/step - loss: -0.0013 - accuracy: 0.9923\n",
      "At the end of episode 2270 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3609/3609 [==============================] - 1s 298us/step - loss: -0.0032 - accuracy: 0.9909\n",
      "At the end of episode 2271 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3115/3115 [==============================] - 1s 304us/step - loss: -6.8849e-04 - accuracy: 0.9920\n",
      "At the end of episode 2272 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "4045/4045 [==============================] - 1s 303us/step - loss: 0.0027 - accuracy: 0.9867\n",
      "At the end of episode 2273 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3006/3006 [==============================] - 1s 294us/step - loss: -0.0045 - accuracy: 0.9920\n",
      "At the end of episode 2274 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3061/3061 [==============================] - 1s 307us/step - loss: -0.0042 - accuracy: 0.9935\n",
      "At the end of episode 2275 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3916/3916 [==============================] - 1s 298us/step - loss: 0.0037 - accuracy: 0.9939\n",
      "At the end of episode 2276 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3583/3583 [==============================] - 1s 312us/step - loss: 4.5619e-05 - accuracy: 0.9925\n",
      "At the end of episode 2277 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3092/3092 [==============================] - 1s 296us/step - loss: -0.0045 - accuracy: 0.9926\n",
      "At the end of episode 2278 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3118/3118 [==============================] - 1s 302us/step - loss: -0.0136 - accuracy: 0.9891\n",
      "At the end of episode 2279 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3414/3414 [==============================] - 1s 299us/step - loss: 0.0043 - accuracy: 0.9859\n",
      "At the end of episode 2280 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2955/2955 [==============================] - 1s 306us/step - loss: 0.0073 - accuracy: 0.9902\n",
      "At the end of episode 2281 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2748/2748 [==============================] - 1s 353us/step - loss: 0.0048 - accuracy: 0.9854\n",
      "At the end of episode 2282 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3242/3242 [==============================] - 1s 322us/step - loss: -0.0045 - accuracy: 0.9880\n",
      "At the end of episode 2283 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2950/2950 [==============================] - 1s 348us/step - loss: 0.0122 - accuracy: 0.9902\n",
      "At the end of episode 2284 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2678/2678 [==============================] - 1s 290us/step - loss: 0.0081 - accuracy: 0.9873\n",
      "At the end of episode 2285 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3312/3312 [==============================] - 1s 305us/step - loss: 1.8016e-04 - accuracy: 0.9876\n",
      "At the end of episode 2286 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2221/2221 [==============================] - 1s 297us/step - loss: -0.0019 - accuracy: 0.9883\n",
      "At the end of episode 2287 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2563/2563 [==============================] - 1s 321us/step - loss: -0.0050 - accuracy: 0.9934\n",
      "At the end of episode 2288 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2770/2770 [==============================] - 1s 319us/step - loss: 0.0031 - accuracy: 0.9957\n",
      "At the end of episode 2289 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2950/2950 [==============================] - 1s 309us/step - loss: -0.0104 - accuracy: 0.9895\n",
      "At the end of episode 2290 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3283/3283 [==============================] - 1s 293us/step - loss: 0.0041 - accuracy: 0.9899\n",
      "At the end of episode 2291 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2796/2796 [==============================] - 1s 314us/step - loss: 0.0037 - accuracy: 0.9914\n",
      "At the end of episode 2292 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2779/2779 [==============================] - 1s 347us/step - loss: -3.2327e-04 - accuracy: 0.9928\n",
      "At the end of episode 2293 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3476/3476 [==============================] - 1s 302us/step - loss: -0.0026 - accuracy: 0.9891\n",
      "At the end of episode 2294 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3280/3280 [==============================] - 1s 282us/step - loss: -0.0038 - accuracy: 0.9909\n",
      "At the end of episode 2295 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3474/3474 [==============================] - 1s 339us/step - loss: -0.0045 - accuracy: 0.9908\n",
      "At the end of episode 2296 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2903/2903 [==============================] - 1s 299us/step - loss: -0.0041 - accuracy: 0.9924\n",
      "At the end of episode 2297 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2771/2771 [==============================] - 1s 316us/step - loss: 0.0012 - accuracy: 0.9903\n",
      "At the end of episode 2298 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3777/3777 [==============================] - 1s 355us/step - loss: -0.0013 - accuracy: 0.9907\n",
      "At the end of episode 2299 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3460/3460 [==============================] - 1s 384us/step - loss: 0.0025 - accuracy: 0.9867\n",
      "At the end of episode 2300 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3169/3169 [==============================] - 1s 315us/step - loss: -0.0015 - accuracy: 0.9871\n",
      "At the end of episode 2301 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3200/3200 [==============================] - 1s 293us/step - loss: -0.0044 - accuracy: 0.9931\n",
      "At the end of episode 2302 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "3688/3688 [==============================] - 1s 274us/step - loss: -0.0013 - accuracy: 0.9886\n",
      "At the end of episode 2303 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3477/3477 [==============================] - 1s 279us/step - loss: 0.0019 - accuracy: 0.9902\n",
      "At the end of episode 2304 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3302/3302 [==============================] - 1s 317us/step - loss: -0.0021 - accuracy: 0.9924\n",
      "At the end of episode 2305 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3244/3244 [==============================] - 1s 277us/step - loss: 0.0064 - accuracy: 0.9861\n",
      "At the end of episode 2306 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3312/3312 [==============================] - 1s 279us/step - loss: 0.0042 - accuracy: 0.9852\n",
      "At the end of episode 2307 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2999/2999 [==============================] - 1s 297us/step - loss: 0.0062 - accuracy: 0.9840\n",
      "At the end of episode 2308 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3205/3205 [==============================] - 1s 288us/step - loss: -0.0030 - accuracy: 0.9913\n",
      "At the end of episode 2309 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2998/2998 [==============================] - 1s 288us/step - loss: -0.0193 - accuracy: 0.9860\n",
      "At the end of episode 2310 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2781/2781 [==============================] - 1s 306us/step - loss: 0.0063 - accuracy: 0.9939\n",
      "At the end of episode 2311 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3327/3327 [==============================] - 1s 305us/step - loss: -0.0035 - accuracy: 0.9859\n",
      "At the end of episode 2312 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3011/3011 [==============================] - 1s 305us/step - loss: 0.0024 - accuracy: 0.9910\n",
      "At the end of episode 2313 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2996/2996 [==============================] - 1s 300us/step - loss: -0.0021 - accuracy: 0.9863\n",
      "At the end of episode 2314 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3159/3159 [==============================] - 1s 285us/step - loss: 0.0065 - accuracy: 0.9899\n",
      "At the end of episode 2315 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2799/2799 [==============================] - 1s 321us/step - loss: 1.7621e-04 - accuracy: 0.9929\n",
      "At the end of episode 2316 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3026/3026 [==============================] - 1s 323us/step - loss: -0.0049 - accuracy: 0.9858\n",
      "At the end of episode 2317 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2906/2906 [==============================] - 1s 304us/step - loss: -7.2058e-04 - accuracy: 0.9873\n",
      "At the end of episode 2318 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2753/2753 [==============================] - 1s 336us/step - loss: -0.0068 - accuracy: 0.9916\n",
      "At the end of episode 2319 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2640/2640 [==============================] - 1s 305us/step - loss: 0.0084 - accuracy: 0.9852\n",
      "At the end of episode 2320 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3097/3097 [==============================] - 1s 296us/step - loss: 0.0030 - accuracy: 0.9910\n",
      "At the end of episode 2321 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2788/2788 [==============================] - 1s 308us/step - loss: -0.0038 - accuracy: 0.9910\n",
      "At the end of episode 2322 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2886/2886 [==============================] - 1s 372us/step - loss: -0.0038 - accuracy: 0.9906\n",
      "At the end of episode 2323 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2865/2865 [==============================] - 1s 342us/step - loss: 7.5175e-05 - accuracy: 0.9930\n",
      "At the end of episode 2324 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2467/2467 [==============================] - 1s 291us/step - loss: -0.0026 - accuracy: 0.9927\n",
      "At the end of episode 2325 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2635/2635 [==============================] - 1s 347us/step - loss: -0.0076 - accuracy: 0.9909\n",
      "At the end of episode 2326 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3002/3002 [==============================] - 1s 410us/step - loss: 0.0019 - accuracy: 0.9923\n",
      "At the end of episode 2327 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3341/3341 [==============================] - 1s 372us/step - loss: -0.0055 - accuracy: 0.9871\n",
      "At the end of episode 2328 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3772/3772 [==============================] - 1s 288us/step - loss: 0.0198 - accuracy: 0.9799\n",
      "At the end of episode 2329 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3136/3136 [==============================] - 1s 270us/step - loss: -3.5829e-04 - accuracy: 0.9879\n",
      "At the end of episode 2330 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3111/3111 [==============================] - 1s 291us/step - loss: -1.6895e-04 - accuracy: 0.9916\n",
      "At the end of episode 2331 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3573/3573 [==============================] - 1s 381us/step - loss: -0.0048 - accuracy: 0.9885\n",
      "At the end of episode 2332 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3238/3238 [==============================] - 1s 321us/step - loss: 0.0066 - accuracy: 0.9895\n",
      "At the end of episode 2333 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3229/3229 [==============================] - 1s 327us/step - loss: -0.0055 - accuracy: 0.9861\n",
      "At the end of episode 2334 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2731/2731 [==============================] - 1s 356us/step - loss: 0.0017 - accuracy: 0.9861\n",
      "At the end of episode 2335 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "3056/3056 [==============================] - 1s 296us/step - loss: 0.0022 - accuracy: 0.9902\n",
      "At the end of episode 2336 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 1s 309us/step - loss: -0.0059 - accuracy: 0.9874\n",
      "At the end of episode 2337 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2561/2561 [==============================] - 1s 318us/step - loss: -0.0021 - accuracy: 0.9945\n",
      "At the end of episode 2338 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3102/3102 [==============================] - 1s 347us/step - loss: -0.0022 - accuracy: 0.9871\n",
      "At the end of episode 2339 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3177/3177 [==============================] - 1s 305us/step - loss: -0.0020 - accuracy: 0.9915\n",
      "At the end of episode 2340 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3187/3187 [==============================] - 1s 323us/step - loss: 0.0018 - accuracy: 0.9925\n",
      "At the end of episode 2341 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3228/3228 [==============================] - 1s 298us/step - loss: 0.0036 - accuracy: 0.9913\n",
      "At the end of episode 2342 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2953/2953 [==============================] - 1s 295us/step - loss: 4.2192e-04 - accuracy: 0.9912\n",
      "At the end of episode 2343 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2660/2660 [==============================] - 1s 311us/step - loss: 4.8330e-04 - accuracy: 0.9925\n",
      "At the end of episode 2344 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3705/3705 [==============================] - 1s 298us/step - loss: -0.0067 - accuracy: 0.9846\n",
      "At the end of episode 2345 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3051/3051 [==============================] - 1s 327us/step - loss: 0.0022 - accuracy: 0.9853\n",
      "At the end of episode 2346 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2631/2631 [==============================] - 1s 313us/step - loss: 0.0097 - accuracy: 0.9920\n",
      "At the end of episode 2347 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3105/3105 [==============================] - 1s 317us/step - loss: -2.7239e-04 - accuracy: 0.9878\n",
      "At the end of episode 2348 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 1s 299us/step - loss: -4.2785e-04 - accuracy: 0.9920\n",
      "At the end of episode 2349 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3243/3243 [==============================] - 1s 332us/step - loss: -0.0012 - accuracy: 0.9938\n",
      "At the end of episode 2350 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3287/3287 [==============================] - 1s 314us/step - loss: -0.0040 - accuracy: 0.9890\n",
      "At the end of episode 2351 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3064/3064 [==============================] - 1s 307us/step - loss: -0.0021 - accuracy: 0.9899\n",
      "At the end of episode 2352 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3070/3070 [==============================] - 1s 318us/step - loss: 1.1120e-04 - accuracy: 0.9896\n",
      "At the end of episode 2353 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 1s 313us/step - loss: -0.0019 - accuracy: 0.9922\n",
      "At the end of episode 2354 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2808/2808 [==============================] - 1s 300us/step - loss: -0.0066 - accuracy: 0.9897\n",
      "At the end of episode 2355 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2328/2328 [==============================] - 1s 288us/step - loss: 0.0027 - accuracy: 0.9923\n",
      "At the end of episode 2356 the total reward was : -15.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3021/3021 [==============================] - 1s 323us/step - loss: 0.0037 - accuracy: 0.9904\n",
      "At the end of episode 2357 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3195/3195 [==============================] - 1s 379us/step - loss: -0.0090 - accuracy: 0.9894\n",
      "At the end of episode 2358 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2655/2655 [==============================] - 1s 318us/step - loss: -8.2369e-04 - accuracy: 0.9864\n",
      "At the end of episode 2359 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3324/3324 [==============================] - 1s 325us/step - loss: -0.0076 - accuracy: 0.9919\n",
      "At the end of episode 2360 the total reward was : -10.0\n",
      "Epoch 1/1\n",
      "3636/3636 [==============================] - 1s 314us/step - loss: -0.0044 - accuracy: 0.9895\n",
      "At the end of episode 2361 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2988/2988 [==============================] - 1s 330us/step - loss: 0.0027 - accuracy: 0.9886\n",
      "At the end of episode 2362 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2736/2736 [==============================] - 1s 349us/step - loss: -0.0100 - accuracy: 0.9850\n",
      "At the end of episode 2363 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2225/2225 [==============================] - 1s 301us/step - loss: 3.4356e-04 - accuracy: 0.9919\n",
      "At the end of episode 2364 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2502/2502 [==============================] - 1s 294us/step - loss: 0.0022 - accuracy: 0.9896\n",
      "At the end of episode 2365 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2106/2106 [==============================] - 1s 283us/step - loss: -0.0092 - accuracy: 0.9881\n",
      "At the end of episode 2366 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2519/2519 [==============================] - 1s 266us/step - loss: -0.0027 - accuracy: 0.9921\n",
      "At the end of episode 2367 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2785/2785 [==============================] - 1s 272us/step - loss: 0.0023 - accuracy: 0.9885\n",
      "At the end of episode 2368 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2698/2698 [==============================] - 1s 270us/step - loss: 0.0054 - accuracy: 0.9933\n",
      "At the end of episode 2369 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2144/2144 [==============================] - 1s 282us/step - loss: -0.0017 - accuracy: 0.9883\n",
      "At the end of episode 2370 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2602/2602 [==============================] - 1s 288us/step - loss: 0.0094 - accuracy: 0.9908\n",
      "At the end of episode 2371 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2607/2607 [==============================] - 1s 381us/step - loss: 0.0029 - accuracy: 0.9912\n",
      "At the end of episode 2372 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "1760/1760 [==============================] - 1s 345us/step - loss: -0.0053 - accuracy: 0.9903\n",
      "At the end of episode 2373 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2659/2659 [==============================] - 1s 341us/step - loss: -0.0010 - accuracy: 0.9925\n",
      "At the end of episode 2374 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3207/3207 [==============================] - 1s 316us/step - loss: -0.0201 - accuracy: 0.9835\n",
      "At the end of episode 2375 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2723/2723 [==============================] - 1s 319us/step - loss: -0.0093 - accuracy: 0.9905\n",
      "At the end of episode 2376 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3152/3152 [==============================] - ETA: 0s - loss: -0.0014 - accuracy: 0.9898  - 1s 346us/step - loss: -0.0014 - accuracy: 0.9902\n",
      "At the end of episode 2377 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "3004/3004 [==============================] - 1s 321us/step - loss: -0.0046 - accuracy: 0.9937\n",
      "At the end of episode 2378 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2529/2529 [==============================] - 1s 324us/step - loss: 0.0065 - accuracy: 0.9858\n",
      "At the end of episode 2379 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2970/2970 [==============================] - 1s 326us/step - loss: -0.0039 - accuracy: 0.9848\n",
      "At the end of episode 2380 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3325/3325 [==============================] - 1s 349us/step - loss: -0.0169 - accuracy: 0.9850\n",
      "At the end of episode 2381 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3224/3224 [==============================] - 1s 386us/step - loss: 0.0069 - accuracy: 0.9888\n",
      "At the end of episode 2382 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2647/2647 [==============================] - 1s 350us/step - loss: 0.0127 - accuracy: 0.9902\n",
      "At the end of episode 2383 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3096/3096 [==============================] - 1s 315us/step - loss: 0.0040 - accuracy: 0.9939\n",
      "At the end of episode 2384 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3120/3120 [==============================] - 1s 313us/step - loss: -0.0067 - accuracy: 0.9913\n",
      "At the end of episode 2385 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3611/3611 [==============================] - 1s 335us/step - loss: -1.1586e-04 - accuracy: 0.9881\n",
      "At the end of episode 2386 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3783/3783 [==============================] - 1s 293us/step - loss: 0.0039 - accuracy: 0.9947\n",
      "At the end of episode 2387 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3686/3686 [==============================] - 1s 316us/step - loss: -8.1537e-04 - accuracy: 0.9948\n",
      "At the end of episode 2388 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2949/2949 [==============================] - 1s 295us/step - loss: -0.0028 - accuracy: 0.9895\n",
      "At the end of episode 2389 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2817/2817 [==============================] - 1s 343us/step - loss: -5.4757e-04 - accuracy: 0.9879\n",
      "At the end of episode 2390 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2960/2960 [==============================] - 1s 311us/step - loss: -0.0025 - accuracy: 0.9932\n",
      "At the end of episode 2391 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2669/2669 [==============================] - 1s 289us/step - loss: 0.0237 - accuracy: 0.9816\n",
      "At the end of episode 2392 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2882/2882 [==============================] - 1s 360us/step - loss: 4.8881e-05 - accuracy: 0.9955\n",
      "At the end of episode 2393 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 1s 314us/step - loss: -0.0066 - accuracy: 0.9937\n",
      "At the end of episode 2394 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3376/3376 [==============================] - 1s 281us/step - loss: -0.0030 - accuracy: 0.9882\n",
      "At the end of episode 2395 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2882/2882 [==============================] - 1s 303us/step - loss: 0.0018 - accuracy: 0.9924\n",
      "At the end of episode 2396 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2666/2666 [==============================] - 1s 281us/step - loss: -0.0033 - accuracy: 0.9917\n",
      "At the end of episode 2397 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3393/3393 [==============================] - 1s 308us/step - loss: 0.0048 - accuracy: 0.9926\n",
      "At the end of episode 2398 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2203/2203 [==============================] - 1s 345us/step - loss: -0.0043 - accuracy: 0.9909\n",
      "At the end of episode 2399 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3245/3245 [==============================] - 1s 333us/step - loss: 2.9229e-04 - accuracy: 0.9929\n",
      "At the end of episode 2400 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2400/2400 [==============================] - 1s 298us/step - loss: -3.5911e-04 - accuracy: 0.9921\n",
      "At the end of episode 2401 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2368/2368 [==============================] - 1s 317us/step - loss: -0.0017 - accuracy: 0.9894\n",
      "At the end of episode 2402 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2403/2403 [==============================] - 1s 308us/step - loss: -0.0041 - accuracy: 0.9883\n",
      "At the end of episode 2403 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3351/3351 [==============================] - 1s 295us/step - loss: -0.0042 - accuracy: 0.9845\n",
      "At the end of episode 2404 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3394/3394 [==============================] - 1s 301us/step - loss: 0.0032 - accuracy: 0.9918\n",
      "At the end of episode 2405 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3291/3291 [==============================] - 1s 319us/step - loss: 9.2774e-04 - accuracy: 0.9897\n",
      "At the end of episode 2406 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3310/3310 [==============================] - 1s 312us/step - loss: 0.0059 - accuracy: 0.9858\n",
      "At the end of episode 2407 the total reward was : -19.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2790/2790 [==============================] - 1s 299us/step - loss: -0.0034 - accuracy: 0.9910\n",
      "At the end of episode 2408 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2554/2554 [==============================] - 1s 302us/step - loss: 0.0027 - accuracy: 0.9898\n",
      "At the end of episode 2409 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2887/2887 [==============================] - 1s 292us/step - loss: 0.0019 - accuracy: 0.9920\n",
      "At the end of episode 2410 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2516/2516 [==============================] - 1s 296us/step - loss: 0.0048 - accuracy: 0.9944\n",
      "At the end of episode 2411 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2670/2670 [==============================] - 1s 307us/step - loss: 0.0030 - accuracy: 0.9921\n",
      "At the end of episode 2412 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3101/3101 [==============================] - 1s 292us/step - loss: 0.0027 - accuracy: 0.9916\n",
      "At the end of episode 2413 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "3006/3006 [==============================] - 1s 308us/step - loss: 0.0026 - accuracy: 0.9943\n",
      "At the end of episode 2414 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2501/2501 [==============================] - 1s 297us/step - loss: -0.0011 - accuracy: 0.9884\n",
      "At the end of episode 2415 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2831/2831 [==============================] - 1s 303us/step - loss: 0.0018 - accuracy: 0.9943\n",
      "At the end of episode 2416 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3077/3077 [==============================] - 1s 299us/step - loss: 0.0017 - accuracy: 0.9906\n",
      "At the end of episode 2417 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3118/3118 [==============================] - 1s 292us/step - loss: -0.0138 - accuracy: 0.9830\n",
      "At the end of episode 2418 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2600/2600 [==============================] - 1s 301us/step - loss: 0.0018 - accuracy: 0.9900\n",
      "At the end of episode 2419 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2893/2893 [==============================] - 1s 307us/step - loss: -0.0049 - accuracy: 0.9893\n",
      "At the end of episode 2420 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 1s 303us/step - loss: -2.5075e-04 - accuracy: 0.9924\n",
      "At the end of episode 2421 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2742/2742 [==============================] - 1s 409us/step - loss: 0.0017 - accuracy: 0.9938\n",
      "At the end of episode 2422 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2583/2583 [==============================] - 1s 310us/step - loss: 6.8883e-04 - accuracy: 0.9895\n",
      "At the end of episode 2423 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2840/2840 [==============================] - 1s 302us/step - loss: 5.0797e-04 - accuracy: 0.9908\n",
      "At the end of episode 2424 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2694/2694 [==============================] - 1s 306us/step - loss: -0.0053 - accuracy: 0.9892\n",
      "At the end of episode 2425 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2962/2962 [==============================] - 1s 338us/step - loss: -0.0048 - accuracy: 0.9851\n",
      "At the end of episode 2426 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3231/3231 [==============================] - 1s 320us/step - loss: -8.3593e-04 - accuracy: 0.9842\n",
      "At the end of episode 2427 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2805/2805 [==============================] - 1s 302us/step - loss: 5.5727e-04 - accuracy: 0.9868\n",
      "At the end of episode 2428 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 1s 283us/step - loss: 7.0845e-04 - accuracy: 0.9910\n",
      "At the end of episode 2429 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2581/2581 [==============================] - 1s 266us/step - loss: -0.0058 - accuracy: 0.9892\n",
      "At the end of episode 2430 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2441/2441 [==============================] - 1s 279us/step - loss: -0.0064 - accuracy: 0.9906\n",
      "At the end of episode 2431 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2205/2205 [==============================] - 1s 272us/step - loss: -0.0015 - accuracy: 0.9887\n",
      "At the end of episode 2432 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3076/3076 [==============================] - 1s 297us/step - loss: -0.0145 - accuracy: 0.9785\n",
      "At the end of episode 2433 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3356/3356 [==============================] - 1s 298us/step - loss: 0.0036 - accuracy: 0.9902\n",
      "At the end of episode 2434 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2974/2974 [==============================] - 1s 266us/step - loss: -7.0017e-04 - accuracy: 0.9909\n",
      "At the end of episode 2435 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2635/2635 [==============================] - 1s 284us/step - loss: -7.1273e-04 - accuracy: 0.9913\n",
      "At the end of episode 2436 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3008/3008 [==============================] - 1s 274us/step - loss: -0.0036 - accuracy: 0.9900\n",
      "At the end of episode 2437 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2836/2836 [==============================] - 1s 267us/step - loss: 0.0015 - accuracy: 0.9827\n",
      "At the end of episode 2438 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2596/2596 [==============================] - 1s 271us/step - loss: -0.0012 - accuracy: 0.9931\n",
      "At the end of episode 2439 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2618/2618 [==============================] - 1s 289us/step - loss: 0.0047 - accuracy: 0.9939\n",
      "At the end of episode 2440 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2658/2658 [==============================] - 1s 271us/step - loss: 0.0144 - accuracy: 0.9913\n",
      "At the end of episode 2441 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2851/2851 [==============================] - 1s 291us/step - loss: 5.2658e-04 - accuracy: 0.9916\n",
      "At the end of episode 2442 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3278/3278 [==============================] - 1s 277us/step - loss: -0.0025 - accuracy: 0.9896\n",
      "At the end of episode 2443 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3435/3435 [==============================] - 1s 277us/step - loss: -0.0011 - accuracy: 0.9854\n",
      "At the end of episode 2444 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3406/3406 [==============================] - 1s 268us/step - loss: 5.3304e-04 - accuracy: 0.9924\n",
      "At the end of episode 2445 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2751/2751 [==============================] - 1s 264us/step - loss: -0.0044 - accuracy: 0.9935\n",
      "At the end of episode 2446 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2897/2897 [==============================] - 1s 278us/step - loss: -0.0087 - accuracy: 0.9924\n",
      "At the end of episode 2447 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3049/3049 [==============================] - 1s 342us/step - loss: -0.0042 - accuracy: 0.9944\n",
      "At the end of episode 2448 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2719/2719 [==============================] - 1s 308us/step - loss: -0.0024 - accuracy: 0.9919\n",
      "At the end of episode 2449 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2619/2619 [==============================] - 1s 297us/step - loss: 4.5230e-04 - accuracy: 0.9912\n",
      "At the end of episode 2450 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2970/2970 [==============================] - 1s 291us/step - loss: 0.0066 - accuracy: 0.9909\n",
      "At the end of episode 2451 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3306/3306 [==============================] - 1s 286us/step - loss: 0.0052 - accuracy: 0.9882\n",
      "At the end of episode 2452 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2772/2772 [==============================] - 1s 287us/step - loss: 0.0042 - accuracy: 0.9895\n",
      "At the end of episode 2453 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2549/2549 [==============================] - 1s 273us/step - loss: -0.0016 - accuracy: 0.9953\n",
      "At the end of episode 2454 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2740/2740 [==============================] - 1s 267us/step - loss: 0.0014 - accuracy: 0.9912\n",
      "At the end of episode 2455 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2584/2584 [==============================] - 1s 286us/step - loss: -0.0051 - accuracy: 0.9888\n",
      "At the end of episode 2456 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2412/2412 [==============================] - 1s 266us/step - loss: -0.0034 - accuracy: 0.9909\n",
      "At the end of episode 2457 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3232/3232 [==============================] - 1s 266us/step - loss: -0.0091 - accuracy: 0.9916\n",
      "At the end of episode 2458 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2827/2827 [==============================] - 1s 274us/step - loss: -0.0130 - accuracy: 0.9897\n",
      "At the end of episode 2459 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2292/2292 [==============================] - 1s 284us/step - loss: 0.0075 - accuracy: 0.9865\n",
      "At the end of episode 2460 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "3298/3298 [==============================] - 1s 266us/step - loss: -8.7650e-04 - accuracy: 0.9906\n",
      "At the end of episode 2461 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3206/3206 [==============================] - 1s 275us/step - loss: -0.0089 - accuracy: 0.9913\n",
      "At the end of episode 2462 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2548/2548 [==============================] - 1s 283us/step - loss: -0.0095 - accuracy: 0.9890\n",
      "At the end of episode 2463 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2859/2859 [==============================] - 1s 276us/step - loss: 7.1264e-04 - accuracy: 0.9899\n",
      "At the end of episode 2464 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2818/2818 [==============================] - 1s 264us/step - loss: 6.1704e-04 - accuracy: 0.9897\n",
      "At the end of episode 2465 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3159/3159 [==============================] - 1s 267us/step - loss: 0.0092 - accuracy: 0.9772\n",
      "At the end of episode 2466 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1727/1727 [==============================] - 0s 284us/step - loss: 7.8704e-04 - accuracy: 0.9913\n",
      "At the end of episode 2467 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2612/2612 [==============================] - 1s 301us/step - loss: -0.0021 - accuracy: 0.9912\n",
      "At the end of episode 2468 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1988/1988 [==============================] - 1s 328us/step - loss: -0.0021 - accuracy: 0.9904\n",
      "At the end of episode 2469 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2194/2194 [==============================] - 1s 277us/step - loss: -0.0081 - accuracy: 0.9909\n",
      "At the end of episode 2470 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2769/2769 [==============================] - 1s 263us/step - loss: -0.0114 - accuracy: 0.9870\n",
      "At the end of episode 2471 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3337/3337 [==============================] - 1s 266us/step - loss: -0.0088 - accuracy: 0.9904\n",
      "At the end of episode 2472 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2657/2657 [==============================] - 1s 273us/step - loss: -2.0900e-04 - accuracy: 0.9917\n",
      "At the end of episode 2473 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2791/2791 [==============================] - 1s 264us/step - loss: 8.5860e-04 - accuracy: 0.9885\n",
      "At the end of episode 2474 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3066/3066 [==============================] - 1s 264us/step - loss: -4.7862e-04 - accuracy: 0.9941\n",
      "At the end of episode 2475 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2827/2827 [==============================] - 1s 276us/step - loss: -0.0021 - accuracy: 0.9912\n",
      "At the end of episode 2476 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2705/2705 [==============================] - 1s 270us/step - loss: -0.0014 - accuracy: 0.9915\n",
      "At the end of episode 2477 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2715/2715 [==============================] - 1s 272us/step - loss: 0.0023 - accuracy: 0.9882\n",
      "At the end of episode 2478 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2997/2997 [==============================] - 1s 274us/step - loss: 0.0058 - accuracy: 0.9940\n",
      "At the end of episode 2479 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2595/2595 [==============================] - 1s 267us/step - loss: -0.0027 - accuracy: 0.9881\n",
      "At the end of episode 2480 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3006/3006 [==============================] - 1s 265us/step - loss: 0.0105 - accuracy: 0.9850\n",
      "At the end of episode 2481 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2593/2593 [==============================] - 1s 291us/step - loss: 0.0042 - accuracy: 0.9934\n",
      "At the end of episode 2482 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3080/3080 [==============================] - 1s 278us/step - loss: -0.0031 - accuracy: 0.9909\n",
      "At the end of episode 2483 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3521/3521 [==============================] - 1s 291us/step - loss: 0.0035 - accuracy: 0.9889\n",
      "At the end of episode 2484 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3331/3331 [==============================] - 1s 321us/step - loss: 0.0031 - accuracy: 0.9895\n",
      "At the end of episode 2485 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2879/2879 [==============================] - 1s 365us/step - loss: 0.0054 - accuracy: 0.9903\n",
      "At the end of episode 2486 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3235/3235 [==============================] - 1s 316us/step - loss: 8.7832e-04 - accuracy: 0.9926\n",
      "At the end of episode 2487 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2922/2922 [==============================] - 1s 283us/step - loss: -9.5985e-04 - accuracy: 0.9962\n",
      "At the end of episode 2488 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3167/3167 [==============================] - 1s 265us/step - loss: 0.0109 - accuracy: 0.9883\n",
      "At the end of episode 2489 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2355/2355 [==============================] - 1s 323us/step - loss: 5.0676e-04 - accuracy: 0.9911\n",
      "At the end of episode 2490 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3611/3611 [==============================] - 1s 272us/step - loss: -0.0044 - accuracy: 0.9914\n",
      "At the end of episode 2491 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2495/2495 [==============================] - 1s 273us/step - loss: -0.0012 - accuracy: 0.9892\n",
      "At the end of episode 2492 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2150/2150 [==============================] - 1s 277us/step - loss: -0.0037 - accuracy: 0.9930\n",
      "At the end of episode 2493 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "3287/3287 [==============================] - 1s 268us/step - loss: -0.0120 - accuracy: 0.9860\n",
      "At the end of episode 2494 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2376/2376 [==============================] - 1s 291us/step - loss: 0.0065 - accuracy: 0.9912\n",
      "At the end of episode 2495 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2940/2940 [==============================] - 1s 279us/step - loss: 0.0055 - accuracy: 0.9857\n",
      "At the end of episode 2496 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2917/2917 [==============================] - 1s 301us/step - loss: -0.0056 - accuracy: 0.9883\n",
      "At the end of episode 2497 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3264/3264 [==============================] - 1s 294us/step - loss: -0.0026 - accuracy: 0.9899\n",
      "At the end of episode 2498 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2986/2986 [==============================] - 1s 287us/step - loss: 0.0056 - accuracy: 0.9896\n",
      "At the end of episode 2499 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2727/2727 [==============================] - 1s 297us/step - loss: 0.0018 - accuracy: 0.9960\n",
      "At the end of episode 2500 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3644/3644 [==============================] - 1s 275us/step - loss: 8.1869e-04 - accuracy: 0.9909\n",
      "At the end of episode 2501 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3000/3000 [==============================] - 1s 281us/step - loss: 3.2486e-04 - accuracy: 0.9887\n",
      "At the end of episode 2502 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2520/2520 [==============================] - 1s 293us/step - loss: -0.0012 - accuracy: 0.9917\n",
      "At the end of episode 2503 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2887/2887 [==============================] - 1s 273us/step - loss: 0.0011 - accuracy: 0.9934\n",
      "At the end of episode 2504 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 1s 293us/step - loss: -0.0072 - accuracy: 0.9930\n",
      "At the end of episode 2505 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2918/2918 [==============================] - 1s 327us/step - loss: -0.0030 - accuracy: 0.9945\n",
      "At the end of episode 2506 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2849/2849 [==============================] - 1s 282us/step - loss: -7.9577e-04 - accuracy: 0.9944\n",
      "At the end of episode 2507 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3092/3092 [==============================] - 1s 307us/step - loss: 0.0116 - accuracy: 0.9919\n",
      "At the end of episode 2508 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2994/2994 [==============================] - 1s 299us/step - loss: -0.0033 - accuracy: 0.9923\n",
      "At the end of episode 2509 the total reward was : -16.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2688/2688 [==============================] - 1s 314us/step - loss: 0.0048 - accuracy: 0.9903\n",
      "At the end of episode 2510 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2982/2982 [==============================] - 1s 292us/step - loss: -0.0056 - accuracy: 0.9906\n",
      "At the end of episode 2511 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2613/2613 [==============================] - 1s 304us/step - loss: -3.5802e-05 - accuracy: 0.9920\n",
      "At the end of episode 2512 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2643/2643 [==============================] - 1s 325us/step - loss: -5.6160e-04 - accuracy: 0.9909\n",
      "At the end of episode 2513 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2614/2614 [==============================] - 1s 280us/step - loss: -0.0044 - accuracy: 0.9931\n",
      "At the end of episode 2514 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3161/3161 [==============================] - 1s 328us/step - loss: 0.0018 - accuracy: 0.9873\n",
      "At the end of episode 2515 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2952/2952 [==============================] - 1s 269us/step - loss: -0.0079 - accuracy: 0.9888\n",
      "At the end of episode 2516 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2855/2855 [==============================] - 1s 292us/step - loss: 0.0024 - accuracy: 0.9933\n",
      "At the end of episode 2517 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2759/2759 [==============================] - 1s 273us/step - loss: 0.0040 - accuracy: 0.9895\n",
      "At the end of episode 2518 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3152/3152 [==============================] - 1s 268us/step - loss: 0.0054 - accuracy: 0.9914\n",
      "At the end of episode 2519 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2736/2736 [==============================] - 1s 298us/step - loss: -0.0035 - accuracy: 0.9861\n",
      "At the end of episode 2520 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2618/2618 [==============================] - 1s 316us/step - loss: 0.0202 - accuracy: 0.9916\n",
      "At the end of episode 2521 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3406/3406 [==============================] - 1s 321us/step - loss: 0.0026 - accuracy: 0.9918\n",
      "At the end of episode 2522 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2767/2767 [==============================] - 1s 362us/step - loss: -0.0023 - accuracy: 0.9924\n",
      "At the end of episode 2523 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3100/3100 [==============================] - 1s 309us/step - loss: -0.0038 - accuracy: 0.9939\n",
      "At the end of episode 2524 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2828/2828 [==============================] - 1s 276us/step - loss: 4.5549e-04 - accuracy: 0.9929\n",
      "At the end of episode 2525 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3070/3070 [==============================] - 1s 289us/step - loss: -0.0043 - accuracy: 0.9958\n",
      "At the end of episode 2526 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2739/2739 [==============================] - 1s 299us/step - loss: -0.0027 - accuracy: 0.9898\n",
      "At the end of episode 2527 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2632/2632 [==============================] - 1s 327us/step - loss: 0.0016 - accuracy: 0.9951\n",
      "At the end of episode 2528 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2582/2582 [==============================] - 1s 504us/step - loss: -3.3181e-05 - accuracy: 0.9919\n",
      "At the end of episode 2529 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2935/2935 [==============================] - 1s 356us/step - loss: 0.0067 - accuracy: 0.9918\n",
      "At the end of episode 2530 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2121/2121 [==============================] - 1s 294us/step - loss: -0.0018 - accuracy: 0.9910\n",
      "At the end of episode 2531 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3297/3297 [==============================] - 1s 330us/step - loss: 1.8501e-04 - accuracy: 0.9909\n",
      "At the end of episode 2532 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2839/2839 [==============================] - 1s 277us/step - loss: 0.0011 - accuracy: 0.9930\n",
      "At the end of episode 2533 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2919/2919 [==============================] - 1s 317us/step - loss: -0.0022 - accuracy: 0.9908\n",
      "At the end of episode 2534 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2868/2868 [==============================] - 1s 275us/step - loss: -0.0020 - accuracy: 0.9930\n",
      "At the end of episode 2535 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2975/2975 [==============================] - 1s 286us/step - loss: -0.0026 - accuracy: 0.9862\n",
      "At the end of episode 2536 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2692/2692 [==============================] - 1s 299us/step - loss: -0.0035 - accuracy: 0.9911\n",
      "At the end of episode 2537 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3047/3047 [==============================] - 1s 271us/step - loss: 0.0013 - accuracy: 0.9918\n",
      "At the end of episode 2538 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 1s 309us/step - loss: 0.0062 - accuracy: 0.9926\n",
      "At the end of episode 2539 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2980/2980 [==============================] - 1s 286us/step - loss: -0.0023 - accuracy: 0.9943\n",
      "At the end of episode 2540 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2977/2977 [==============================] - 1s 310us/step - loss: 3.1235e-04 - accuracy: 0.9906\n",
      "At the end of episode 2541 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2851/2851 [==============================] - 1s 296us/step - loss: -0.0026 - accuracy: 0.9937\n",
      "At the end of episode 2542 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3122/3122 [==============================] - 1s 304us/step - loss: 0.0017 - accuracy: 0.9875\n",
      "At the end of episode 2543 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2628/2628 [==============================] - 1s 305us/step - loss: -0.0078 - accuracy: 0.9897\n",
      "At the end of episode 2544 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3138/3138 [==============================] - 1s 284us/step - loss: 0.0087 - accuracy: 0.9911\n",
      "At the end of episode 2545 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2644/2644 [==============================] - 1s 275us/step - loss: 0.0090 - accuracy: 0.9917\n",
      "At the end of episode 2546 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2890/2890 [==============================] - 1s 296us/step - loss: 6.6093e-06 - accuracy: 0.9934\n",
      "At the end of episode 2547 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3061/3061 [==============================] - 1s 284us/step - loss: 0.0026 - accuracy: 0.9935\n",
      "At the end of episode 2548 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2734/2734 [==============================] - 1s 285us/step - loss: -9.3956e-04 - accuracy: 0.9934\n",
      "At the end of episode 2549 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2384/2384 [==============================] - 1s 275us/step - loss: -0.0055 - accuracy: 0.9941\n",
      "At the end of episode 2550 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2622/2622 [==============================] - 1s 286us/step - loss: -0.0037 - accuracy: 0.9889\n",
      "At the end of episode 2551 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3167/3167 [==============================] - 1s 283us/step - loss: -0.0047 - accuracy: 0.9899\n",
      "At the end of episode 2552 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2918/2918 [==============================] - 1s 302us/step - loss: 0.0010 - accuracy: 0.9969\n",
      "At the end of episode 2553 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2277/2277 [==============================] - 1s 347us/step - loss: -0.0044 - accuracy: 0.9925\n",
      "At the end of episode 2554 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3135/3135 [==============================] - 1s 276us/step - loss: 0.0076 - accuracy: 0.9933\n",
      "At the end of episode 2555 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2656/2656 [==============================] - 1s 349us/step - loss: -4.4105e-04 - accuracy: 0.9925\n",
      "At the end of episode 2556 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3014/3014 [==============================] - 1s 340us/step - loss: 9.0342e-04 - accuracy: 0.9917\n",
      "At the end of episode 2557 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2949/2949 [==============================] - 1s 323us/step - loss: 0.0034 - accuracy: 0.9925\n",
      "At the end of episode 2558 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2952/2952 [==============================] - 1s 272us/step - loss: -0.0019 - accuracy: 0.9946\n",
      "At the end of episode 2559 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3299/3299 [==============================] - 1s 343us/step - loss: -0.0013 - accuracy: 0.9933\n",
      "At the end of episode 2560 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2350/2350 [==============================] - 1s 368us/step - loss: -9.1390e-04 - accuracy: 0.9945\n",
      "At the end of episode 2561 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2165/2165 [==============================] - 1s 305us/step - loss: 0.0036 - accuracy: 0.9894\n",
      "At the end of episode 2562 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2378/2378 [==============================] - 1s 274us/step - loss: 0.0031 - accuracy: 0.9912\n",
      "At the end of episode 2563 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3726/3726 [==============================] - 1s 336us/step - loss: 0.0066 - accuracy: 0.9922\n",
      "At the end of episode 2564 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2897/2897 [==============================] - 1s 307us/step - loss: -0.0011 - accuracy: 0.9928\n",
      "At the end of episode 2565 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2952/2952 [==============================] - 1s 278us/step - loss: -0.0061 - accuracy: 0.9898\n",
      "At the end of episode 2566 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2802/2802 [==============================] - 1s 270us/step - loss: -0.0057 - accuracy: 0.9918\n",
      "At the end of episode 2567 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3330/3330 [==============================] - 1s 288us/step - loss: -0.0080 - accuracy: 0.9889\n",
      "At the end of episode 2568 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3318/3318 [==============================] - 1s 307us/step - loss: 0.0091 - accuracy: 0.9898\n",
      "At the end of episode 2569 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2997/2997 [==============================] - 1s 311us/step - loss: -0.0070 - accuracy: 0.9873\n",
      "At the end of episode 2570 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2594/2594 [==============================] - 1s 281us/step - loss: -0.0024 - accuracy: 0.9958\n",
      "At the end of episode 2571 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3129/3129 [==============================] - 1s 293us/step - loss: 0.0012 - accuracy: 0.9926\n",
      "At the end of episode 2572 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 1s 285us/step - loss: -0.0041 - accuracy: 0.9932\n",
      "At the end of episode 2573 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2873/2873 [==============================] - 1s 300us/step - loss: -9.5859e-04 - accuracy: 0.9934\n",
      "At the end of episode 2574 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2938/2938 [==============================] - 1s 308us/step - loss: 0.0024 - accuracy: 0.9918\n",
      "At the end of episode 2575 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "3644/3644 [==============================] - 1s 306us/step - loss: -0.0011 - accuracy: 0.9901\n",
      "At the end of episode 2576 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3078/3078 [==============================] - 1s 315us/step - loss: 0.0015 - accuracy: 0.9906\n",
      "At the end of episode 2577 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2636/2636 [==============================] - 1s 303us/step - loss: -0.0038 - accuracy: 0.9913\n",
      "At the end of episode 2578 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2870/2870 [==============================] - 1s 283us/step - loss: 0.0085 - accuracy: 0.9955\n",
      "At the end of episode 2579 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2661/2661 [==============================] - 1s 274us/step - loss: 6.0616e-04 - accuracy: 0.9951\n",
      "At the end of episode 2580 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2800/2800 [==============================] - 1s 403us/step - loss: -0.0014 - accuracy: 0.9925\n",
      "At the end of episode 2581 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2181/2181 [==============================] - 1s 333us/step - loss: -0.0012 - accuracy: 0.9940\n",
      "At the end of episode 2582 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2879/2879 [==============================] - 1s 432us/step - loss: -0.0040 - accuracy: 0.9903\n",
      "At the end of episode 2583 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2677/2677 [==============================] - 1s 320us/step - loss: -0.0036 - accuracy: 0.9914\n",
      "At the end of episode 2584 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3117/3117 [==============================] - 1s 447us/step - loss: -0.0041 - accuracy: 0.9945\n",
      "At the end of episode 2585 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3332/3332 [==============================] - 1s 271us/step - loss: -0.0100 - accuracy: 0.9847\n",
      "At the end of episode 2586 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2567/2567 [==============================] - 1s 282us/step - loss: 8.4704e-04 - accuracy: 0.9895\n",
      "At the end of episode 2587 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3332/3332 [==============================] - 1s 303us/step - loss: 1.7035e-04 - accuracy: 0.9943\n",
      "At the end of episode 2588 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2664/2664 [==============================] - 1s 377us/step - loss: 0.0038 - accuracy: 0.9902\n",
      "At the end of episode 2589 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2833/2833 [==============================] - 1s 405us/step - loss: -0.0017 - accuracy: 0.9922\n",
      "At the end of episode 2590 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3158/3158 [==============================] - 1s 287us/step - loss: -0.0046 - accuracy: 0.9924\n",
      "At the end of episode 2591 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2534/2534 [==============================] - 1s 280us/step - loss: 0.0015 - accuracy: 0.9905\n",
      "At the end of episode 2592 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3043/3043 [==============================] - 1s 282us/step - loss: -0.0032 - accuracy: 0.9908\n",
      "At the end of episode 2593 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2915/2915 [==============================] - 1s 323us/step - loss: -0.0091 - accuracy: 0.9880\n",
      "At the end of episode 2594 the total reward was : -11.0\n",
      "Epoch 1/1\n",
      "3593/3593 [==============================] - 1s 346us/step - loss: -0.0074 - accuracy: 0.9894\n",
      "At the end of episode 2595 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2820/2820 [==============================] - 1s 288us/step - loss: 3.7309e-04 - accuracy: 0.9865\n",
      "At the end of episode 2596 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3150/3150 [==============================] - 1s 267us/step - loss: 0.0036 - accuracy: 0.9924\n",
      "At the end of episode 2597 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2862/2862 [==============================] - 1s 289us/step - loss: 0.0056 - accuracy: 0.9934\n",
      "At the end of episode 2598 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2663/2663 [==============================] - 1s 291us/step - loss: 8.9223e-04 - accuracy: 0.9917\n",
      "At the end of episode 2599 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3136/3136 [==============================] - 1s 291us/step - loss: -0.0023 - accuracy: 0.9895\n",
      "At the end of episode 2600 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3071/3071 [==============================] - 1s 318us/step - loss: -0.0016 - accuracy: 0.9971\n",
      "At the end of episode 2601 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2652/2652 [==============================] - 1s 297us/step - loss: 0.0018 - accuracy: 0.9921\n",
      "At the end of episode 2602 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2487/2487 [==============================] - 1s 341us/step - loss: 0.0035 - accuracy: 0.9916\n",
      "At the end of episode 2603 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3105/3105 [==============================] - 1s 318us/step - loss: 0.0038 - accuracy: 0.9939\n",
      "At the end of episode 2604 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3097/3097 [==============================] - 1s 323us/step - loss: 0.0069 - accuracy: 0.9903\n",
      "At the end of episode 2605 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2977/2977 [==============================] - 1s 316us/step - loss: 0.0056 - accuracy: 0.9889\n",
      "At the end of episode 2606 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2870/2870 [==============================] - 1s 362us/step - loss: 0.0041 - accuracy: 0.9906\n",
      "At the end of episode 2607 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2410/2410 [==============================] - 1s 292us/step - loss: 0.0041 - accuracy: 0.9921\n",
      "At the end of episode 2608 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2693/2693 [==============================] - 1s 301us/step - loss: -0.0053 - accuracy: 0.9933\n",
      "At the end of episode 2609 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2874/2874 [==============================] - 1s 308us/step - loss: 0.0062 - accuracy: 0.9941\n",
      "At the end of episode 2610 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2980/2980 [==============================] - 1s 359us/step - loss: -0.0035 - accuracy: 0.9960\n",
      "At the end of episode 2611 the total reward was : -19.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3139/3139 [==============================] - 1s 320us/step - loss: 2.5891e-04 - accuracy: 0.9924\n",
      "At the end of episode 2612 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2929/2929 [==============================] - 1s 314us/step - loss: -4.2851e-04 - accuracy: 0.9921\n",
      "At the end of episode 2613 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3065/3065 [==============================] - 1s 286us/step - loss: -4.7074e-04 - accuracy: 0.9935\n",
      "At the end of episode 2614 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2661/2661 [==============================] - 1s 363us/step - loss: 9.0902e-04 - accuracy: 0.9962\n",
      "At the end of episode 2615 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 1s 309us/step - loss: -0.0025 - accuracy: 0.9959\n",
      "At the end of episode 2616 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2971/2971 [==============================] - 1s 323us/step - loss: 0.0018 - accuracy: 0.9929\n",
      "At the end of episode 2617 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3066/3066 [==============================] - 1s 327us/step - loss: 0.0011 - accuracy: 0.9954\n",
      "At the end of episode 2618 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2980/2980 [==============================] - 1s 310us/step - loss: -0.0096 - accuracy: 0.9899\n",
      "At the end of episode 2619 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2918/2918 [==============================] - 1s 320us/step - loss: -5.6020e-04 - accuracy: 0.9904\n",
      "At the end of episode 2620 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2230/2230 [==============================] - 1s 332us/step - loss: 0.0016 - accuracy: 0.9946\n",
      "At the end of episode 2621 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2665/2665 [==============================] - 1s 356us/step - loss: -0.0111 - accuracy: 0.9895\n",
      "At the end of episode 2622 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 1s 378us/step - loss: -0.0045 - accuracy: 0.9872\n",
      "At the end of episode 2623 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3059/3059 [==============================] - 1s 326us/step - loss: -0.0096 - accuracy: 0.9882\n",
      "At the end of episode 2624 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2723/2723 [==============================] - 1s 316us/step - loss: -0.0041 - accuracy: 0.9952\n",
      "At the end of episode 2625 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2921/2921 [==============================] - 1s 287us/step - loss: -3.6466e-04 - accuracy: 0.9942\n",
      "At the end of episode 2626 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2667/2667 [==============================] - 1s 334us/step - loss: 9.7036e-04 - accuracy: 0.9903\n",
      "At the end of episode 2627 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2957/2957 [==============================] - 1s 369us/step - loss: 0.0086 - accuracy: 0.9919\n",
      "At the end of episode 2628 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2259/2259 [==============================] - 1s 318us/step - loss: -0.0028 - accuracy: 0.9938\n",
      "At the end of episode 2629 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2264/2264 [==============================] - 1s 317us/step - loss: -1.6929e-05 - accuracy: 0.9956\n",
      "At the end of episode 2630 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2574/2574 [==============================] - 1s 322us/step - loss: -7.8639e-04 - accuracy: 0.9926\n",
      "At the end of episode 2631 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2720/2720 [==============================] - 1s 314us/step - loss: 7.6372e-05 - accuracy: 0.9945\n",
      "At the end of episode 2632 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2934/2934 [==============================] - 1s 268us/step - loss: 0.0021 - accuracy: 0.9935\n",
      "At the end of episode 2633 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 1s 307us/step - loss: -0.0025 - accuracy: 0.9899\n",
      "At the end of episode 2634 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2645/2645 [==============================] - 1s 281us/step - loss: 0.0020 - accuracy: 0.9943\n",
      "At the end of episode 2635 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2177/2177 [==============================] - 1s 335us/step - loss: -0.0049 - accuracy: 0.9945\n",
      "At the end of episode 2636 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2748/2748 [==============================] - 1s 331us/step - loss: 0.0026 - accuracy: 0.9942\n",
      "At the end of episode 2637 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2226/2226 [==============================] - 1s 281us/step - loss: -0.0012 - accuracy: 0.9924\n",
      "At the end of episode 2638 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2993/2993 [==============================] - 1s 371us/step - loss: -0.0080 - accuracy: 0.9910\n",
      "At the end of episode 2639 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2546/2546 [==============================] - 1s 365us/step - loss: -0.0021 - accuracy: 0.9937\n",
      "At the end of episode 2640 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2537/2537 [==============================] - 1s 460us/step - loss: 0.0083 - accuracy: 0.9937\n",
      "At the end of episode 2641 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3055/3055 [==============================] - 1s 347us/step - loss: -0.0017 - accuracy: 0.9902\n",
      "At the end of episode 2642 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2965/2965 [==============================] - 1s 346us/step - loss: 0.0048 - accuracy: 0.9892\n",
      "At the end of episode 2643 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2666/2666 [==============================] - 1s 315us/step - loss: 0.0075 - accuracy: 0.9910\n",
      "At the end of episode 2644 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "2837/2837 [==============================] - 1s 432us/step - loss: 0.0027 - accuracy: 0.9926\n",
      "At the end of episode 2645 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2378/2378 [==============================] - 1s 304us/step - loss: -0.0024 - accuracy: 0.9907\n",
      "At the end of episode 2646 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2707/2707 [==============================] - 1s 309us/step - loss: -0.0021 - accuracy: 0.9948\n",
      "At the end of episode 2647 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3468/3468 [==============================] - 1s 323us/step - loss: 9.0058e-04 - accuracy: 0.9931\n",
      "At the end of episode 2648 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3175/3175 [==============================] - 1s 329us/step - loss: -0.0015 - accuracy: 0.9915\n",
      "At the end of episode 2649 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2256/2256 [==============================] - 1s 345us/step - loss: 0.0049 - accuracy: 0.9885\n",
      "At the end of episode 2650 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2544/2544 [==============================] - 1s 365us/step - loss: -0.0028 - accuracy: 0.9961\n",
      "At the end of episode 2651 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2824/2824 [==============================] - 1s 312us/step - loss: -0.0172 - accuracy: 0.9915\n",
      "At the end of episode 2652 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2960/2960 [==============================] - 1s 324us/step - loss: -5.8919e-04 - accuracy: 0.9926\n",
      "At the end of episode 2653 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2663/2663 [==============================] - 1s 324us/step - loss: -0.0034 - accuracy: 0.9947\n",
      "At the end of episode 2654 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2600/2600 [==============================] - 1s 283us/step - loss: -0.0061 - accuracy: 0.9927\n",
      "At the end of episode 2655 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2162/2162 [==============================] - 1s 472us/step - loss: -0.0036 - accuracy: 0.9935\n",
      "At the end of episode 2656 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2691/2691 [==============================] - 1s 355us/step - loss: -7.3583e-04 - accuracy: 0.9937\n",
      "At the end of episode 2657 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2521/2521 [==============================] - 1s 305us/step - loss: -7.2434e-05 - accuracy: 0.9972\n",
      "At the end of episode 2658 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2572/2572 [==============================] - 1s 276us/step - loss: 7.1416e-04 - accuracy: 0.9969\n",
      "At the end of episode 2659 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2625/2625 [==============================] - 1s 284us/step - loss: 0.0012 - accuracy: 0.9870\n",
      "At the end of episode 2660 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2813/2813 [==============================] - 1s 285us/step - loss: 0.0170 - accuracy: 0.9947\n",
      "At the end of episode 2661 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2686/2686 [==============================] - 1s 280us/step - loss: -0.0051 - accuracy: 0.9926\n",
      "At the end of episode 2662 the total reward was : -17.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2994/2994 [==============================] - 1s 308us/step - loss: -0.0018 - accuracy: 0.9910\n",
      "At the end of episode 2663 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3351/3351 [==============================] - 1s 372us/step - loss: -2.9764e-04 - accuracy: 0.9949\n",
      "At the end of episode 2664 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2274/2274 [==============================] - 1s 288us/step - loss: 0.0017 - accuracy: 0.9930\n",
      "At the end of episode 2665 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2974/2974 [==============================] - 1s 371us/step - loss: 0.0034 - accuracy: 0.9886\n",
      "At the end of episode 2666 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2656/2656 [==============================] - 1s 419us/step - loss: 0.0058 - accuracy: 0.9940\n",
      "At the end of episode 2667 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 1s 433us/step - loss: -6.1428e-04 - accuracy: 0.9944\n",
      "At the end of episode 2668 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 1s 269us/step - loss: -0.0030 - accuracy: 0.9942\n",
      "At the end of episode 2669 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2736/2736 [==============================] - 1s 435us/step - loss: -0.0238 - accuracy: 0.9898\n",
      "At the end of episode 2670 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2893/2893 [==============================] - 1s 307us/step - loss: -0.0042 - accuracy: 0.9917\n",
      "At the end of episode 2671 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2239/2239 [==============================] - 1s 276us/step - loss: -0.0025 - accuracy: 0.9955\n",
      "At the end of episode 2672 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 1s 294us/step - loss: -0.0071 - accuracy: 0.9925\n",
      "At the end of episode 2673 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2800/2800 [==============================] - 1s 270us/step - loss: 0.0027 - accuracy: 0.9939\n",
      "At the end of episode 2674 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3335/3335 [==============================] - 1s 282us/step - loss: -0.0013 - accuracy: 0.9943\n",
      "At the end of episode 2675 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2931/2931 [==============================] - 1s 307us/step - loss: -0.0024 - accuracy: 0.9908\n",
      "At the end of episode 2676 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2761/2761 [==============================] - 1s 328us/step - loss: 0.0018 - accuracy: 0.9909\n",
      "At the end of episode 2677 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2582/2582 [==============================] - 1s 285us/step - loss: 7.0956e-04 - accuracy: 0.9934\n",
      "At the end of episode 2678 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2726/2726 [==============================] - 1s 279us/step - loss: -0.0030 - accuracy: 0.9938\n",
      "At the end of episode 2679 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2867/2867 [==============================] - 1s 379us/step - loss: 3.1204e-04 - accuracy: 0.9951\n",
      "At the end of episode 2680 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3064/3064 [==============================] - 1s 287us/step - loss: 1.2499e-04 - accuracy: 0.9928\n",
      "At the end of episode 2681 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2583/2583 [==============================] - 1s 329us/step - loss: -9.5337e-04 - accuracy: 0.9965\n",
      "At the end of episode 2682 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3489/3489 [==============================] - 1s 299us/step - loss: -0.0016 - accuracy: 0.9920\n",
      "At the end of episode 2683 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2716/2716 [==============================] - 1s 272us/step - loss: 0.0024 - accuracy: 0.9919\n",
      "At the end of episode 2684 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2567/2567 [==============================] - 1s 289us/step - loss: -0.0012 - accuracy: 0.9953\n",
      "At the end of episode 2685 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2819/2819 [==============================] - 1s 287us/step - loss: 0.0012 - accuracy: 0.9947\n",
      "At the end of episode 2686 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2567/2567 [==============================] - 1s 278us/step - loss: 0.0022 - accuracy: 0.9922\n",
      "At the end of episode 2687 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3085/3085 [==============================] - 1s 286us/step - loss: 0.0031 - accuracy: 0.9929\n",
      "At the end of episode 2688 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2714/2714 [==============================] - 1s 272us/step - loss: -6.8482e-04 - accuracy: 0.9904\n",
      "At the end of episode 2689 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2931/2931 [==============================] - 1s 276us/step - loss: 0.0013 - accuracy: 0.9949\n",
      "At the end of episode 2690 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2879/2879 [==============================] - 1s 299us/step - loss: -0.0030 - accuracy: 0.9944\n",
      "At the end of episode 2691 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2968/2968 [==============================] - 1s 277us/step - loss: -0.0104 - accuracy: 0.9933\n",
      "At the end of episode 2692 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3366/3366 [==============================] - 1s 363us/step - loss: 0.0054 - accuracy: 0.9890\n",
      "At the end of episode 2693 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3539/3539 [==============================] - 1s 326us/step - loss: -3.8479e-04 - accuracy: 0.9943\n",
      "At the end of episode 2694 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2687/2687 [==============================] - 1s 279us/step - loss: 3.5425e-04 - accuracy: 0.9896\n",
      "At the end of episode 2695 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3109/3109 [==============================] - 1s 301us/step - loss: -5.4068e-04 - accuracy: 0.9916\n",
      "At the end of episode 2696 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2310/2310 [==============================] - 1s 293us/step - loss: 0.0018 - accuracy: 0.9939\n",
      "At the end of episode 2697 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2657/2657 [==============================] - 1s 289us/step - loss: -0.0095 - accuracy: 0.9928\n",
      "At the end of episode 2698 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2943/2943 [==============================] - 1s 322us/step - loss: -0.0017 - accuracy: 0.9942\n",
      "At the end of episode 2699 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3285/3285 [==============================] - 1s 273us/step - loss: 7.1471e-04 - accuracy: 0.9918\n",
      "At the end of episode 2700 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2502/2502 [==============================] - 1s 318us/step - loss: -0.0048 - accuracy: 0.9924\n",
      "At the end of episode 2701 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2549/2549 [==============================] - 1s 304us/step - loss: -0.0016 - accuracy: 0.9976\n",
      "At the end of episode 2702 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2627/2627 [==============================] - 1s 280us/step - loss: -0.0029 - accuracy: 0.9935\n",
      "At the end of episode 2703 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3208/3208 [==============================] - 1s 267us/step - loss: -3.1894e-05 - accuracy: 0.9910\n",
      "At the end of episode 2704 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2510/2510 [==============================] - 1s 329us/step - loss: 0.0115 - accuracy: 0.9869\n",
      "At the end of episode 2705 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "3034/3034 [==============================] - 1s 307us/step - loss: -5.1058e-04 - accuracy: 0.9904\n",
      "At the end of episode 2706 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2975/2975 [==============================] - 1s 279us/step - loss: -0.0063 - accuracy: 0.9926\n",
      "At the end of episode 2707 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3378/3378 [==============================] - 1s 299us/step - loss: -0.0011 - accuracy: 0.9938\n",
      "At the end of episode 2708 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2323/2323 [==============================] - 1s 285us/step - loss: -0.0063 - accuracy: 0.9910\n",
      "At the end of episode 2709 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3392/3392 [==============================] - 1s 284us/step - loss: -0.0068 - accuracy: 0.9900\n",
      "At the end of episode 2710 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2938/2938 [==============================] - 1s 302us/step - loss: 0.0026 - accuracy: 0.9939\n",
      "At the end of episode 2711 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3074/3074 [==============================] - 1s 300us/step - loss: -0.0034 - accuracy: 0.9928\n",
      "At the end of episode 2712 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3448/3448 [==============================] - 1s 289us/step - loss: -5.8526e-04 - accuracy: 0.9939\n",
      "At the end of episode 2713 the total reward was : -21.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2889/2889 [==============================] - 1s 328us/step - loss: -5.9722e-04 - accuracy: 0.9931\n",
      "At the end of episode 2714 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2729/2729 [==============================] - 1s 284us/step - loss: 0.0122 - accuracy: 0.9916\n",
      "At the end of episode 2715 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2796/2796 [==============================] - 1s 265us/step - loss: 4.8091e-04 - accuracy: 0.9921\n",
      "At the end of episode 2716 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2491/2491 [==============================] - 1s 276us/step - loss: -0.0122 - accuracy: 0.9932\n",
      "At the end of episode 2717 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3074/3074 [==============================] - 1s 271us/step - loss: -0.0037 - accuracy: 0.9941\n",
      "At the end of episode 2718 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3187/3187 [==============================] - 1s 268us/step - loss: -0.0011 - accuracy: 0.9950\n",
      "At the end of episode 2719 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3410/3410 [==============================] - 1s 281us/step - loss: -0.0238 - accuracy: 0.9883\n",
      "At the end of episode 2720 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3148/3148 [==============================] - 1s 273us/step - loss: -0.0052 - accuracy: 0.9898\n",
      "At the end of episode 2721 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3908/3908 [==============================] - 1s 273us/step - loss: 0.0044 - accuracy: 0.9908\n",
      "At the end of episode 2722 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3332/3332 [==============================] - 1s 331us/step - loss: 0.0153 - accuracy: 0.9871\n",
      "At the end of episode 2723 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3099/3099 [==============================] - 1s 325us/step - loss: 0.0061 - accuracy: 0.9929\n",
      "At the end of episode 2724 the total reward was : -9.0\n",
      "Epoch 1/1\n",
      "4168/4168 [==============================] - 1s 303us/step - loss: -0.0032 - accuracy: 0.9930\n",
      "At the end of episode 2725 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3486/3486 [==============================] - 1s 288us/step - loss: -0.0067 - accuracy: 0.9925\n",
      "At the end of episode 2726 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2790/2790 [==============================] - 1s 303us/step - loss: -0.0064 - accuracy: 0.9892\n",
      "At the end of episode 2727 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 1s 310us/step - loss: 0.0022 - accuracy: 0.9940\n",
      "At the end of episode 2728 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2836/2836 [==============================] - 1s 269us/step - loss: 0.0019 - accuracy: 0.9894\n",
      "At the end of episode 2729 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2650/2650 [==============================] - 1s 341us/step - loss: 0.0036 - accuracy: 0.9947\n",
      "At the end of episode 2730 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2560/2560 [==============================] - 1s 318us/step - loss: 0.0038 - accuracy: 0.9918\n",
      "At the end of episode 2731 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2674/2674 [==============================] - 1s 311us/step - loss: -0.0072 - accuracy: 0.9925\n",
      "At the end of episode 2732 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2826/2826 [==============================] - 1s 298us/step - loss: -6.9950e-04 - accuracy: 0.9968\n",
      "At the end of episode 2733 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2674/2674 [==============================] - 1s 324us/step - loss: 0.0053 - accuracy: 0.9940\n",
      "At the end of episode 2734 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2724/2724 [==============================] - 1s 317us/step - loss: -0.0032 - accuracy: 0.9938\n",
      "At the end of episode 2735 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2770/2770 [==============================] - 1s 295us/step - loss: -0.0026 - accuracy: 0.9921\n",
      "At the end of episode 2736 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3443/3443 [==============================] - 1s 319us/step - loss: -0.0019 - accuracy: 0.9904\n",
      "At the end of episode 2737 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2405/2405 [==============================] - 1s 312us/step - loss: -0.0040 - accuracy: 0.9946\n",
      "At the end of episode 2738 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3233/3233 [==============================] - 1s 360us/step - loss: 1.5195e-04 - accuracy: 0.9966\n",
      "At the end of episode 2739 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2143/2143 [==============================] - 1s 286us/step - loss: -0.0042 - accuracy: 0.9944\n",
      "At the end of episode 2740 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "3344/3344 [==============================] - 1s 324us/step - loss: -0.0011 - accuracy: 0.9961\n",
      "At the end of episode 2741 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2347/2347 [==============================] - 1s 342us/step - loss: -0.0017 - accuracy: 0.9949\n",
      "At the end of episode 2742 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2940/2940 [==============================] - 1s 303us/step - loss: -0.0061 - accuracy: 0.9929\n",
      "At the end of episode 2743 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2393/2393 [==============================] - 1s 346us/step - loss: 2.1266e-04 - accuracy: 0.9946\n",
      "At the end of episode 2744 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2815/2815 [==============================] - 1s 328us/step - loss: 8.8628e-04 - accuracy: 0.9950\n",
      "At the end of episode 2745 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3187/3187 [==============================] - 1s 269us/step - loss: -8.4865e-04 - accuracy: 0.9922\n",
      "At the end of episode 2746 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2590/2590 [==============================] - 1s 266us/step - loss: -0.0058 - accuracy: 0.9838\n",
      "At the end of episode 2747 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2723/2723 [==============================] - 1s 491us/step - loss: -0.0030 - accuracy: 0.9952\n",
      "At the end of episode 2748 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2376/2376 [==============================] - 1s 300us/step - loss: -0.0039 - accuracy: 0.9933\n",
      "At the end of episode 2749 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2937/2937 [==============================] - 1s 343us/step - loss: -0.0140 - accuracy: 0.9915\n",
      "At the end of episode 2750 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2811/2811 [==============================] - 1s 417us/step - loss: -0.0031 - accuracy: 0.9918\n",
      "At the end of episode 2751 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2795/2795 [==============================] - 1s 344us/step - loss: -0.0026 - accuracy: 0.9936\n",
      "At the end of episode 2752 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2725/2725 [==============================] - 1s 338us/step - loss: -0.0021 - accuracy: 0.9908\n",
      "At the end of episode 2753 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3228/3228 [==============================] - 1s 291us/step - loss: 0.0037 - accuracy: 0.9938\n",
      "At the end of episode 2754 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2684/2684 [==============================] - 1s 281us/step - loss: -2.9747e-04 - accuracy: 0.9952\n",
      "At the end of episode 2755 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3103/3103 [==============================] - 1s 294us/step - loss: 2.5643e-04 - accuracy: 0.9948\n",
      "At the end of episode 2756 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3311/3311 [==============================] - 1s 283us/step - loss: -5.5786e-04 - accuracy: 0.9915\n",
      "At the end of episode 2757 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2758/2758 [==============================] - 1s 275us/step - loss: -0.0019 - accuracy: 0.9956\n",
      "At the end of episode 2758 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2955/2955 [==============================] - 1s 273us/step - loss: -5.4666e-04 - accuracy: 0.9909\n",
      "At the end of episode 2759 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2339/2339 [==============================] - 1s 291us/step - loss: 0.0024 - accuracy: 0.9949\n",
      "At the end of episode 2760 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2826/2826 [==============================] - 1s 279us/step - loss: -2.0655e-04 - accuracy: 0.9950\n",
      "At the end of episode 2761 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2573/2573 [==============================] - 1s 280us/step - loss: 0.0017 - accuracy: 0.9938\n",
      "At the end of episode 2762 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2589/2589 [==============================] - 1s 275us/step - loss: -0.0010 - accuracy: 0.9919\n",
      "At the end of episode 2763 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2263/2263 [==============================] - 1s 284us/step - loss: -0.0019 - accuracy: 0.9951\n",
      "At the end of episode 2764 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2921/2921 [==============================] - 1s 279us/step - loss: -0.0018 - accuracy: 0.9949\n",
      "At the end of episode 2765 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2679/2679 [==============================] - 1s 274us/step - loss: -0.0080 - accuracy: 0.9940\n",
      "At the end of episode 2766 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2900/2900 [==============================] - 1s 407us/step - loss: -0.0233 - accuracy: 0.9910\n",
      "At the end of episode 2767 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3047/3047 [==============================] - 1s 346us/step - loss: -0.0179 - accuracy: 0.9918\n",
      "At the end of episode 2768 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2644/2644 [==============================] - 1s 289us/step - loss: -0.0011 - accuracy: 0.9966\n",
      "At the end of episode 2769 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2691/2691 [==============================] - 1s 323us/step - loss: -0.0028 - accuracy: 0.9941\n",
      "At the end of episode 2770 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2537/2537 [==============================] - 1s 322us/step - loss: -5.7491e-04 - accuracy: 0.9965\n",
      "At the end of episode 2771 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2725/2725 [==============================] - 1s 453us/step - loss: -0.0024 - accuracy: 0.9949\n",
      "At the end of episode 2772 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2705/2705 [==============================] - 1s 330us/step - loss: -0.0040 - accuracy: 0.9948\n",
      "At the end of episode 2773 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2752/2752 [==============================] - 1s 359us/step - loss: 0.0027 - accuracy: 0.9960\n",
      "At the end of episode 2774 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3212/3212 [==============================] - 1s 295us/step - loss: -0.0097 - accuracy: 0.9882\n",
      "At the end of episode 2775 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2895/2895 [==============================] - 1s 334us/step - loss: 0.0017 - accuracy: 0.9934\n",
      "At the end of episode 2776 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2535/2535 [==============================] - 1s 285us/step - loss: -0.0019 - accuracy: 0.9933\n",
      "At the end of episode 2777 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2946/2946 [==============================] - 1s 318us/step - loss: 0.0052 - accuracy: 0.9939\n",
      "At the end of episode 2778 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2765/2765 [==============================] - 1s 307us/step - loss: 0.0053 - accuracy: 0.9892\n",
      "At the end of episode 2779 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 1s 484us/step - loss: -0.0080 - accuracy: 0.9915\n",
      "At the end of episode 2780 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2545/2545 [==============================] - 1s 273us/step - loss: 0.0022 - accuracy: 0.9969\n",
      "At the end of episode 2781 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3161/3161 [==============================] - 1s 356us/step - loss: 0.0022 - accuracy: 0.9946\n",
      "At the end of episode 2782 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "3085/3085 [==============================] - 1s 269us/step - loss: 0.0092 - accuracy: 0.9922\n",
      "At the end of episode 2783 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2743/2743 [==============================] - 1s 306us/step - loss: -0.0129 - accuracy: 0.9891\n",
      "At the end of episode 2784 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2654/2654 [==============================] - 1s 338us/step - loss: 0.0052 - accuracy: 0.9921\n",
      "At the end of episode 2785 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2406/2406 [==============================] - 1s 318us/step - loss: 2.2955e-04 - accuracy: 0.9958\n",
      "At the end of episode 2786 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2897/2897 [==============================] - 1s 299us/step - loss: -0.0042 - accuracy: 0.9924\n",
      "At the end of episode 2787 the total reward was : -11.0\n",
      "Epoch 1/1\n",
      "3041/3041 [==============================] - 1s 367us/step - loss: 8.9873e-04 - accuracy: 0.9947\n",
      "At the end of episode 2788 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2519/2519 [==============================] - 1s 308us/step - loss: -0.0015 - accuracy: 0.9944\n",
      "At the end of episode 2789 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3649/3649 [==============================] - 1s 299us/step - loss: -0.0092 - accuracy: 0.9921\n",
      "At the end of episode 2790 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2932/2932 [==============================] - 1s 280us/step - loss: -0.0030 - accuracy: 0.9949\n",
      "At the end of episode 2791 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3322/3322 [==============================] - 1s 289us/step - loss: 0.0044 - accuracy: 0.9922\n",
      "At the end of episode 2792 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2565/2565 [==============================] - 1s 354us/step - loss: 0.0066 - accuracy: 0.9910\n",
      "At the end of episode 2793 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2570/2570 [==============================] - 1s 287us/step - loss: 0.0046 - accuracy: 0.9914\n",
      "At the end of episode 2794 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2555/2555 [==============================] - 1s 333us/step - loss: -0.0063 - accuracy: 0.9930\n",
      "At the end of episode 2795 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2533/2533 [==============================] - 1s 316us/step - loss: -0.0045 - accuracy: 0.9957\n",
      "At the end of episode 2796 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2884/2884 [==============================] - 1s 286us/step - loss: -0.0015 - accuracy: 0.9924\n",
      "At the end of episode 2797 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2337/2337 [==============================] - 1s 275us/step - loss: 0.0015 - accuracy: 0.9936\n",
      "At the end of episode 2798 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2759/2759 [==============================] - 1s 269us/step - loss: -0.0016 - accuracy: 0.9913\n",
      "At the end of episode 2799 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3292/3292 [==============================] - 1s 363us/step - loss: -0.0057 - accuracy: 0.9948\n",
      "At the end of episode 2800 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2888/2888 [==============================] - 1s 318us/step - loss: 0.0042 - accuracy: 0.9931\n",
      "At the end of episode 2801 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 1s 299us/step - loss: 0.0036 - accuracy: 0.9943\n",
      "At the end of episode 2802 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2406/2406 [==============================] - 1s 278us/step - loss: -5.9917e-04 - accuracy: 0.9946\n",
      "At the end of episode 2803 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3636/3636 [==============================] - 1s 410us/step - loss: -0.0018 - accuracy: 0.9956\n",
      "At the end of episode 2804 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2741/2741 [==============================] - 1s 388us/step - loss: 0.0027 - accuracy: 0.9934\n",
      "At the end of episode 2805 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2628/2628 [==============================] - 1s 323us/step - loss: -0.0029 - accuracy: 0.9958\n",
      "At the end of episode 2806 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2665/2665 [==============================] - 1s 337us/step - loss: -0.0011 - accuracy: 0.9951\n",
      "At the end of episode 2807 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3066/3066 [==============================] - 1s 331us/step - loss: -0.0010 - accuracy: 0.9899\n",
      "At the end of episode 2808 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2839/2839 [==============================] - 1s 326us/step - loss: -0.0045 - accuracy: 0.9940\n",
      "At the end of episode 2809 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "3012/3012 [==============================] - 1s 318us/step - loss: 0.0045 - accuracy: 0.9924\n",
      "At the end of episode 2810 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2773/2773 [==============================] - 1s 281us/step - loss: 0.0040 - accuracy: 0.9942\n",
      "At the end of episode 2811 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3354/3354 [==============================] - 1s 293us/step - loss: -2.5138e-04 - accuracy: 0.9958\n",
      "At the end of episode 2812 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2932/2932 [==============================] - 1s 334us/step - loss: 0.0045 - accuracy: 0.9884\n",
      "At the end of episode 2813 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2589/2589 [==============================] - 1s 276us/step - loss: 0.0043 - accuracy: 0.9919\n",
      "At the end of episode 2814 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2783/2783 [==============================] - 1s 284us/step - loss: -0.0096 - accuracy: 0.9903\n",
      "At the end of episode 2815 the total reward was : -19.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2725/2725 [==============================] - 1s 335us/step - loss: 0.0048 - accuracy: 0.9912\n",
      "At the end of episode 2816 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2867/2867 [==============================] - 1s 276us/step - loss: 0.0099 - accuracy: 0.9920\n",
      "At the end of episode 2817 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3163/3163 [==============================] - 1s 269us/step - loss: -0.0015 - accuracy: 0.9921\n",
      "At the end of episode 2818 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2899/2899 [==============================] - 1s 268us/step - loss: 0.0096 - accuracy: 0.9966\n",
      "At the end of episode 2819 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2892/2892 [==============================] - 1s 287us/step - loss: 0.0044 - accuracy: 0.9927\n",
      "At the end of episode 2820 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3196/3196 [==============================] - 1s 276us/step - loss: -7.1660e-04 - accuracy: 0.9959\n",
      "At the end of episode 2821 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2899/2899 [==============================] - 1s 286us/step - loss: 0.0070 - accuracy: 0.9941\n",
      "At the end of episode 2822 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3053/3053 [==============================] - 1s 272us/step - loss: -2.4677e-04 - accuracy: 0.9938\n",
      "At the end of episode 2823 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3150/3150 [==============================] - 1s 328us/step - loss: -0.0027 - accuracy: 0.9927\n",
      "At the end of episode 2824 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2646/2646 [==============================] - 1s 453us/step - loss: -0.0016 - accuracy: 0.9940\n",
      "At the end of episode 2825 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3245/3245 [==============================] - 1s 371us/step - loss: 0.0166 - accuracy: 0.9923\n",
      "At the end of episode 2826 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2651/2651 [==============================] - 1s 345us/step - loss: 0.0015 - accuracy: 0.9947\n",
      "At the end of episode 2827 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2766/2766 [==============================] - 1s 355us/step - loss: -9.6933e-05 - accuracy: 0.9986\n",
      "At the end of episode 2828 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2876/2876 [==============================] - 1s 355us/step - loss: 0.0013 - accuracy: 0.9924\n",
      "At the end of episode 2829 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3568/3568 [==============================] - 1s 291us/step - loss: -0.0030 - accuracy: 0.9899\n",
      "At the end of episode 2830 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2735/2735 [==============================] - 1s 329us/step - loss: 0.0020 - accuracy: 0.9952\n",
      "At the end of episode 2831 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2589/2589 [==============================] - 1s 337us/step - loss: -0.0045 - accuracy: 0.9977\n",
      "At the end of episode 2832 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2593/2593 [==============================] - 1s 453us/step - loss: 0.0011 - accuracy: 0.9923\n",
      "At the end of episode 2833 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "3358/3358 [==============================] - 1s 317us/step - loss: -3.2842e-04 - accuracy: 0.9958\n",
      "At the end of episode 2834 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3141/3141 [==============================] - 1s 337us/step - loss: 0.0017 - accuracy: 0.9930\n",
      "At the end of episode 2835 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2918/2918 [==============================] - 1s 316us/step - loss: -0.0024 - accuracy: 0.9931\n",
      "At the end of episode 2836 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2942/2942 [==============================] - 1s 348us/step - loss: 0.0021 - accuracy: 0.9946\n",
      "At the end of episode 2837 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2424/2424 [==============================] - 1s 282us/step - loss: -0.0055 - accuracy: 0.9950\n",
      "At the end of episode 2838 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2381/2381 [==============================] - 1s 285us/step - loss: 0.0051 - accuracy: 0.9971\n",
      "At the end of episode 2839 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 1s 271us/step - loss: -0.0056 - accuracy: 0.9952\n",
      "At the end of episode 2840 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2989/2989 [==============================] - 1s 337us/step - loss: -0.0019 - accuracy: 0.9900\n",
      "At the end of episode 2841 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3150/3150 [==============================] - 1s 324us/step - loss: -0.0036 - accuracy: 0.9959\n",
      "At the end of episode 2842 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2505/2505 [==============================] - 1s 365us/step - loss: -0.0031 - accuracy: 0.9948\n",
      "At the end of episode 2843 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "3364/3364 [==============================] - 1s 309us/step - loss: -0.0088 - accuracy: 0.9893\n",
      "At the end of episode 2844 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2631/2631 [==============================] - 1s 415us/step - loss: -0.0016 - accuracy: 0.9905\n",
      "At the end of episode 2845 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2666/2666 [==============================] - 1s 389us/step - loss: -0.0038 - accuracy: 0.9944\n",
      "At the end of episode 2846 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3247/3247 [==============================] - 1s 328us/step - loss: -0.0049 - accuracy: 0.9945\n",
      "At the end of episode 2847 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3236/3236 [==============================] - 1s 345us/step - loss: 6.7377e-04 - accuracy: 0.9951\n",
      "At the end of episode 2848 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "3125/3125 [==============================] - 1s 342us/step - loss: -1.9904e-04 - accuracy: 0.9907\n",
      "At the end of episode 2849 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2708/2708 [==============================] - 1s 323us/step - loss: -0.0015 - accuracy: 0.9922\n",
      "At the end of episode 2850 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3070/3070 [==============================] - 1s 375us/step - loss: 0.0066 - accuracy: 0.9935\n",
      "At the end of episode 2851 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2986/2986 [==============================] - 1s 319us/step - loss: -0.0044 - accuracy: 0.9950\n",
      "At the end of episode 2852 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2412/2412 [==============================] - 1s 321us/step - loss: -0.0041 - accuracy: 0.9938\n",
      "At the end of episode 2853 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3171/3171 [==============================] - 1s 336us/step - loss: -4.6976e-04 - accuracy: 0.9940\n",
      "At the end of episode 2854 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "3065/3065 [==============================] - 1s 325us/step - loss: 9.6823e-04 - accuracy: 0.9951\n",
      "At the end of episode 2855 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2334/2334 [==============================] - 1s 317us/step - loss: -0.0021 - accuracy: 0.9923\n",
      "At the end of episode 2856 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2822/2822 [==============================] - 1s 327us/step - loss: 0.0148 - accuracy: 0.9872\n",
      "At the end of episode 2857 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2036/2036 [==============================] - 1s 325us/step - loss: -0.0035 - accuracy: 0.9951\n",
      "At the end of episode 2858 the total reward was : -10.0\n",
      "Epoch 1/1\n",
      "3412/3412 [==============================] - 1s 328us/step - loss: -7.1280e-05 - accuracy: 0.9933\n",
      "At the end of episode 2859 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2764/2764 [==============================] - 1s 369us/step - loss: 0.0014 - accuracy: 0.9913\n",
      "At the end of episode 2860 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 1s 350us/step - loss: -5.6980e-04 - accuracy: 0.9924\n",
      "At the end of episode 2861 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2422/2422 [==============================] - 1s 317us/step - loss: 1.6055e-04 - accuracy: 0.9942\n",
      "At the end of episode 2862 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3056/3056 [==============================] - 1s 324us/step - loss: -0.0173 - accuracy: 0.9882\n",
      "At the end of episode 2863 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2935/2935 [==============================] - 1s 332us/step - loss: 9.5340e-04 - accuracy: 0.9956\n",
      "At the end of episode 2864 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2763/2763 [==============================] - 1s 333us/step - loss: -0.0017 - accuracy: 0.9964\n",
      "At the end of episode 2865 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2990/2990 [==============================] - 1s 330us/step - loss: 0.0041 - accuracy: 0.9916\n",
      "At the end of episode 2866 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2694/2694 [==============================] - 1s 304us/step - loss: -4.1336e-04 - accuracy: 0.9933\n",
      "At the end of episode 2867 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2612/2612 [==============================] - 1s 307us/step - loss: 0.0011 - accuracy: 0.9954\n",
      "At the end of episode 2868 the total reward was : -10.0\n",
      "Epoch 1/1\n",
      "3499/3499 [==============================] - 1s 305us/step - loss: -0.0012 - accuracy: 0.9914\n",
      "At the end of episode 2869 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "3068/3068 [==============================] - 1s 293us/step - loss: 0.0021 - accuracy: 0.9922\n",
      "At the end of episode 2870 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2832/2832 [==============================] - 1s 293us/step - loss: 2.6503e-05 - accuracy: 0.9944\n",
      "At the end of episode 2871 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2653/2653 [==============================] - 1s 297us/step - loss: 4.3807e-04 - accuracy: 0.9936\n",
      "At the end of episode 2872 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2938/2938 [==============================] - 1s 316us/step - loss: 0.0067 - accuracy: 0.9949\n",
      "At the end of episode 2873 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "3078/3078 [==============================] - 1s 296us/step - loss: -0.0025 - accuracy: 0.9873\n",
      "At the end of episode 2874 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2622/2622 [==============================] - 1s 297us/step - loss: -0.0041 - accuracy: 0.9924\n",
      "At the end of episode 2875 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2367/2367 [==============================] - 1s 290us/step - loss: -0.0043 - accuracy: 0.9941\n",
      "At the end of episode 2876 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2619/2619 [==============================] - 1s 309us/step - loss: 9.8386e-04 - accuracy: 0.9958\n",
      "At the end of episode 2877 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2530/2530 [==============================] - 1s 297us/step - loss: -0.0045 - accuracy: 0.9933\n",
      "At the end of episode 2878 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2219/2219 [==============================] - 1s 293us/step - loss: 0.0068 - accuracy: 0.9919\n",
      "At the end of episode 2879 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2211/2211 [==============================] - 1s 319us/step - loss: 0.0062 - accuracy: 0.9910\n",
      "At the end of episode 2880 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 1s 293us/step - loss: -0.0037 - accuracy: 0.9930\n",
      "At the end of episode 2881 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1798/1798 [==============================] - 1s 316us/step - loss: -0.0021 - accuracy: 0.9944\n",
      "At the end of episode 2882 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2523/2523 [==============================] - 1s 304us/step - loss: -0.0050 - accuracy: 0.9941\n",
      "At the end of episode 2883 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2328/2328 [==============================] - 1s 308us/step - loss: -0.0131 - accuracy: 0.9923\n",
      "At the end of episode 2884 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2329/2329 [==============================] - 1s 304us/step - loss: 0.0052 - accuracy: 0.9948\n",
      "At the end of episode 2885 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 1s 297us/step - loss: 0.0021 - accuracy: 0.9924\n",
      "At the end of episode 2886 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3007/3007 [==============================] - 1s 304us/step - loss: -0.0071 - accuracy: 0.9904\n",
      "At the end of episode 2887 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2820/2820 [==============================] - 1s 313us/step - loss: -0.0041 - accuracy: 0.9957\n",
      "At the end of episode 2888 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2407/2407 [==============================] - 1s 302us/step - loss: 7.4196e-04 - accuracy: 0.9946\n",
      "At the end of episode 2889 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2545/2545 [==============================] - 1s 296us/step - loss: 6.4243e-04 - accuracy: 0.9961\n",
      "At the end of episode 2890 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2768/2768 [==============================] - 1s 301us/step - loss: -0.0015 - accuracy: 0.9960\n",
      "At the end of episode 2891 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "3143/3143 [==============================] - 1s 311us/step - loss: -0.0014 - accuracy: 0.9930\n",
      "At the end of episode 2892 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2782/2782 [==============================] - 1s 307us/step - loss: -0.0047 - accuracy: 0.9921\n",
      "At the end of episode 2893 the total reward was : -14.0\n",
      "Epoch 1/1\n",
      "2808/2808 [==============================] - 1s 295us/step - loss: -0.0214 - accuracy: 0.9882\n",
      "At the end of episode 2894 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1549/1549 [==============================] - 0s 314us/step - loss: -0.0034 - accuracy: 0.9961\n",
      "At the end of episode 2895 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1918/1918 [==============================] - 1s 313us/step - loss: 0.0163 - accuracy: 0.9917\n",
      "At the end of episode 2896 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2202/2202 [==============================] - 1s 295us/step - loss: -0.0019 - accuracy: 0.9968\n",
      "At the end of episode 2897 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2290/2290 [==============================] - 1s 301us/step - loss: 0.0020 - accuracy: 0.9895\n",
      "At the end of episode 2898 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1841/1841 [==============================] - 1s 299us/step - loss: 5.5282e-06 - accuracy: 0.9967\n",
      "At the end of episode 2899 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2182/2182 [==============================] - 1s 317us/step - loss: -0.0117 - accuracy: 0.9904\n",
      "At the end of episode 2900 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1274/1274 [==============================] - 0s 311us/step - loss: -0.0021 - accuracy: 0.9945\n",
      "At the end of episode 2901 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2265/2265 [==============================] - 1s 311us/step - loss: 3.7216e-04 - accuracy: 0.9894\n",
      "At the end of episode 2902 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2162/2162 [==============================] - 1s 304us/step - loss: 8.8335e-04 - accuracy: 0.9921\n",
      "At the end of episode 2903 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2233/2233 [==============================] - 1s 313us/step - loss: 0.0023 - accuracy: 0.9919\n",
      "At the end of episode 2904 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1771/1771 [==============================] - 1s 296us/step - loss: -0.0013 - accuracy: 0.9972\n",
      "At the end of episode 2905 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2081/2081 [==============================] - 1s 317us/step - loss: -0.0034 - accuracy: 0.9962\n",
      "At the end of episode 2906 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1506/1506 [==============================] - 0s 313us/step - loss: -0.0049 - accuracy: 0.9980\n",
      "At the end of episode 2907 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1983/1983 [==============================] - 1s 317us/step - loss: -0.0041 - accuracy: 0.9914\n",
      "At the end of episode 2908 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2082/2082 [==============================] - 1s 296us/step - loss: -0.0026 - accuracy: 0.9962\n",
      "At the end of episode 2909 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1598/1598 [==============================] - 1s 318us/step - loss: 0.0031 - accuracy: 0.9944\n",
      "At the end of episode 2910 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1514/1514 [==============================] - 0s 309us/step - loss: -0.0029 - accuracy: 0.9954\n",
      "At the end of episode 2911 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1726/1726 [==============================] - 1s 318us/step - loss: -0.0206 - accuracy: 0.9907\n",
      "At the end of episode 2912 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1987/1987 [==============================] - 1s 320us/step - loss: -0.0120 - accuracy: 0.9930\n",
      "At the end of episode 2913 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1426/1426 [==============================] - 0s 305us/step - loss: -0.0083 - accuracy: 0.9951\n",
      "At the end of episode 2914 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1998/1998 [==============================] - 1s 325us/step - loss: -9.7042e-04 - accuracy: 0.9970\n",
      "At the end of episode 2915 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1165/1165 [==============================] - 0s 306us/step - loss: 0.0050 - accuracy: 0.9931\n",
      "At the end of episode 2916 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1338/1338 [==============================] - 0s 328us/step - loss: -0.0224 - accuracy: 0.9851\n",
      "At the end of episode 2917 the total reward was : -20.0\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1795/1795 [==============================] - 1s 305us/step - loss: -0.0056 - accuracy: 0.9955\n",
      "At the end of episode 2918 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1605/1605 [==============================] - 1s 312us/step - loss: -0.0080 - accuracy: 0.9882\n",
      "At the end of episode 2919 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1668/1668 [==============================] - 1s 320us/step - loss: -0.0061 - accuracy: 0.9964\n",
      "At the end of episode 2920 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1670/1670 [==============================] - 0s 294us/step - loss: -4.8122e-04 - accuracy: 0.9946\n",
      "At the end of episode 2921 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2257/2257 [==============================] - 1s 300us/step - loss: -8.2969e-04 - accuracy: 0.9938\n",
      "At the end of episode 2922 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1762/1762 [==============================] - 1s 304us/step - loss: 0.0119 - accuracy: 0.9921\n",
      "At the end of episode 2923 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1614/1614 [==============================] - 1s 316us/step - loss: -0.0061 - accuracy: 0.9919\n",
      "At the end of episode 2924 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1488/1488 [==============================] - 0s 295us/step - loss: -0.0034 - accuracy: 0.9966\n",
      "At the end of episode 2925 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1594/1594 [==============================] - 0s 293us/step - loss: -0.0026 - accuracy: 0.9925\n",
      "At the end of episode 2926 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1997/1997 [==============================] - 1s 304us/step - loss: -0.0109 - accuracy: 0.9920\n",
      "At the end of episode 2927 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "1552/1552 [==============================] - 0s 314us/step - loss: -0.0070 - accuracy: 0.9903\n",
      "At the end of episode 2928 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1429/1429 [==============================] - 0s 298us/step - loss: 0.0037 - accuracy: 0.9951\n",
      "At the end of episode 2929 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1921/1921 [==============================] - 1s 323us/step - loss: -9.2523e-04 - accuracy: 0.9964\n",
      "At the end of episode 2930 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1926/1926 [==============================] - 1s 301us/step - loss: -0.0023 - accuracy: 0.9953\n",
      "At the end of episode 2931 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1095/1095 [==============================] - 0s 321us/step - loss: 0.0061 - accuracy: 0.9945\n",
      "At the end of episode 2932 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1175/1175 [==============================] - 0s 304us/step - loss: -0.0015 - accuracy: 0.9898\n",
      "At the end of episode 2933 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1269/1269 [==============================] - 0s 325us/step - loss: 3.9808e-04 - accuracy: 0.9953\n",
      "At the end of episode 2934 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1507/1507 [==============================] - 0s 309us/step - loss: -0.0046 - accuracy: 0.9980\n",
      "At the end of episode 2935 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2083/2083 [==============================] - 1s 311us/step - loss: 0.0059 - accuracy: 0.9928\n",
      "At the end of episode 2936 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1407/1407 [==============================] - 0s 320us/step - loss: -0.0133 - accuracy: 0.9900\n",
      "At the end of episode 2937 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2109/2109 [==============================] - 1s 309us/step - loss: -0.0041 - accuracy: 0.9934\n",
      "At the end of episode 2938 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1764/1764 [==============================] - 1s 313us/step - loss: -0.0054 - accuracy: 0.9943\n",
      "At the end of episode 2939 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2987/2987 [==============================] - 1s 313us/step - loss: -6.0614e-04 - accuracy: 0.9916\n",
      "At the end of episode 2940 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2167/2167 [==============================] - 1s 295us/step - loss: 0.0056 - accuracy: 0.9945\n",
      "At the end of episode 2941 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1928/1928 [==============================] - 1s 309us/step - loss: -0.0046 - accuracy: 0.9953\n",
      "At the end of episode 2942 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2168/2168 [==============================] - 1s 294us/step - loss: -0.0028 - accuracy: 0.9945\n",
      "At the end of episode 2943 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2217/2217 [==============================] - 1s 308us/step - loss: -0.0146 - accuracy: 0.9932\n",
      "At the end of episode 2944 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 1s 317us/step - loss: 0.0155 - accuracy: 0.9918\n",
      "At the end of episode 2945 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2331/2331 [==============================] - 1s 301us/step - loss: 8.7454e-04 - accuracy: 0.9914\n",
      "At the end of episode 2946 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2655/2655 [==============================] - 1s 302us/step - loss: 0.0104 - accuracy: 0.9917\n",
      "At the end of episode 2947 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2066/2066 [==============================] - 1s 311us/step - loss: -0.0104 - accuracy: 0.9894\n",
      "At the end of episode 2948 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2010/2010 [==============================] - 1s 299us/step - loss: -0.0012 - accuracy: 0.9980\n",
      "At the end of episode 2949 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2505/2505 [==============================] - 1s 358us/step - loss: -7.4068e-04 - accuracy: 0.9964\n",
      "At the end of episode 2950 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2128/2128 [==============================] - 1s 300us/step - loss: -0.0029 - accuracy: 0.9934\n",
      "At the end of episode 2951 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2854/2854 [==============================] - 1s 306us/step - loss: 0.0077 - accuracy: 0.9909\n",
      "At the end of episode 2952 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "1921/1921 [==============================] - 1s 307us/step - loss: -0.0133 - accuracy: 0.9927\n",
      "At the end of episode 2953 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2227/2227 [==============================] - 1s 315us/step - loss: 0.0012 - accuracy: 0.9955\n",
      "At the end of episode 2954 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1506/1506 [==============================] - 0s 310us/step - loss: -0.0046 - accuracy: 0.9920\n",
      "At the end of episode 2955 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1507/1507 [==============================] - 0s 314us/step - loss: -0.0022 - accuracy: 0.9973\n",
      "At the end of episode 2956 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2483/2483 [==============================] - 1s 290us/step - loss: -0.0069 - accuracy: 0.9907\n",
      "At the end of episode 2957 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1683/1683 [==============================] - 0s 294us/step - loss: -0.0067 - accuracy: 0.9887\n",
      "At the end of episode 2958 the total reward was : -16.0\n",
      "Epoch 1/1\n",
      "2615/2615 [==============================] - 1s 297us/step - loss: -8.3984e-04 - accuracy: 0.9927\n",
      "At the end of episode 2959 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2324/2324 [==============================] - 1s 305us/step - loss: 0.0012 - accuracy: 0.9923\n",
      "At the end of episode 2960 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2422/2422 [==============================] - 1s 296us/step - loss: -9.8945e-04 - accuracy: 0.9946\n",
      "At the end of episode 2961 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1834/1834 [==============================] - 1s 321us/step - loss: -0.0096 - accuracy: 0.9945\n",
      "At the end of episode 2962 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2090/2090 [==============================] - 1s 307us/step - loss: -0.0037 - accuracy: 0.9947\n",
      "At the end of episode 2963 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2700/2700 [==============================] - 1s 310us/step - loss: -6.1950e-04 - accuracy: 0.9948\n",
      "At the end of episode 2964 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2087/2087 [==============================] - 1s 316us/step - loss: -0.0088 - accuracy: 0.9890\n",
      "At the end of episode 2965 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2305/2305 [==============================] - 1s 313us/step - loss: -0.0022 - accuracy: 0.9935\n",
      "At the end of episode 2966 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1836/1836 [==============================] - 1s 315us/step - loss: -0.0012 - accuracy: 0.9951\n",
      "At the end of episode 2967 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2023/2023 [==============================] - 1s 328us/step - loss: 9.1468e-04 - accuracy: 0.9975\n",
      "At the end of episode 2968 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1744/1744 [==============================] - 1s 340us/step - loss: 7.2348e-04 - accuracy: 0.9948\n",
      "At the end of episode 2969 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1744/1744 [==============================] - 1s 313us/step - loss: -0.0013 - accuracy: 0.9954\n",
      "At the end of episode 2970 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2157/2157 [==============================] - 1s 305us/step - loss: -0.0013 - accuracy: 0.9958\n",
      "At the end of episode 2971 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1893/1893 [==============================] - 1s 317us/step - loss: -0.0109 - accuracy: 0.9931\n",
      "At the end of episode 2972 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2002/2002 [==============================] - 1s 305us/step - loss: 0.0020 - accuracy: 0.9935\n",
      "At the end of episode 2973 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2560/2560 [==============================] - 1s 291us/step - loss: -1.1276e-04 - accuracy: 0.9973\n",
      "At the end of episode 2974 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1597/1597 [==============================] - 0s 305us/step - loss: -6.7522e-04 - accuracy: 0.9919\n",
      "At the end of episode 2975 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1914/1914 [==============================] - 1s 297us/step - loss: -0.0090 - accuracy: 0.9901\n",
      "At the end of episode 2976 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "1606/1606 [==============================] - 0s 302us/step - loss: -0.0044 - accuracy: 0.9900\n",
      "At the end of episode 2977 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2609/2609 [==============================] - 1s 307us/step - loss: -4.3270e-04 - accuracy: 0.9916\n",
      "At the end of episode 2978 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2378/2378 [==============================] - 1s 306us/step - loss: 0.0052 - accuracy: 0.9903\n",
      "At the end of episode 2979 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2577/2577 [==============================] - 1s 314us/step - loss: -0.0025 - accuracy: 0.9953\n",
      "At the end of episode 2980 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2275/2275 [==============================] - 1s 311us/step - loss: -5.2014e-04 - accuracy: 0.9921\n",
      "At the end of episode 2981 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2918/2918 [==============================] - 1s 304us/step - loss: -0.0050 - accuracy: 0.9952\n",
      "At the end of episode 2982 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2879/2879 [==============================] - 1s 304us/step - loss: 7.5367e-04 - accuracy: 0.9948\n",
      "At the end of episode 2983 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2565/2565 [==============================] - 1s 326us/step - loss: 0.0104 - accuracy: 0.9895\n",
      "At the end of episode 2984 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2097/2097 [==============================] - 1s 327us/step - loss: -0.0056 - accuracy: 0.9895\n",
      "At the end of episode 2985 the total reward was : -15.0\n",
      "Epoch 1/1\n",
      "2757/2757 [==============================] - 1s 304us/step - loss: 0.0328 - accuracy: 0.9891\n",
      "At the end of episode 2986 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2653/2653 [==============================] - 1s 306us/step - loss: -0.0060 - accuracy: 0.9928\n",
      "At the end of episode 2987 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2215/2215 [==============================] - 1s 294us/step - loss: 3.1136e-04 - accuracy: 0.9959\n",
      "At the end of episode 2988 the total reward was : -18.0\n",
      "Epoch 1/1\n",
      "2540/2540 [==============================] - 1s 302us/step - loss: -0.0026 - accuracy: 0.9949\n",
      "At the end of episode 2989 the total reward was : -21.0\n",
      "Epoch 1/1\n",
      "2153/2153 [==============================] - 1s 320us/step - loss: 0.0100 - accuracy: 0.9949\n",
      "At the end of episode 2990 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2874/2874 [==============================] - 1s 302us/step - loss: -3.5333e-04 - accuracy: 0.9916\n",
      "At the end of episode 2991 the total reward was : -20.0\n",
      "Epoch 1/1\n",
      "2512/2512 [==============================] - 1s 296us/step - loss: -0.0033 - accuracy: 0.9948\n",
      "At the end of episode 2992 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 1s 299us/step - loss: -0.0018 - accuracy: 0.9938\n",
      "At the end of episode 2993 the total reward was : -13.0\n",
      "Epoch 1/1\n",
      "3196/3196 [==============================] - 1s 298us/step - loss: -0.0034 - accuracy: 0.9928\n",
      "At the end of episode 2994 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2671/2671 [==============================] - 1s 303us/step - loss: -1.9536e-04 - accuracy: 0.9921\n",
      "At the end of episode 2995 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2819/2819 [==============================] - 1s 297us/step - loss: -5.1812e-04 - accuracy: 0.9929\n",
      "At the end of episode 2996 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2546/2546 [==============================] - 1s 299us/step - loss: -0.0016 - accuracy: 0.9929\n",
      "At the end of episode 2997 the total reward was : -17.0\n",
      "Epoch 1/1\n",
      "2656/2656 [==============================] - 1s 297us/step - loss: -0.0012 - accuracy: 0.9947\n",
      "At the end of episode 2998 the total reward was : -12.0\n",
      "Epoch 1/1\n",
      "3532/3532 [==============================] - 1s 308us/step - loss: 0.0022 - accuracy: 0.9926\n",
      "At the end of episode 2999 the total reward was : -19.0\n",
      "Epoch 1/1\n",
      "2517/2517 [==============================] - 1s 327us/step - loss: -0.0040 - accuracy: 0.9917\n"
     ]
    }
   ],
   "source": [
    "# from karpathy import prepro, discount_rewards\n",
    "reward_sum_history = []\n",
    "\n",
    "# main loop\n",
    "# while (True):\n",
    "while episode_nb < 3000:\n",
    "\n",
    "    # preprocess the observation, set input as difference between images\n",
    "    cur_input = prepro(observation)\n",
    "    x = cur_input - prev_input if prev_input is not None else np.zeros(80 * 80)\n",
    "    prev_input = cur_input\n",
    "    \n",
    "    # forward the policy network and sample action according to the proba distribution\n",
    "    proba = model.predict(np.expand_dims(x, axis=1).T)\n",
    "    action = UP_ACTION if np.random.uniform() < proba else DOWN_ACTION\n",
    "    y = 1 if action == 2 else 0 # 0 and 1 are our labels\n",
    "\n",
    "    # log the input and label to train later\n",
    "    x_train.append(x)\n",
    "    y_train.append(y)\n",
    "\n",
    "    # do one step in our environment\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    rewards.append(reward)\n",
    "    reward_sum += reward\n",
    "    \n",
    "    # end of an episode\n",
    "    if done:\n",
    "        print('At the end of episode', episode_nb, 'the total reward was :', reward_sum)\n",
    "#         print(f'cur_input: {cur_input}, prev_input = {prev_input}, x = {x}, action = {action}, proba = {proba}')\n",
    "#         print(f'x_train = {x_train}, y_train = {y_train}')\n",
    "#         print(f'reward = {reward}')\n",
    "        \n",
    "        reward_sum_history.append(reward_sum)\n",
    "        \n",
    "        # increment episode number\n",
    "        episode_nb += 1\n",
    "        \n",
    "        # training\n",
    "        model.fit(x=np.vstack(x_train), y=np.vstack(y_train), verbose=1, sample_weight=discount_rewards(rewards, gamma))\n",
    "                                                             \n",
    "        # Reinitialization\n",
    "        x_train, y_train, rewards = [],[],[]\n",
    "        observation = env.reset()\n",
    "        reward_sum = 0\n",
    "        prev_input = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing total rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reward_sum_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = np.array(reward_sum_history)\n",
    "plt.plot(Y, linewidth=0.25)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total reward')\n",
    "plt.title('Pong-agent training')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: matplotlib\n",
      "Version: 2.2.5\n",
      "Summary: Python plotting package\n",
      "Home-page: http://matplotlib.org\n",
      "Author: John D. Hunter, Michael Droettboom\n",
      "Author-email: matplotlib-users@python.org\n",
      "License: PSF\n",
      "Location: /Users/hannesengelbrecht/Library/Python/2.7/lib/python/site-packages\n",
      "Requires: kiwisolver, subprocess32, cycler, six, backports.functools-lru-cache, pytz, numpy, pyparsing, python-dateutil\n",
      "Required-by: \n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip show matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frame list collector\n",
    "frames = []\n",
    "STEPS = 3000\n",
    "\n",
    "# code for the two only actions in Pong\n",
    "UP_ACTION = 2\n",
    "DOWN_ACTION = 3\n",
    "\n",
    "# initializing our environment\n",
    "env = gym.make(\"Pong-v0\")\n",
    "\n",
    "# beginning of an episode\n",
    "observation = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk.\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main loop\n",
    "for i in range(STEPS):    \n",
    "    # choose action based on model's recommendation\n",
    "    # preprocess the observation, set input as difference between images\n",
    "    cur_input = prepro(observation)\n",
    "    x = cur_input - prev_input if prev_input is not None else np.zeros(80 * 80)\n",
    "    prev_input = cur_input\n",
    "    \n",
    "    proba = loaded_model.predict(np.expand_dims(x, axis=1).T)\n",
    "    action = UP_ACTION if np.random.uniform() < proba else DOWN_ACTION\n",
    "\n",
    "    #run one step\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    frames.append(observation) # collecting observation\n",
    "\n",
    "    # if episode is over, reset to beginning\n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "        frames.append(observation) # collecting observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "\n",
    "def save_frames_as_gif(frames, filename=None):\n",
    "    \"\"\"\n",
    "    Save a list of frames as a gif\n",
    "    \"\"\"\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "    if filename:\n",
    "        anim.save(filename, dpi=72, writer='imagemagick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALQAAADnCAYAAAC313xrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAADVUlEQVR4nO3cwU0bQRiAUTaigcQ1pAMucEdKRAvuIRKFoKQHt4By4A4XOqAGpwXnFokEr0jkzbKf37utR5bn8OnXyBp72O12J1Dxbu4NwCEJmhRBkyJoUgRNyunY4jAMo1+BfP30/rC7gVf48v3HsG9tNOglBHt5cf7Ha3f3DzPsZHker6/++j1nN7cT7ORwHDlIETQpgiZl9AzNcXnpfPwv5+w5mdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFJcTuKXpV1EeokJTYqgSRE0KcPYf9t9+/zBH9/x5oz96tuEJkXQpIweObbbrSMHb85qtXLk4DgImhRBkyJoUgRNiqBJETQpgiZF0KS4nMTiuJzE0RA0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFJO594AbY/XV8+ez25uJ/08E5oUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImxX1oJjX1/effmdCkCJqUyY8clxfnz57v7h+m/kiOmAlNiqBJETQpgiZF0KQImhRBkyJoUhYR9HrzdLLePM29DRZgEUHDawmaFEGTsoj70Jv1x7m3wEKY0KQImhRBkzL5GdqFfv4nE5oUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJqUYbfb7V3cbrf7F2Emq9Vq2LdmQpMiaFIETYqgSRE0KYImRdCkCJoUQZMiaFIETYqgSRE0KYImRdCkCJqU0Qv+sDQmNCmCJkXQpAiaFEGTImhSfgJqrkHV/CS8pQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from support import save_frames_as_gif\n",
    "# Save the run\n",
    "save_frames_as_gif(frames, filename='pong-agent demo.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main file (.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Python file for reviewers\n",
    "\n",
    "# import relevant libs\n",
    "import gym\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from support import save_frames_as_gif, prepro, summary_of_episodes \"\"\"create a support.py file containing these two functions\"\"\"\n",
    "\n",
    "# set up the environment\n",
    "# Frame list collector\n",
    "frames = []\n",
    "STEPS = 1000\n",
    "\n",
    "# code for the two only actions in Pong\n",
    "UP_ACTION = 2\n",
    "DOWN_ACTION = 3\n",
    "\n",
    "# initializing our environment\n",
    "env = gym.make(\"Pong-v0\")\n",
    "reward_sum = 0\n",
    "\n",
    "# beginning of an episode\n",
    "observation = env.reset()\n",
    "\n",
    "# import model here\n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk.\")\n",
    "\n",
    "# support function 1 - put in support.py file\n",
    "# preprocessing used by Karpathy (cf. https://gist.github.com/karpathy/a4166c7fe253700972fcbc77e4ea32c5)\n",
    "def prepro(I):\n",
    "    \"\"\"prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector\"\"\"\n",
    "    I = I[35:195] # crop\n",
    "    I = I[::2,::2,0] # downsample by factor of 2\n",
    "    I[I == 144] = 0 # erase background (background type 1)\n",
    "    I[I == 109] = 0 # erase background (background type 2)\n",
    "    I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "    return I.astype(np.float).ravel()\n",
    "\n",
    "# support function 2 - put in support.py file\n",
    "# visualising the game\n",
    "def save_frames_as_gif(frames, filename=None):\n",
    "    \"\"\"\n",
    "    Save a list of frames as a gif\n",
    "    \"\"\"\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    def animate(i):\n",
    "        patch.set_data(frames[i])s\n",
    "    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "    if filename:\n",
    "        anim.save(filename, dpi=72, writer='imagemagick')\n",
    "\n",
    "# main loop\n",
    "reward_sum_history_2 = []\n",
    "for i in range(STEPS):\n",
    "    # choose action based on model's recommendation\n",
    "    # preprocess the observation, set input as difference between images\n",
    "    cur_input = prepro(observation)\n",
    "    x = cur_input - prev_input if prev_input is not None else np.zeros(80 * 80)\n",
    "    prev_input = cur_input\n",
    "    \n",
    "    proba = loaded_model.predict(np.expand_dims(x, axis=1).T)\n",
    "    action = UP_ACTION if np.random.uniform() < proba else DOWN_ACTION\n",
    "\n",
    "    #run one step\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    frames.append(observation) # collecting observation\n",
    "    reward_sum += reward\n",
    "    \n",
    "    # if episode is over, reset to beginning\n",
    "    if done:\n",
    "        observation = env.reset()\n",
    "        frames.append(observation) # collecting observation\n",
    "        reward_sum_history_2.append(reward_sum)\n",
    "        \n",
    "        # increment episode number\n",
    "        episode_nb += 1\n",
    "\n",
    "        # Reinitialization\n",
    "        rewards = [],[],[]\n",
    "        observation = env.reset()\n",
    "        reward_sum = 0\n",
    "        prev_input = None\n",
    "\n",
    "# print results to command line\n",
    "summary_of_episodes(reward_sum_history)\n",
    "\n",
    "# Save the run\n",
    "save_frames_as_gif(frames, filename='pong-agent-demo.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
